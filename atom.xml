<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>00&#39;s Adventure</title>
  
  <subtitle>Why join the navy if you can be a pirate</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://uegeek.com/"/>
  <updated>2018-03-22T14:22:45.000Z</updated>
  <id>http://uegeek.com/</id>
  
  <author>
    <name>kidult00</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DeepLearning笔记：如何用亚马逊云服务 GPU 训练神经网络</title>
    <link href="http://uegeek.com/180322-DeepLearning11-aws-gpu-training.html"/>
    <id>http://uegeek.com/180322-DeepLearning11-aws-gpu-training.html</id>
    <published>2018-03-22T14:05:27.000Z</published>
    <updated>2018-03-22T14:22:45.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/p2_cool_gpus_1.png" alt=""></p><p>在 Udacity 的深度学习纳米学位课程中，5 个实战项目里至少有 3 个需要用到 GPU 来训练模型。课程附带了 100 刀的亚马逊云服务（AWS）credit，这篇笔记分享如何使用 AWS 完成模型的训练。</p><p>[toc]</p><a id="more"></a> <h2 id="注册帐户"><a href="#注册帐户" class="headerlink" title="注册帐户"></a>注册帐户</h2><p>首先，注册亚马逊 AWS 的免费帐号：<a href="https://aws.amazon.com/free/" target="_blank" rel="noopener">Amazon Web Services Cloud</a>。</p><p>在项目中要用到 <a href="https://aws.amazon.com/ec2" target="_blank" rel="noopener">Elastic Compute Cloud (EC2)</a>，它可以启动 GPU 运行的虚拟服务，具体类型是 <code>p2.xlarge</code>。</p><p>我们会用到 <a href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB#product-description" target="_blank" rel="noopener">this AMI (Amazon Machine Image)</a> 去定义所需要的环境。在使用之前，需要选择离你最近的 AWS 地区：</p><ul><li>EU (Ireland)</li><li>Asia Pacific (Seoul)</li><li>Asia Pacific (Tokyo)</li><li>Asia Pacific (Sydney)</li><li>US East (N. Virginia)</li><li>US East (Ohio)</li><li>US West (Oregon)</li></ul><p>选择好后，查看 <a href="https://console.aws.amazon.com/ec2/v2/home?#Limits" target="_blank" rel="noopener">EC2 Service Limit report</a>，找到 「正在按需运行的 p2.xlarge 实例」项目：</p><p><img src="https://d17h27t6h515a5.cloudfront.net/topher/2017/November/5a1c631b_p2xlarge-limit-request/p2xlarge-limit-request.png" alt=""></p><p>如果限制是 0，点击右侧「请求提高限制」链接。提高限值不会收费，运行 instance 才会收费。</p><p>提高限制的表单需要填写：</p><ul><li>Region: 选择前面步骤的 AWS 地区</li><li>Primary Instance Type: p2.xlarge</li><li>Limit: Instance Limit</li><li>New Limit Value: 1 (more if you like)</li><li>Use Case Description: I would like to use GPU instances for deep learning.</li></ul><p>如果之前没有启动过 AWS 服务，可能会收到确认邮件。</p><p>在 <a href="https://console.aws.amazon.com/billing/home?#/credits" target="_blank" rel="noopener">Billing Management Console</a> 页面输入 Udacity 提供的优惠代码。</p><h2 id="运行实例"><a href="#运行实例" class="headerlink" title="运行实例"></a>运行实例</h2><h3 id="Launch-an-Instance"><a href="#Launch-an-Instance" class="headerlink" title="Launch an Instance"></a>Launch an Instance</h3><p>访问 <a href="https://console.aws.amazon.com/ec2/v2/home" target="_blank" rel="noopener">EC2 Management Console</a>, 点击 “Launch Instance” 。</p><p>选择 AMI (Amazon Machine Image) </p><p>如下图，进入 AWS Marketplace，搜索 Deep Learning AMI with Source Code (CUDA 8, Ubuntu)。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/screen-shot-2017-11-26-at-9.38.24-am.png" alt=""></p><h3 id="Select-the-Instance-Type"><a href="#Select-the-Instance-Type" class="headerlink" title="Select the Instance Type"></a>Select the Instance Type</h3><p>在步骤 2: 选择一个实例类型中</p><ul><li>Filter the instance list to only show “GPU compute”</li><li>Select the p2.xlarge instance type</li><li>Review and Launch</li></ul><h3 id="Configure-the-Security-Group"><a href="#Configure-the-Security-Group" class="headerlink" title="Configure the Security Group"></a>Configure the Security Group</h3><p>在 步骤 7: 核查实例启动 中点击「编辑安全组」</p><p>On the “Configure Security Group” page:</p><ul><li>Select “Create a new security group”</li><li>Set the “Security group name” (i.e. “Jupyter”)</li><li>Click “Add Rule”</li><li>Set a “Custom TCP Rule”<ul><li>Set the “Port Range” to “8888”</li><li>Select “Anywhere” as the “Source”</li></ul></li><li>Click “Review and Launch” (again)</li></ul><h3 id="Create-an-Authentication-Key-Pair"><a href="#Create-an-Authentication-Key-Pair" class="headerlink" title="Create an Authentication Key Pair"></a>Create an Authentication Key Pair</h3><p>“Create a new key pair” and click the “Download Key Pair” button. 下载 .pem 文件并保存好，在启动时需要这个文件。</p><p>下载完成后，继续点击「启动实例」按钮。</p><h3 id="设置计费提醒"><a href="#设置计费提醒" class="headerlink" title="设置计费提醒"></a>设置计费提醒</h3><p>此刻开始，启动这个 EC2 instance，AWS 会开始计费。费用可以查看 <a href="https://aws.amazon.com/ec2/pricing/on-demand/" target="_blank" rel="noopener">EC2 On-Demand Pricing page</a></p><p>p2.xlarge: $0.9 每小时</p><blockquote><p>Most importantly, remember to “stop” (i.e. shutdown) your instances when you are not using them. Otherwise, your instances might run for a day, week, month, or longer without you remembering, and you’ll wind up with a large bill!</p></blockquote><h2 id="登录云服务器"><a href="#登录云服务器" class="headerlink" title="登录云服务器"></a>登录云服务器</h2><p>实例启动后，在命令行中进入 .pem 文件保存的目录，输入命令（IP 是控制台提供的 IP，每次都不同）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -i DLND.pem ubuntu@13.115.162.209</span><br></pre></td></tr></table></figure><p>这时候看到错误提示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">@         WARNING: UNPROTECTED PRIVATE KEY FILE!          @</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">Permissions 0644 <span class="keyword">for</span> <span class="string">'DLND.pem'</span> are too open.</span><br><span class="line">It is required that your private key files are NOT accessible by others.</span><br><span class="line">This private key will be ignored.</span><br><span class="line">Load key <span class="string">"DLND.pem"</span>: bad permissions</span><br><span class="line">ubuntu@13.115.162.209: Permission denied (publickey).</span><br></pre></td></tr></table></figure><p>查找到 <a href="https://docs.aws.amazon.com/zh_cn/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#troubleshoot-unprotected-key" target="_blank" rel="noopener">排查实例的连接问题 - Amazon Elastic Compute Cloud</a></p><blockquote><p>您的密钥必须不公开可见，SSH 才能工作。要修复此错误，请执行以下命令:</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 400 DLND.pem</span><br></pre></td></tr></table></figure><h2 id="配置-Jupyter-notebook"><a href="#配置-Jupyter-notebook" class="headerlink" title="配置 Jupyter notebook"></a>配置 Jupyter notebook</h2><p>连接服务器后，输入以下命令创建 Jupyter notebook 的配置文件： </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --generate-config</span><br></pre></td></tr></table></figure><p>服务器返回：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Writing default config to: /home/ubuntu/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure><p>然后，修改 notebook 的 IP 地址设置： </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -ie <span class="string">"s/#c.NotebookApp.ip = 'localhost'/#c.NotebookApp.ip = '*'/g"</span> ~/.jupyter/jupyter_notebook_config.py</span><br></pre></td></tr></table></figure><h2 id="测试实例"><a href="#测试实例" class="headerlink" title="测试实例"></a>测试实例</h2><p>On the EC2 instance</p><ul><li>Clone a GitHub repository<br>  <code>git clone https://github.com/udacity/aind2-cnn.git</code></li><li>Enter the repo directory<br>  <code>cd aind2-cnn</code></li><li>Install the requirements<br>  <code>sudo python3 -m pip install -r requirements/requirements-gpu.txt</code></li><li>Start Jupyter notebook<br>  <code>jupyter notebook --ip=0.0.0.0 --no-browser</code></li></ul><p>From your local machine</p><ul><li><p>You will need the token generated by your jupyter notebook to access it. On your instance terminal, there will be the following line: <code>Copy/paste this URL into your browser when you connect for the first time, to login with a token:</code>. Copy everything starting with the <code>:8888/?token=</code>.</p><ul><li><code>http://13.115.162.209:8888/?token=94e72e170ca3fdbe1cd7c58a3fd898e9533e740beb6070fa</code></li></ul></li><li><p>Access the Jupyter notebook index from your web browser by visiting: X.X.X.X:8888/?token=… (where X.X.X.X is the IP address of your EC2 instance and everything starting with :8888/?token= is what you just copied).</p></li><li>Click on “mnist_mlp” to enter the folder, and select the “mnist_mlp.ipynb” notebook.</li><li>Run each cell in the notebook.</li></ul><p>实验完，记得 stop instance。</p><h2 id="新建环境"><a href="#新建环境" class="headerlink" title="新建环境"></a>新建环境</h2><p>参考<a href="https://discussions.youdaxue.com/t/topic/44102" target="_blank" rel="noopener">深度学习学前须知及常见问题 - DLND: 深度学习纳米学位 - 优达学城论坛</a></p><p>安装 conda</p><p><code>wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh</code></p><p><code>bash Miniconda3-latest-Linux-x86_64.sh</code></p><p>新建环境</p><p><code>conda create -n dlnd python=3</code></p><p>激活环境</p><p><code>source activate dlnd</code></p><p>安装 tf</p><p><code>pip install --ignore-installed https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.1.0-cp36-cp36m-linux_x86_64.whl</code></p><h2 id="下次进入环境"><a href="#下次进入环境" class="headerlink" title="下次进入环境"></a>下次进入环境</h2><ul><li>从链接 <a href="https://ap-northeast-1.console.aws.amazon.com/ec2/v2/home?region=ap-northeast-1#Instances:sort=instanceId" target="_blank" rel="noopener">EC2 Management Console</a> 启动实例</li><li>本地输入命令 <code>ssh -i DLND.pem ubuntu@52.197.226.169</code></li><li>连接服务器后，激活环境 <code>source activate dlnd</code></li><li>启动 jupyter notebook <code>jupyter notebook --ip=0.0.0.0</code></li><li>在浏览器打开：<a href="http://52.197.226.169:8888/?token=a55e1cfbc162df6d3358e3553d220b4d269e2789df6e5ddd" target="_blank" rel="noopener">http://52.197.226.169:8888/?token=a55e1cfbc162df6d3358e3553d220b4d269e2789df6e5ddd</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/p2_cool_gpus_1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在 Udacity 的深度学习纳米学位课程中，5 个实战项目里至少有 3 个需要用到 GPU 来训练模型。课程附带了 100 刀的亚马逊云服务（AWS）credit，这篇笔记分享如何使用 AWS 完成模型的训练。&lt;/p&gt;
&lt;p&gt;[toc]&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="神经网络" scheme="http://uegeek.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Programming" scheme="http://uegeek.com/tags/Programming/"/>
    
      <category term="AWS" scheme="http://uegeek.com/tags/AWS/"/>
    
      <category term="GPU" scheme="http://uegeek.com/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>00&#39;s Learning Log 180223</title>
    <link href="http://uegeek.com/180223-learning-log.html"/>
    <id>http://uegeek.com/180223-learning-log.html</id>
    <published>2018-02-23T14:38:28.000Z</published>
    <updated>2018-02-23T14:41:07.000Z</updated>
    
    <content type="html"><![CDATA[<p>Summary</p><ul><li>整理文档系统结构，参考 <a href="http://www.yangzhiping.com/psy/yang-KnowledgeSystem.html" target="_blank" rel="noopener">构建优雅的知识创造系统 - 阳志平的网志</a> 采用域名方式命名。</li><li>整理 gitbook 文档理出 sound visualization 的思路</li><li>p5.sound 的 envelope 和 FFT 例子</li><li>Music Theory 101 的 <a href="https://prod-edxapp.edx-cdn.org/assets/courseware/v1/063c6ec50fc9d2b0f6c8624843bfaf24/asset-v1:JuilliardX+JX001x+3T2017+type@asset+block/Mod4_PS.pdf" target="_blank" rel="noopener">Model 4 练习</a></li><li>「乐理自学指南」第1-10课</li></ul><a id="more"></a> <h2 id="p5-sound"><a href="#p5-sound" class="headerlink" title="p5.sound"></a>p5.sound</h2><h3 id="phrase"><a href="#phrase" class="headerlink" title="phrase"></a>phrase</h3><p>乐句是一段时间内 musical events 的模式，比如一系列的音符和休止。Phrases 必需添加到 <code>p5.Part</code> 播放。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> p5.Phrase(name,callback,sequence)</span><br></pre></td></tr></table></figure><p><code>p5.Part</code> 播放一个或多个 <code>p5.Phrases</code>. 用 steps and tatums(Divisions of a beat) 初始化. 每个 step 默认为 1/16 音符。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> p5.Part([steps],[tatums])</span><br></pre></td></tr></table></figure><p>例子中用函数控制声音播放/暂停时的显示，可以参考</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">updateDescription</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!soundFile.isPlaying()) &#123;</span><br><span class="line">    description = <span class="string">'Paused...'</span>;</span><br><span class="line">    p.html(description);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (soundFile.isPlaying())&#123;</span><br><span class="line">    description = <span class="string">'Playing!'</span>;</span><br><span class="line">    p.html(description);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; frameCount%<span class="number">3</span>; i++ ) &#123;</span><br><span class="line">      <span class="comment">// add periods to loading to create a fun loading bar effect</span></span><br><span class="line">      <span class="keyword">if</span> (frameCount%<span class="number">4</span> == <span class="number">0</span>)&#123;</span><br><span class="line">        description += <span class="string">'.'</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (frameCount%<span class="number">25</span> == <span class="number">0</span>) &#123;</span><br><span class="line">        description = <span class="string">'loading'</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    p.html(description);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="sampleRate"><a href="#sampleRate" class="headerlink" title="sampleRate"></a>sampleRate</h3><p>返回每一秒所有声音对象总体采样率数值。It is often 44100, or twice the range of human hearing.</p><ul><li><a href="https://p5js.org/reference/#/p5.Phrase" target="_blank" rel="noopener">p5.js | Phrase</a></li><li><a href="https://p5js.org/reference/#/p5.Part" target="_blank" rel="noopener">p5.js | Part</a></li><li><a href="https://p5js.org/reference/#/p5/sampleRate" target="_blank" rel="noopener">p5.js | sampleRate</a></li></ul><h2 id="Music-Theory-101-Model-4-练习"><a href="#Music-Theory-101-Model-4-练习" class="headerlink" title="Music Theory 101 Model 4 练习"></a>Music Theory 101 Model 4 练习</h2><p>在识别音级的这个练习中：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-02-23%20at%205.34.34%20PM.png" alt=""></p><p>在给定曲调的下方的音符，音程为 (8+1-间隔音程)</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Summary&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;整理文档系统结构，参考 &lt;a href=&quot;http://www.yangzhiping.com/psy/yang-KnowledgeSystem.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;构建优雅的知识创造系统 - 阳志平的网志&lt;/a&gt; 采用域名方式命名。&lt;/li&gt;
&lt;li&gt;整理 gitbook 文档理出 sound visualization 的思路&lt;/li&gt;
&lt;li&gt;p5.sound 的 envelope 和 FFT 例子&lt;/li&gt;
&lt;li&gt;Music Theory 101 的 &lt;a href=&quot;https://prod-edxapp.edx-cdn.org/assets/courseware/v1/063c6ec50fc9d2b0f6c8624843bfaf24/asset-v1:JuilliardX+JX001x+3T2017+type@asset+block/Mod4_PS.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Model 4 练习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;「乐理自学指南」第1-10课&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
      <category term="读书" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="Note" scheme="http://uegeek.com/tags/Note/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Learning" scheme="http://uegeek.com/tags/Learning/"/>
    
      <category term="Music" scheme="http://uegeek.com/tags/Music/"/>
    
  </entry>
  
  <entry>
    <title>00&#39;s Learning Log 180222</title>
    <link href="http://uegeek.com/180222-learning-log.html"/>
    <id>http://uegeek.com/180222-learning-log.html</id>
    <published>2018-02-22T12:35:53.000Z</published>
    <updated>2018-02-23T14:39:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>Summary</p><ul><li>p5.sound 的例子</li><li>优化了情人节小动画</li><li>Treble + Bass clef 组合练习</li><li>Music Theory 101 Model 4</li><li>知识大融通 ch12</li></ul><a id="more"></a> <h2 id="p5-sound-对象和方法学习"><a href="#p5-sound-对象和方法学习" class="headerlink" title="p5.sound 对象和方法学习"></a>p5.sound 对象和方法学习</h2><p>补充昨天 SawOsc/TriOsc 的波形图像<br><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Waveforms.svg/400px-Waveforms.svg.png" alt=""></p><p>昨天看了半天文档和例子，发现效率还是比较低。今早搜了一下 youtube，发现丹叔也有讲 p5.sound！<a href="https://www.youtube.com/watch?v=Pn1g1wjxl_0&amp;list=PLRqwX-V7Uu6aFcVjlDAkkGIixw70s7jpW" target="_blank" rel="noopener">17.1: Loading and Playing - p5.js Sound Tutorial</a> 开心地刷完了 11 个视频。</p><h3 id="Loading-and-Playing"><a href="#Loading-and-Playing" class="headerlink" title="Loading and Playing"></a>Loading and Playing</h3><p><a href="https://www.youtube.com/watch?v=Pn1g1wjxl_0&amp;list=PLRqwX-V7Uu6aFcVjlDAkkGIixw70s7jpW" target="_blank" rel="noopener">17.1: Loading and Playing - p5.js Sound Tutorial</a></p><p>加载声音：<code>loadSound()</code>，必需在 setup() 或 draw() 函数内使用。在 p5.js 里一般会用两种方式加载声音文件：</p><ul><li><code>preload()</code> : 用于在 <code>setup()</code> 之前加载文件，加载成功才开始运行其他部分</li><li><code>callback()</code> ：如果不想完全加载才运行程序，可以用</li></ul><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> song, slider, button;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">setup</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">createCanvas(<span class="number">200</span>, <span class="number">200</span>);</span><br><span class="line">background(<span class="number">127</span>);</span><br><span class="line">  song = loadSound(<span class="string">'song.mp3'</span>, loaded);</span><br><span class="line">button = createButton(<span class="string">'play'</span>);</span><br><span class="line">button.mousePressed(togglePlaying);</span><br><span class="line">  slider = createSlider(<span class="number">0</span>, <span class="number">1</span>, <span class="number">0.5</span>, <span class="number">0.01</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">loaded</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">'loaded'</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">draw</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  song.setVolume(slider.value());</span><br><span class="line">  <span class="comment">// song.pan(slider.value()); //set right or left channel, -1~1</span></span><br><span class="line">  <span class="comment">// song.rate(slider.value()); //set play speed</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">togglePlaying</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (!song.isPlaying()) &#123;</span><br><span class="line">song.play(); <span class="comment">// or song.loop();</span></span><br><span class="line">button.html(<span class="string">'pause'</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">song.pause();</span><br><span class="line">button.html(<span class="string">'play'</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Add-cue"><a href="#Add-cue" class="headerlink" title="Add cue"></a>Add cue</h3><p><code>addCue(time,callback,[value])</code> ：在设定的时间点(a playback cue point)触发事件。 <a href="https://p5js.org/reference/#/p5.SoundFile/addCue" target="_blank" rel="noopener">p5.js | addCue</a></p><p>比如可以在游戏中加载音效：<a href="https://www.youtube.com/watch?v=40Me1-yAtTc&amp;index=5&amp;list=PLRqwX-V7Uu6aFcVjlDAkkGIixw70s7jpW" target="_blank" rel="noopener">17.5: Adding Sound Effects - p5.js Sound Tutorial</a></p><h3 id="Sound-Synthesis"><a href="#Sound-Synthesis" class="headerlink" title="Sound Synthesis"></a>Sound Synthesis</h3><p><a href="https://www.youtube.com/watch?v=Bk8rLzzSink&amp;index=6&amp;list=PLRqwX-V7Uu6aFcVjlDAkkGIixw70s7jpW" target="_blank" rel="noopener">17.6: Sound Synthesis - p5.js Sound Tutorial</a></p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wave = <span class="keyword">new</span> p5.Oscillator();</span><br><span class="line"></span><br><span class="line">wave.setType(<span class="string">'sine'</span>);</span><br><span class="line">wave.start();</span><br><span class="line">wave.amp(<span class="number">0.5</span>);</span><br><span class="line">wave.freq(<span class="number">440</span>);</span><br></pre></td></tr></table></figure><h3 id="ADSR-Envelope"><a href="#ADSR-Envelope" class="headerlink" title="ADSR Envelope"></a>ADSR Envelope</h3><p>补充昨天的 env 对象。<a href="https://www.youtube.com/watch?v=wUSva_BnedA&amp;list=PLRqwX-V7Uu6aFcVjlDAkkGIixw70s7jpW&amp;index=7" target="_blank" rel="noopener">17.7: ADSR Envelope - p5.js Sound Tutorial</a></p><p><img src="https://blog.landr.com/wp-content/uploads/2016/10/ASDR-01.jpg" alt=""></p><p>A-Attack<br>D-Decay<br>S-Sustain<br>R-Release</p><h2 id="优化情人节小动画"><a href="#优化情人节小动画" class="headerlink" title="优化情人节小动画"></a>优化情人节小动画</h2><p><a href="http://www.uegeek.com/20180214.html" target="_blank" rel="noopener">查看</a></p><ul><li>裁剪音频</li><li>用 preload 函数预先加载音频</li><li>增加 play/pause 按钮控制播放</li><li>调整频谱视觉效果，尝试渐变</li></ul><h2 id="拾遗"><a href="#拾遗" class="headerlink" title="拾遗"></a>拾遗</h2><ul><li><a href="https://github.com/sindresorhus/awesome" target="_blank" rel="noopener">sindresorhus/awesome: Curated list of awesome lists</a>：Github 超全索引！</li><li><a href="https://www.electronics-tutorials.ws/" target="_blank" rel="noopener">Basic Electronics Tutorials and Revision</a>：电路电子教材</li><li><a href="https://arnofaure.github.io/free-sfx/" target="_blank" rel="noopener">Free SFX</a>：免费音效</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Summary&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;p5.sound 的例子&lt;/li&gt;
&lt;li&gt;优化了情人节小动画&lt;/li&gt;
&lt;li&gt;Treble + Bass clef 组合练习&lt;/li&gt;
&lt;li&gt;Music Theory 101 Model 4&lt;/li&gt;
&lt;li&gt;知识大融通 ch12&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
      <category term="读书" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="Note" scheme="http://uegeek.com/tags/Note/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Learning" scheme="http://uegeek.com/tags/Learning/"/>
    
      <category term="Music" scheme="http://uegeek.com/tags/Music/"/>
    
  </entry>
  
  <entry>
    <title>00&#39;s Learning Log 180221</title>
    <link href="http://uegeek.com/180221-learning-log.html"/>
    <id>http://uegeek.com/180221-learning-log.html</id>
    <published>2018-02-21T13:02:31.000Z</published>
    <updated>2018-02-22T08:58:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>Summary</p><ul><li>基于例子学习 p5.sound 库的几类对象和方法</li><li>开始 Bass clef 低音谱号识谱练习(工具 Music Tutor App)</li><li>Music Theory 101 的 <a href="https://prod-edxapp.edx-cdn.org/assets/courseware/v1/063c6ec50fc9d2b0f6c8624843bfaf24/asset-v1:JuilliardX+JX001x+3T2017+type@asset+block/Mod3_PS.pdf" target="_blank" rel="noopener">Module 3 练习</a></li><li>开始使用 workflowy 写学习 log (工具 <a href="https://chrome.google.com/webstore/detail/workflowy-panel/nhmckiepjgggfmmdlklgalgphjaopidk" target="_blank" rel="noopener">WorkFlowy Panel</a>)</li><li>知识大融通 ch11</li></ul><a id="more"></a> <h2 id="p5-sound-对象和方法学习"><a href="#p5-sound-对象和方法学习" class="headerlink" title="p5.sound 对象和方法学习"></a>p5.sound 对象和方法学习</h2><h3 id="fft"><a href="#fft" class="headerlink" title="fft"></a>fft</h3><p>FFT (Fast Fourier Transform 快速傅里叶变换) 是一种分离声音频率波形的分析算法。p5 里面的 FFP 对象可以分析声音的频率，返回两种数组：</p><ul><li><p><code>FFT.waveform()</code> : 计算时间振幅。数组内每一个值代表取样时间内的波形振幅。返回值在 -1 到 1 之间。<strong>可用来绘制声音的波形</strong>。</p></li><li><p><code>FFT.analyze()</code> : 计算频率振幅。数组内每一个值代表频谱(frequency spectrum, i.e. pitches)振幅。用 <code>getEnergy()</code> 方法可以获取某个范围内的频率。</p></li></ul><p><a href="https://www.youtube.com/watch?v=2O3nm0Nvbi4&amp;list=PLRqwX-V7Uu6aFcVjlDAkkGIixw70s7jpW&amp;index=11" target="_blank" rel="noopener">17.11: Sound Visualization: Frequency Analysis with FFT - p5.js Sound Tutorial</a></p><h3 id="noise"><a href="#noise" class="headerlink" title="noise"></a>noise</h3><p>Noise 对象是生成随机 buffer 的振荡器(oscillator)。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> p5.Noise(type) <span class="comment">//String: Type of noise can be 'white' (default), 'brown' or 'pink'.</span></span><br></pre></td></tr></table></figure><h3 id="delay"><a href="#delay" class="headerlink" title="delay"></a>delay</h3><p>Delay 生成回声效果. 参数包括 delay time, feedback, filter, and type. </p><h3 id="env"><a href="#env" class="headerlink" title="env"></a>env</h3><p>Envelopes (中文术语是什么？)是预先定义时间内的振幅分布，常用于控制输出音量和 a series of fades referred to as Attack, Decay, Sustain and Release (ADSR).<br><img src="https://upload.wikimedia.org/wikipedia/commons/e/ea/ADSR_parameter.svg" alt="ADSR">  </p><h3 id="SawOsc-TriOsc"><a href="#SawOsc-TriOsc" class="headerlink" title="SawOsc/TriOsc"></a>SawOsc/TriOsc</h3><p>创建 SawTooth Wave Oscillator / Triangle Wave Oscillator (相当于 <code>new p5.Oscillator(&#39;sawtooth&#39;)</code>/ <code>p5.Oscillator(&#39;triangle&#39;)</code> 或者创建 <code>p5.Oscillator</code> 然后调用 <code>setType(&#39;sawtooth&#39;)</code> / <code>setType(&#39;triangle&#39;)</code> )</p><h3 id="distortion"><a href="#distortion" class="headerlink" title="distortion"></a>distortion</h3><p>生成 Waveshaper Node，是 p5.Effect 的子类。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> p5.Distortion([amount=<span class="number">0.25</span>],[oversample=<span class="string">'none'</span>])</span><br></pre></td></tr></table></figure><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://p5js.org/reference/#/p5.FFT" target="_blank" rel="noopener">p5.js | FFT</a></li><li><a href="https://p5js.org/reference/#/p5.Noise" target="_blank" rel="noopener">p5.js | Noise</a></li><li><a href="https://p5js.org/reference/#/p5.Delay" target="_blank" rel="noopener">p5.js | Delay</a></li><li><a href="https://p5js.org/reference/#/p5.Env" target="_blank" rel="noopener">p5.js | Env</a></li><li><a href="https://p5js.org/reference/#/p5.Oscillator" target="_blank" rel="noopener">p5.js | Oscillator</a></li><li><a href="https://p5js.org/reference/#/p5.SawOsc" target="_blank" rel="noopener">p5.js | SawOsc</a></li><li><a href="https://p5js.org/reference/#/p5.TriOsc" target="_blank" rel="noopener">p5.js | TriOsc</a></li><li><a href="https://p5js.org/reference/#/p5.Distortion" target="_blank" rel="noopener">p5.js | Distortion</a></li></ul><h2 id="Bass-clef-识谱练习"><a href="#Bass-clef-识谱练习" class="headerlink" title="Bass clef 识谱练习"></a>Bass clef 识谱练习</h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Bass_and_Treble_clef.svg/400px-Bass_and_Treble_clef.svg.png" alt=""></p><p>经过一周练习，Treble clef 高音谱号的识谱练习准确率可达 95% 以上。熟练掌握 Treble clef 后，Bass clef 整体下移三度，另外加上快捷位置记忆：</p><ul><li>下加二线：C</li><li>0-3间：FACE 🙂</li><li>5线：A</li><li>上加一线：C</li></ul><p>继续用 Music Tutor 练习，吸取 Treble clef 的经验，开始时的练习可以设置为：</p><ul><li>练习时长 1 分钟（便于总结规律）</li><li>识别区间B1-E4 (强化记忆中间区域的 notes)</li><li>去掉升降号识别</li><li>熟悉自己的 base notes 以后，增加练习时长，并且加入升降号识别</li></ul><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/IMG_9C409B101E19-1.jpeg" alt=""></p><h2 id="Music-Theory-101-的-Module-3-练习"><a href="#Music-Theory-101-的-Module-3-练习" class="headerlink" title="Music Theory 101 的 Module 3 练习"></a>Music Theory 101 的 Module 3 练习</h2><p>Juilliard 的这门课 <a href="https://courses.edx.org/courses/course-v1:JuilliardX+JX001x+3T2017/course/" target="_blank" rel="noopener">Music Theory 101</a> 的练习都很走心。今天做到 <a href="https://prod-edxapp.edx-cdn.org/assets/courseware/v1/063c6ec50fc9d2b0f6c8624843bfaf24/asset-v1:JuilliardX+JX001x+3T2017+type@asset+block/Mod3_PS.pdf" target="_blank" rel="noopener">Module 3 练习</a>，主要针对音符/休止符和拍子。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Mod3_AK_page_1.png" alt=""></p><p>为了在电脑上写作业，找了一款音乐符号的字体：<a href="http://www.fontspace.com/robert-allgeyer/musisync" target="_blank" rel="noopener">MusiSync font - FontSpace</a></p><p>Meter 的遗留问题：如何确定以什么音符为一拍？</p><h2 id="明日-To-do"><a href="#明日-To-do" class="headerlink" title="明日 To do"></a>明日 To do</h2><ul><li>p5.sound 的例子</li><li>Treble + Bass clef 组合练习</li><li>Music Theory 101 Module 4</li><li>知识大融通 ch12</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Summary&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于例子学习 p5.sound 库的几类对象和方法&lt;/li&gt;
&lt;li&gt;开始 Bass clef 低音谱号识谱练习(工具 Music Tutor App)&lt;/li&gt;
&lt;li&gt;Music Theory 101 的 &lt;a href=&quot;https://prod-edxapp.edx-cdn.org/assets/courseware/v1/063c6ec50fc9d2b0f6c8624843bfaf24/asset-v1:JuilliardX+JX001x+3T2017+type@asset+block/Mod3_PS.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Module 3 练习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;开始使用 workflowy 写学习 log (工具 &lt;a href=&quot;https://chrome.google.com/webstore/detail/workflowy-panel/nhmckiepjgggfmmdlklgalgphjaopidk&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;WorkFlowy Panel&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;知识大融通 ch11&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
      <category term="读书" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/%E8%AF%BB%E4%B9%A6/"/>
    
    
      <category term="Note" scheme="http://uegeek.com/tags/Note/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Learning" scheme="http://uegeek.com/tags/Learning/"/>
    
      <category term="Music" scheme="http://uegeek.com/tags/Music/"/>
    
  </entry>
  
  <entry>
    <title>DeepLearning 笔记：用 Python 实现反向传播算法</title>
    <link href="http://uegeek.com/180208-DeepLearning10-backpropagation-python.html"/>
    <id>http://uegeek.com/180208-DeepLearning10-backpropagation-python.html</id>
    <published>2018-02-08T14:37:55.000Z</published>
    <updated>2018-02-08T16:41:10.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p>用反向传播算法更新权重的算法如下：</p><ul><li>给每一层的权重赋值为 0<ul><li>输入层→隐层的权重 $\Delta w_{ij}=0$</li><li>隐层→输出层的权重 $\Delta W_j=0$<br>​</li></ul></li><li>对训练集里的每一个数据：<ul><li>使用 forward pass，计算输出节点的值 $\hat y$</li><li>计算输出节点的误差梯度 $\delta^o=(y-\hat y)f’(z)$，  这里的 $z=\sum_jW_ja_j$</li><li>将误差反向传递到隐层 $\delta^h_j=\delta^oW_jf’(h_j)$</li><li>更新权重步长<ul><li>$\Delta W_j = \Delta W_j + \delta^oa_j$</li><li>$\Delta w<em>{ij} = \Delta w</em>{ij} + \delta^h_ja_i$</li></ul></li></ul></li><li>更新权重（η 为学习率，m 为输入节点的个数):<ul><li>$W_j = W_j + \eta \Delta W_j /m$</li><li>$w<em>{ij} = w</em>{ij} + \eta \Delta w_{ij} /m$</li></ul></li><li>重复 e 次训练步骤 (epochs)</li></ul><p>在 python 中实现如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> data_prep <span class="keyword">import</span> features, targets, features_test, targets_test</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">21</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Calculate sigmoid</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyperparameters</span></span><br><span class="line">n_hidden = <span class="number">2</span>  <span class="comment"># number of hidden units</span></span><br><span class="line">epochs = <span class="number">900</span></span><br><span class="line">learnrate = <span class="number">0.005</span></span><br><span class="line"></span><br><span class="line">n_records, n_features = features.shape</span><br><span class="line">last_loss = <span class="keyword">None</span></span><br><span class="line"><span class="comment"># Initialize weights</span></span><br><span class="line">weights_input_hidden = np.random.normal(scale=<span class="number">1</span> / n_features ** <span class="number">.5</span>,</span><br><span class="line">                                        size=(n_features, n_hidden))</span><br><span class="line">weights_hidden_output = np.random.normal(scale=<span class="number">1</span> / n_features ** <span class="number">.5</span>,</span><br><span class="line">                                         size=n_hidden)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">    del_w_input_hidden = np.zeros(weights_input_hidden.shape)</span><br><span class="line">    del_w_hidden_output = np.zeros(weights_hidden_output.shape)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(features.values, targets):</span><br><span class="line"></span><br><span class="line">      <span class="comment">## Forward pass ##</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the output</span></span><br><span class="line">        hidden_input = np.dot(x, weights_input_hidden) <span class="comment"># x·w</span></span><br><span class="line">        hidden_output = sigmoid(hidden_input)</span><br><span class="line">        output = sigmoid(np.dot(hidden_output, weights_hidden_output))</span><br><span class="line"></span><br><span class="line">      <span class="comment">## Backward pass ##</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the network's prediction error</span></span><br><span class="line">        error = y - output</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate error term for the output unit</span></span><br><span class="line">        output_error_term = error * output * (<span class="number">1</span> - output)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## propagate errors to hidden layer</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the hidden layer's contribution to the error</span></span><br><span class="line">        hidden_error = np.dot(output_error_term, weights_hidden_output)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error term for the hidden layer</span></span><br><span class="line">        hidden_error_term = hidden_error * hidden_output * (<span class="number">1</span> - hidden_output)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update the change in weights</span></span><br><span class="line">        del_w_hidden_output += output_error_term * hidden_output</span><br><span class="line">        del_w_input_hidden += hidden_error_term * x[:,<span class="keyword">None</span>] <span class="comment"># x.T</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights</span></span><br><span class="line">    weights_input_hidden += learnrate * del_w_input_hidden / n_records</span><br><span class="line">    weights_hidden_output += learnrate * del_w_hidden_output / n_records</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Printing out the mean square error on the training set</span></span><br><span class="line">    <span class="keyword">if</span> e % (epochs / <span class="number">10</span>) == <span class="number">0</span>:</span><br><span class="line">        hidden_output = sigmoid(np.dot(x, weights_input_hidden))</span><br><span class="line">        out = sigmoid(np.dot(hidden_output,</span><br><span class="line">                             weights_hidden_output))</span><br><span class="line">        loss = np.mean((out - targets) ** <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> last_loss <span class="keyword">and</span> last_loss &lt; loss:</span><br><span class="line">            print(<span class="string">"Train loss: "</span>, loss, <span class="string">"  WARNING - Loss Increasing"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"Train loss: "</span>, loss)</span><br><span class="line">        last_loss = loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate accuracy on test data</span></span><br><span class="line">hidden = sigmoid(np.dot(features_test, weights_input_hidden))</span><br><span class="line">out = sigmoid(np.dot(hidden, weights_hidden_output))</span><br><span class="line">predictions = out &gt; <span class="number">0.5</span></span><br><span class="line">accuracy = np.mean(predictions == targets_test)</span><br><span class="line">print(<span class="string">"Prediction accuracy: &#123;:.3f&#125;"</span>.format(accuracy))</span><br></pre></td></tr></table></figure><p>你可能会感兴趣：</p><ul><li><a href="http://www.uegeek.com/180125-DeepLearning9-backpropagation.html" target="_blank" rel="noopener">DeepLearning笔记：Backpropagation 反向传播算法</a></li><li><a href="http://www.uegeek.com/180104DeepLearning8-MultiLayer-Perceptrons.html" target="_blank" rel="noopener">DeepLearning笔记：多节点神经网络</a></li><li><a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">DL笔记：用 python 实现梯度下降的算法</a></li><li><a href="http://www.uegeek.com/171222DLN6-GradientDescent.html" target="_blank" rel="noopener">DL笔记：梯度下降 Gradient Descent</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DL笔记：Cost function 损失函数</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DL笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="神经网络" scheme="http://uegeek.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="Backpro" scheme="http://uegeek.com/tags/Backpro/"/>
    
      <category term="反向传播" scheme="http://uegeek.com/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    
      <category term="Programming" scheme="http://uegeek.com/tags/Programming/"/>
    
  </entry>
  
  <entry>
    <title>DeepLearning笔记：Backpropagation 反向传播算法</title>
    <link href="http://uegeek.com/180125-DeepLearning9-backpropagation.html"/>
    <id>http://uegeek.com/180125-DeepLearning9-backpropagation.html</id>
    <published>2018-01-25T08:00:02.000Z</published>
    <updated>2018-01-25T08:10:30.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：今天我们来学习反向传播算法。</p><p><code>阿特</code>：为什么你一脸严肃哦？</p><p><code>阿扣</code>：咳咳，有吗……可能因为当初被 Backpropagation 这个词吓得不轻吧…… 反向传播算法是深度学习的核心之一，不过也没有很难，放轻松~</p><p><code>阿特</code>：你是说你还是说我 😄</p><p><code>阿扣</code>：来，我们先回忆一下，对多层神经网络，我们用梯度下降法去训练。之前已经学过如何计算输出节点的误差项 $\delta =(y-\hat y)f’(h)$，借助梯度下降算法，用误差项训练<strong>隐层到输出层的权重</strong>。</p><p><code>阿特</code>：隐层到输出层。我记得最简单的神经网络应该有 3 层——是不是还有输入层到隐层？</p><p><code>阿扣</code>：没错。</p><p><code>阿特</code>：那该怎么求隐层节点对应的误差项呢？</p><p><code>阿扣</code>：在神经网络里，输出节点的误差项，跟隐层的权重是成比例的。</p><p><code>阿特</code>：意思是误差项越大，隐层节点的权重也越大？</p><p><code>阿扣</code>：可以这么理解。既然我们知道输出的误差项，就可以用它来「反向传播」，求出隐层的误差项，再用于求输入节点的权重。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/vlcsnap-2017-12-19-15h02m16s033.png" alt=""></p><p><code>阿特</code>：咦，那不是反过来了？先知道输出结果，再反推输入权重？</p><p><code>阿扣</code>：对的，所以叫做「反向」呀。</p><p>比如，输出层 k 个节点对应的误差项是 $\delta^o_k$ 。隐层有 j 个节点，那么隐层节点到输出节点的 j 个误差项是：</p><p>$\delta^h<em>j=\sum W</em>{jk} \delta^o_k f’(h_j)$</p><p><code>阿特</code>：等等！先让我复习一下误差项是什么……</p><p><code>阿扣</code>：嗯！误差项 δ 表示 <code>误差 * 激活函数的导数</code>，$\delta_j=(y-\hat y)f’(h_j)$。对比一下 $\delta^h<em>j=\sum W</em>{jk} \delta^o_k f’(h_j)$，看看有什么不同？</p><p><code>阿特</code>：隐层到输出层的误差 (y-y^) 变成了 $\sum W_{jk} \delta^o_k$</p><p><code>阿扣</code>：很棒！你发现了吧，$\delta_k$ 成为了 wx + b 中的变量 x：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/vlcsnap-2017-12-19-15h06m32s756.png" alt=""></p><p><code>阿特</code>：啊，又要来算这个了……</p><p><code>阿扣</code>：没关系，虽然看上去麻烦一些，但是跟正向传播的做法很类似，权重的更新为 $\Delta w_{ij}=\eta \delta^h_jx_i$ 。</p><p><code>阿特</code>：每次都要来一遍，要死不少脑细胞啊……</p><p><code>阿扣</code>：那我给你列个清单吧，每次照着做就好。</p><p>假设我们考虑最简单的神经网络：只有一个隐层节点，只有一个输出节点。用反向传播算法更新权重的算法如下：</p><ul><li>给每一层的权重赋值为 0<ul><li>输入层→隐层的权重 $\Delta w_{ij}=0$</li><li>隐层→输出层的权重 $\Delta W_j=0$<br>​</li></ul></li><li>对训练集里的每一个数据：<ul><li>使用 forward pass，计算输出节点的值 $\hat y$</li><li>计算输出节点的误差梯度 $\delta^o=(y-\hat y)f’(z)$，  这里的 $z=\sum_jW_ja_j$</li><li>将误差反向传递到隐层 $\delta^h_j=\delta^oW_jf’(h_j)$</li><li>更新权重步长<ul><li>$\Delta W_j = \Delta W_j + \delta^oa_j$</li><li>$\Delta w<em>{ij} = \Delta w</em>{ij} + \delta^h_ja_i$</li></ul></li></ul></li><li>更新权重（η 为学习率，m 为输入节点的个数):<ul><li>$W_j = W_j + \eta \Delta W_j /m$</li><li>$w<em>{ij} = w</em>{ij} + \eta \Delta w_{ij} /m$</li></ul></li><li>重复 e 次训练步骤 (epochs)</li></ul><p><code>阿特</code>：天！看上去好复杂。</p><p><code>阿扣</code>：练习两次就能熟悉起来了，别担心。下一次我带你用 Python 实现反向传播算法。</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101" target="_blank" rel="noopener">Deep Learning Nanodegree | Udacity</a></li><li><a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" target="_blank" rel="noopener">Yes you should understand backprop – Medium</a></li><li><a href="https://www.youtube.com/watch?v=59Hbtz7XgjM" target="_blank" rel="noopener">CS231n Winter 2016 Lecture 4 Backpropagation, Neural Networks 1-Q_UWHTY_TEQ.mp4 - YouTube</a></li></ul><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DeepLearning笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DeepLearning笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DeepLearning笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DeepLearning笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DeepLearning笔记：Cost function 损失函数</a></li><li><a href="http://www.uegeek.com/171222DLN6-GradientDescent.html" target="_blank" rel="noopener">DeepLearning笔记：梯度下降 Gradient Descent</a></li><li><a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">DeepLearning笔记：用 python 实现梯度下降的算法</a></li><li><a href="http://www.uegeek.com/180104DeepLearning8-MultiLayer-Perceptrons.html" target="_blank" rel="noopener">DeepLearning笔记：多节点神经网络</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="神经网络" scheme="http://uegeek.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Backpro" scheme="http://uegeek.com/tags/Backpro/"/>
    
      <category term="反向传播" scheme="http://uegeek.com/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    
  </entry>
  
  <entry>
    <title>码以致用03 - 用 Pandas 分析爬虫抓取的数据</title>
    <link href="http://uegeek.com/180118-python-pandas-data-analysis.html"/>
    <id>http://uegeek.com/180118-python-pandas-data-analysis.html</id>
    <published>2018-01-18T09:04:46.000Z</published>
    <updated>2018-01-18T09:10:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg" alt=""></p><a id="more"></a> <p>上一篇，我们<a href="http://www.uegeek.com/180112python-scrapy-jdxl.html" target="_blank" rel="noopener">用 Scrapy 从简单心理网站上抓取了心理咨询师的信息</a>。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapyOutput.png" alt=""></p><p>接下来试着分析一下咨询师的价格。</p><h3 id="如何去掉某一列中不需要的字符？"><a href="#如何去掉某一列中不需要的字符？" class="headerlink" title="如何去掉某一列中不需要的字符？"></a>如何去掉某一列中不需要的字符？</h3><p>在 <code>price</code> 列中，数据格式是 <code>600 元/次</code>。很明显，中文字符会给统计价格带来不便，需要想办法去掉。</p><ul><li>取 <code>price</code> 列：<code>df[&#39;name&#39;]</code></li><li>去掉<code>元/次</code> 字符：<code>str.rstrip()</code></li><li>把剩下字符转换成数字：<code>pd.to_numeric</code></li></ul><p>Pandas 语句可以这样写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'price'</span>].str.rstrip(<span class="string">'元/次'</span>).apply(pd.to_numeric)</span><br></pre></td></tr></table></figure><p>结果：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-01-18%20at%203.53.32%20PM.png" alt=""></p><h3 id="如何统计价格？"><a href="#如何统计价格？" class="headerlink" title="如何统计价格？"></a>如何统计价格？</h3><p>用 Pandas 做基本的数据统计如均值、最大值、最小值等，非常方便，分别用 <code>mean()</code>, <code>max()</code>, <code>min()</code>就可以：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"平均价格：&#123;:.1f&#125;元 \n最高价格：&#123;&#125;元 \n最低价格：&#123;&#125;元"</span>.format(df[<span class="string">'price'</span>].mean(),df[<span class="string">'price'</span>].max(),df[<span class="string">'price'</span>].min()))</span><br></pre></td></tr></table></figure><ul><li>平均价格：570.9元 </li><li>最高价格：3000元 </li><li>最低价格：100元</li></ul><p>另外，Pandas 还提供了 <code>describe()</code> 函数，快速给出概要统计值：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-01-18%20at%203.57.36%20PM.png" alt=""></p><p>然后单独取出收费最高和最低的咨询师资料：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.loc[df[<span class="string">'price'</span>].idxmax()]</span><br><span class="line">df.loc[df[<span class="string">'price'</span>].idxmin()]</span><br></pre></td></tr></table></figure><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-01-18%20at%203.58.52%20PM.png" alt=""></p><h3 id="如何统计咨询师介绍里的词频？"><a href="#如何统计咨询师介绍里的词频？" class="headerlink" title="如何统计咨询师介绍里的词频？"></a>如何统计咨询师介绍里的词频？</h3><p><strong>方法 1 ：用 jieba 分词，用 Counter 统计</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单独导出咨询师介绍列</span></span><br><span class="line">df[<span class="string">'info'</span>].to_csv(<span class="string">'info.txt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'info.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line"></span><br><span class="line">wordlist = Counter()</span><br><span class="line">words = jieba.cut(text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    <span class="keyword">if</span> len(word) &gt; <span class="number">1</span>: </span><br><span class="line">        wordlist[word] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_cloud_word</span><span class="params">()</span>:</span></span><br><span class="line">    words = []</span><br><span class="line">    <span class="keyword">for</span> word,cnt <span class="keyword">in</span> wordlist.most_common(<span class="number">30</span>):</span><br><span class="line">        words.append(word)</span><br><span class="line">    <span class="keyword">return</span> words</span><br></pre></td></tr></table></figure><p>列出前 30 个高频词：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-01-18%20at%204.10.14%20PM.png" alt=""></p><p><strong>方法 2 ：用 wordcloud 直接制作标签云</strong></p><p>word cloud 是一个 python 的标签云生成库，可以直接输入文本，得到标签云图片，还可以定制图片形状和颜色，小巧好用。(<a href="https://github.com/amueller/word_cloud" target="_blank" rel="noopener">https://github.com/amueller/word_cloud</a>)</p><p>结合 matplotlib，很快就可以画出高频词的标签云：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format=<span class="string">'retina'</span></span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud, ImageColorGenerator</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">d = path.dirname(<span class="string">'info.txt'</span>)</span><br><span class="line"><span class="comment"># 设置字体</span></span><br><span class="line">font = <span class="string">r'/Users/kidult/Library/Fonts/MFKeSong_Noncommercial-Regular.TTF'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read the whole text</span></span><br><span class="line">text = open(path.join(d, <span class="string">'info.txt'</span>)).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 排除词</span></span><br><span class="line">stopwords=(<span class="string">'Dr'</span>,<span class="string">'of'</span>,<span class="string">'to'</span>,<span class="string">'and'</span>,<span class="string">'The'</span>,<span class="string">'in'</span>,<span class="string">'zx'</span>,<span class="string">'至今'</span>,<span class="string">'中国'</span>,<span class="string">'同时'</span>,<span class="string">'当然'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用图片截取并取色</span></span><br><span class="line">heart_coloring = np.array(Image.open(path.join(d, <span class="string">"heart.png"</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate a word cloud image</span></span><br><span class="line">wordcloud = WordCloud(max_words=<span class="number">80</span>, background_color=<span class="string">'white'</span>, mask=heart_coloring,</span><br><span class="line">                      max_font_size=<span class="number">60</span>, relative_scaling=<span class="number">0.4</span>, font_path=font,stopwords=stopwords, random_state=<span class="number">42</span>)</span><br><span class="line">wordcloud.generate(text)</span><br><span class="line"></span><br><span class="line">image_colors = ImageColorGenerator(heart_coloring)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line">plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=<span class="string">"bilinear"</span>);</span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxl-wordcloud.png" alt=""></p><p>完整的 Jupyter Notebook，请查看 <a href="https://github.com/kidult00/scrapy-jdxl/blob/master/jdxl/output/jdxl_experts_analysis.ipynb" target="_blank" rel="noopener">00 的 Github</a>。</p><iframe src="http://nbviewer.jupyter.org/github/kidult00/scrapy-jdxl/blob/master/jdxl/output/jdxl_experts_analysis.ipynb" width="780" height="500"></iframe><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="http://blog.csdn.net/weixin_37226516/article/details/64134643" target="_blank" rel="noopener">PANDAS 数据合并与重塑（concat篇） - CSDN博客</a></li><li><a href="http://blog.csdn.net/u010770993/article/details/70312506" target="_blank" rel="noopener">初学pandas（八）条件选取行的便捷… - CSDN博客</a></li><li><a href="http://blog.csdn.net/zhili8866/article/details/68134481" target="_blank" rel="noopener">pandas数据清洗，排序，索引设置，数据选取 - CSDN博客</a></li><li><a href="https://github.com/amueller/word_cloud" target="_blank" rel="noopener">amueller/word_cloud: A little word cloud generator in Python</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="爬虫" scheme="http://uegeek.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="http://uegeek.com/tags/Scrapy/"/>
    
      <category term="Pandas" scheme="http://uegeek.com/tags/Pandas/"/>
    
      <category term="数据分析" scheme="http://uegeek.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>大哉问06 - 学习中最应该养成什么习惯？</title>
    <link href="http://uegeek.com/180113-first-principle-of-learning.html"/>
    <id>http://uegeek.com/180113-first-principle-of-learning.html</id>
    <published>2018-01-13T11:35:45.000Z</published>
    <updated>2018-01-13T11:43:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇大哉问我们讨论了这个问题：<a href="http://www.uegeek.com/180106-the-learning-myth.html" target="_blank" rel="noopener">什么是学习中最大的误区？</a></p><blockquote><p>以为学习的行动，就是学习本身</p></blockquote><p>学习是以改变为目的的一系列探索活动。如果改变没有发生，没有形成新的视角或行动或规则，那么学习基本上可以说无效。</p><p>明确了应该避开「不改变」这个误区，那么下一个大问题来了：</p><blockquote><p>什么是学习中最应该养成的习惯？</p></blockquote><p>00 思考了很久，目前的回答是：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HabitOfStudy.png" alt=""></p><a id="more"></a> <h2 id="学习是一种训练"><a href="#学习是一种训练" class="headerlink" title="学习是一种训练"></a>学习是一种训练</h2><p>学习不是看书、做实验这些行为本身，<strong>学习是围绕目标和薄弱点的「训练」，它们指向思想或行动的改变。</strong></p><p>学习不是孤立的阅读、孤立的理解、孤立的运用，一个学习的「迭代」包括：</p><blockquote><p>设定目标 - 模块拆解 - 刻意练习 - 评估调整</p></blockquote><p>完整的学习由很多个迭代循环构成，迭代的结果是行为改变。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/rethinkingLearning.png" alt=""></p><h2 id="向机器学习「学习」"><a href="#向机器学习「学习」" class="headerlink" title="向机器学习「学习」"></a>向机器学习「学习」</h2><p>最近在学习机器学习和深度学习。机器如何学习给我非常多启发。</p><p>机器的学习为什么高效？除了它计算能力超强、根本不会疲劳以外，它们学习的方法——所谓算法——都是最聪明的人类精心设计的。</p><p>深度学习的基本思路是：</p><ul><li>设定目标 Y</li><li>找到真实数据集（包含自变量 x 和输出值 y）</li><li>给出初始模型，喂入真实数据集</li><li>观察模型输出的损失（目标 Y 和实际值 y 的差值）</li><li>调整模型参数，使损失函数最小</li><li>（重复循环）</li><li>达到目标 Y ，停止训练</li></ul><p><img src="https://viniciusarruda.github.io/images/mp_neuron.png" alt=""></p><p><img src="https://cdn-images-1.medium.com/max/880/1*fbMYoMRFR_Mr8tNoFI0_Jw.jpeg" alt=""></p><p>再打开「刻意练习」这本书复习一下。</p><p>刻意练习聚焦于提高绩效和表现，它的特点：</p><ul><li>有定义明确的特定目标</li><li>专注的</li><li>包含反馈</li><li>需要走出舒适区</li><li>产生有效的心理表征</li><li>构建或修改那些过去已经获得的技能</li></ul><p>See? 机器学习完全遵守了这些规则，能不高效吗？！</p><h2 id="GEXTE-：学习循环的模板"><a href="#GEXTE-：学习循环的模板" class="headerlink" title="GEXTE ：学习循环的模板"></a>GEXTE ：学习循环的模板</h2><p>事不宜迟，在我们下一个学习计划，启用 00 为你准备的「GEXTE 学习循环模板」吧！</p><p>在定义一个学习项目时，我们需要把学习的循环拆分成几个部分：</p><p><strong>目标是什么？怎么评估做到了？可以拆分为哪些训练模块？模仿什么？训练步骤是？</strong></p><table><thead><tr><th>代号</th><th>循环项</th><th>定义</th><th>每次循环时</th></tr></thead><tbody><tr><td>G</td><td>目标 / Goal</td><td>明确可描述的目标，从现状 A 到终点 B</td><td>回顾目标</td></tr><tr><td>E</td><td>评估方法 / Error</td><td>如何评估是否达成目标</td><td>获得反馈</td></tr><tr><td>X</td><td>技能模块 / X</td><td>影响 Error 的模块、技能点</td><td>检查是否有遗漏</td></tr><tr><td>T</td><td>模仿对象 / Target</td><td>具体的模仿对象和结果</td><td>比较的结果差别</td></tr><tr><td>E</td><td>单次训练 / Epoch</td><td>每一次训练要做什么</td><td>调整行动或目标</td></tr></tbody></table><p>可打印的模板也做好了。HackYourself 公众号回复 「学习模板」即可获得：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/GEXTE_Template.png" alt=""></p><p>看吧，学习是远比我们想象要复杂但也更有趣的挑战。不妨在每个循环后面，增加一些奖励来激励自己。</p><p>虽然正儿八经地学个什么颇费力，但总比数十年喊着口号却原地打转强得多，是不是？</p><p>下面来看两个例子：编程学习和产品决策能力训练。</p><h2 id="栗子1：学习用-Processing-模拟自然现象"><a href="#栗子1：学习用-Processing-模拟自然现象" class="headerlink" title="栗子1：学习用 Processing 模拟自然现象"></a>栗子1：学习用 Processing 模拟自然现象</h2><p>Processing 是基于 Java 的一套编程语言和环境，有很强的图形、动画生成能力，被称为「设计师的编程语言」。现在我们就来尝试用 GEXTE 模板定义完整的学习循环。</p><h3 id="G-目标"><a href="#G-目标" class="headerlink" title="G 目标"></a>G 目标</h3><blockquote><p>目标1：学习如何用代码可视化表达随机性、力与运动、震荡、粒子、分形等自然现象</p></blockquote><p>现状 A</p><ul><li>不了解模拟自然现象的算法</li><li>不知道如何用 Processing 实现</li></ul><p>终点 B</p><ul><li>能用基础的公式表示自然现象背后的数学和物理原理</li><li>用 Processing 实现动画程序</li></ul><blockquote><p>目标2：练习巩固 Python 语法</p></blockquote><p>现状 A</p><ul><li>会基本的 Python 语法</li><li>能看懂简单的 Java 程序</li></ul><p>终点 B：用 Python 实现 Processing 动画程序</p><h3 id="E-评估"><a href="#E-评估" class="headerlink" title="E 评估"></a>E 评估</h3><p>用 processing.py 实现模拟自然现象的动画程序</p><ul><li>程序运行结果是否如预期</li><li>抄程序：Java 没问题但 Python 有问题的地方，是需要加强的薄弱点</li><li>重写程序<ul><li>是否理解原理</li><li>是否理解 Processing 如何实现</li><li>是否理清实现的思路</li></ul></li></ul><h3 id="X-模块"><a href="#X-模块" class="headerlink" title="X 模块"></a>X 模块</h3><ul><li>自然现象的原理</li><li>Processing 语法和模块</li><li>Python 语法</li><li>debug 方法</li></ul><h3 id="T-对象"><a href="#T-对象" class="headerlink" title="T 对象"></a>T 对象</h3><p>「The Nature of Code」配套视频和例子</p><h3 id="E-训练"><a href="#E-训练" class="headerlink" title="E 训练"></a>E 训练</h3><ul><li>看 youtube 视频和书，学习自然现象的原理</li><li>看 Java 代码</li><li>用 Python 抄一遍</li><li>用 Python 自己写一遍</li><li>填写训练反馈</li><li>完成 9 个单元，把所有例子翻译成 python 版本</li></ul><h3 id="Bonus"><a href="#Bonus" class="headerlink" title="Bonus"></a>Bonus</h3><ul><li>上传 NOC python version 到 Github</li><li>每一章实现一个有意思的小动画</li></ul><p>上面这个例子可能比较特殊，因为学习对象是界定非常明确的编程练习，学习产出也容易评估。</p><p>下面再举一个不太容易定义的例子。</p><h2 id="栗子2：产品决策能力训练"><a href="#栗子2：产品决策能力训练" class="headerlink" title="栗子2：产品决策能力训练"></a>栗子2：产品决策能力训练</h2><h3 id="G-目标-1"><a href="#G-目标-1" class="headerlink" title="G 目标"></a>G 目标</h3><p>提升决策的质量并优化决策的流程</p><h3 id="E-评估-1"><a href="#E-评估-1" class="headerlink" title="E 评估"></a>E 评估</h3><p>决策是否达到预期目标</p><h3 id="X-模块-1"><a href="#X-模块-1" class="headerlink" title="X 模块"></a>X 模块</h3><ul><li>逻辑思维、抽象、演绎、分析、综合等能力</li><li>决策信息的收集</li><li>提炼、表达和沟通能力</li><li>决策落地</li><li>评估标准制定和信息收集</li></ul><h3 id="T-对象-1"><a href="#T-对象-1" class="headerlink" title="T 对象"></a>T 对象</h3><ul><li>自己的决策：拥有最全面的信息，方便评估</li><li>上级/团队的决策：观察、评估上级或团队的决策，也是绝佳的练习机会</li></ul><h3 id="E-训练-1"><a href="#E-训练-1" class="headerlink" title="E 训练"></a>E 训练</h3><ul><li>决策问题产生和定义</li><li>情报收集和分析</li><li>决策制定和描述</li><li>推进和项目组织</li><li>结果评估</li><li>决策方法总结</li></ul><p>每一步可能还有很多细分的练习模块，这里就不具体展开，产品同学们开启脑洞吧。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HabitOfStudy.png" alt=""></p><p>打造有效的学习循环很难，几乎就像是打造一个产品循环。</p><p>这也就是为什么学习容易成为西西弗斯式壮（xiao）举（hua）的原因。因为富有成效的学习，太不符合大脑喜欢最短路径的构造，所以我们总是自欺自人。</p><p>但总有一些奖赏，要在经历之后才深明其义。</p><blockquote><p>One of the first rules of science is if somebody delivers a secret weapon to you, you better use it. — Herbert Simon</p></blockquote><hr><p>HackYourself 学习专题：</p><ul><li><a href="http://www.uegeek.com/180106-the-learning-myth.html" target="_blank" rel="noopener">大哉问05 - 什么是学习中最大的误区？</a></li><li><a href="http://www.uegeek.com/learning-about-learn.html" target="_blank" rel="noopener">重启学习系统，做个知识炼金术士</a></li><li><a href="http://www.uegeek.com/learning-guide-v1.html" target="_blank" rel="noopener">知识炼金术士行动指南 1.0</a></li><li><a href="http://www.uegeek.com/mindlego1.html" target="_blank" rel="noopener">心智乐高01 - 寻找智慧组块</a></li><li><a href="http://www.uegeek.com/effective-learning.html" target="_blank" rel="noopener">别傻了，傲娇大脑爱学习？</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇大哉问我们讨论了这个问题：&lt;a href=&quot;http://www.uegeek.com/180106-the-learning-myth.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;什么是学习中最大的误区？&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;以为学习的行动，就是学习本身&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;学习是以改变为目的的一系列探索活动。如果改变没有发生，没有形成新的视角或行动或规则，那么学习基本上可以说无效。&lt;/p&gt;
&lt;p&gt;明确了应该避开「不改变」这个误区，那么下一个大问题来了：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;什么是学习中最应该养成的习惯？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;00 思考了很久，目前的回答是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/HabitOfStudy.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="学习" scheme="http://uegeek.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="方法" scheme="http://uegeek.com/tags/%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>码以致用02 - 用 Scrapy 爬虫抓取简单心理咨询师资料</title>
    <link href="http://uegeek.com/180112python-scrapy-jdxl.html"/>
    <id>http://uegeek.com/180112python-scrapy-jdxl.html</id>
    <published>2018-01-12T11:33:34.000Z</published>
    <updated>2018-01-12T11:41:02.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg" alt=""></p><a id="more"></a> <h2 id="目标和步骤"><a href="#目标和步骤" class="headerlink" title="目标和步骤"></a>目标和步骤</h2><p>爬虫目标：从简单心理网站上抓取心理咨询师列表和信息。</p><p>学习目标：</p><ul><li>熟悉 Scrapy 框架，理解如何使用</li><li>初步掌握 xpath 语法</li><li>导出爬取信息为 csv</li><li>用 Pandas 查看和清理数据</li></ul><p><a href="http://jiandanxinli.com" target="_blank" rel="noopener">简单心理网站</a>上有「咨询咨询」和「精神科顾问」两类专家，这里先尝试抓取咨询师资料。</p><p>咨询师展示列表比较简单，一共有 49 页，每页有 10 或 11 个咨询师（真是有点坑……）。抓取每页上的信息即可。</p><p>步骤分解：</p><ul><li>抓取每一页上面所有咨询师的信息，包括姓名、简介、地点、咨询方式、地点、价格等</li><li>按页面顺序抓取全部咨询师资料</li><li>导出信息为 csv</li><li>用 pandas 查看信息</li></ul><h2 id="新建项目和爬虫"><a href="#新建项目和爬虫" class="headerlink" title="新建项目和爬虫"></a>新建项目和爬虫</h2><p><a href="http://www.uegeek.com/180108python-scrapy-introduction.html" target="_blank" rel="noopener">上一篇</a>已经介绍过 Scrapy 爬虫框架和如何新建 Python 虚拟环境。现在来新建一个 Scrapy 爬虫项目：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject jdxl</span><br></pre></td></tr></table></figure><p>Scrapy 生成了以下文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">├── jdxl</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       └── __init__.py</span><br><span class="line">└── scrapy.cfg</span><br></pre></td></tr></table></figure><p>我们在 <code>spiders</code> 文件夹里新建爬虫文件 <code>counselor.py</code>。</p><p>然后在 <code>items.py</code> 里面定义要抓取的项目：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JdxlItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    name = scrapy.Field() <span class="comment">#姓名</span></span><br><span class="line">    url = scrapy.Field() <span class="comment">#链接</span></span><br><span class="line">    info = scrapy.Field() <span class="comment">#简介</span></span><br><span class="line">    zx_type = scrapy.Field() <span class="comment">#咨询类型</span></span><br><span class="line">    location = scrapy.Field() <span class="comment">#地点</span></span><br><span class="line">    price = scrapy.Field() <span class="comment">#价格</span></span><br></pre></td></tr></table></figure><h2 id="抓取页面信息"><a href="#抓取页面信息" class="headerlink" title="抓取页面信息"></a>抓取页面信息</h2><p>打开爬虫 <code>counselor.py</code>，开始写爬取的程序。</p><p>不要忘记先 import 上面定义好对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> jdxl.items <span class="keyword">import</span> JdxlItem</span><br></pre></td></tr></table></figure><h3 id="问题1：如何设置起始-URL？"><a href="#问题1：如何设置起始-URL？" class="headerlink" title="问题1：如何设置起始 URL？"></a>问题1：如何设置起始 URL？</h3><p>打开<a href="https://www.jiandanxinli.com/experts" target="_blank" rel="noopener">心理咨询师列表页面</a>，然后翻到第二页，发现 url 是很长的一串：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.jiandanxinli.com/experts?filter%5Bcity_id%5D=&amp;filter%5Bfield_id%5D=&amp;filter%5Bgender%5D=&amp;filter%5Bonly_available%5D=&amp;filter%5Bonly_junior%5D=&amp;filter%5Bonly_online%5D=&amp;filter%5Bprice%5D=&amp;filter%5Bq%5D=&amp;filter%5Bsect_id%5D=&amp;filter%5Btarget_id%5D=&amp;filter%5Btime%5D=&amp;filter%5Btype_id%5D=&amp;page=2</span><br></pre></td></tr></table></figure><p>中间都是传递的筛选参数，只有最后 <code>&amp;page=2</code> 才是关键。也就是说抓取的页面URL是这样的：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">https://www.jiandanxinli.com/experts?&amp;page=1</span><br><span class="line">https://www.jiandanxinli.com/experts?&amp;page=2</span><br><span class="line">...</span><br><span class="line">https://www.jiandanxinli.com/experts?&amp;page=49</span><br></pre></td></tr></table></figure><p>在 <code>class JdxlSpider(scrapy.Spider):</code> 下面开始定义起始 URL：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">allowed_domains = [<span class="string">"jiandanxinli.com"</span>]</span><br><span class="line">   start_urls = [<span class="string">'http://jiandanxinli.com/experts'</span>]</span><br><span class="line">   start_url_list = []</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">50</span>):</span><br><span class="line">       start_url_list.extend([<span class="string">'http://jiandanxinli.com/experts?&amp;page='</span> + str(i)])</span><br><span class="line"></span><br><span class="line">   start_urls = start_url_list</span><br></pre></td></tr></table></figure><h3 id="问题2：如何抓取一个节点的信息"><a href="#问题2：如何抓取一个节点的信息" class="headerlink" title="问题2：如何抓取一个节点的信息"></a>问题2：如何抓取一个节点的信息</h3><p>在 <code>def parse(self, response):</code> 函数中定义要抓取内容，用 <a href="https://www.wikiwand.com/en/XPath" target="_blank" rel="noopener">XPath</a> 语法告诉爬虫要抓取的节点位置。</p><p>什么是「叉怕死」呢？</p><blockquote><p>XPath (XML Path Language) is a query language for selecting nodes from an XML document. In addition, XPath may be used to compute values (e.g., strings, numbers, or Boolean values) from the content of an XML document. —— Wiki</p></blockquote><p>那怎么写 XPath 呢？</p><p>感谢 Chrome，直接提供了 XPath 选取功能。对需要抓取的位置单击右键，点击 <code>Inspect</code>，打开 chrome-devtools 面板：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapy1.png" alt=""></p><p>对准要抓取的节点，再次右键，点击 <code>Copy XPath</code>，XPath 路径就复制好了。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapy2.png" alt=""></p><p>别高兴得太早，在调试坑里跌倒无数次的 00 颤抖地告诉你：<strong>直接复制的 XPath 往往不能直接用……</strong></p><p>比如上面的咨询师姓名这里，chrome 提供的路径是：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//*[@id="content_wrapper"]/div[2]/div[2]/a[5]/div[1]/strong/text()</span><br></pre></td></tr></table></figure><p>但更准确的路径是：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/div[@class="summary"]/strong/text()</span><br></pre></td></tr></table></figure><p>.</p><p>对初学者来说，如果之前没有太多写 html 和 css 的经验，每一个 xpath 都需要摸索好半天。不过这也是必经之路吧。折腾多了，就学会老老实实去看 <a href="https://www.w3schools.com/xml/xpath_intro.asp" target="_blank" rel="noopener">XPath 的文档</a>了。</p><h3 id="问题3：内容没有节点怎么办？"><a href="#问题3：内容没有节点怎么办？" class="headerlink" title="问题3：内容没有节点怎么办？"></a>问题3：内容没有节点怎么办？</h3><p>抓到咨询师的咨询方式、地点、价格等信息的时候，坑爹的事情来了。</p><p>这一坨的结构是：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapy3.png" alt=""></p><p>文字竟然没有包括在标签之内！前后都是个 i 标签！要怎么抓！</p><p>然后开始了漫漫 Google 之路。最后终于找到了这篇：<a href="https://www.zhihu.com/question/38080188" target="_blank" rel="noopener">如何用scrapy提取不在标签内的文字？</a></p><p>用 <code>following::text()</code> 的方式抓取了几个信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zx_type = response.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">1</span>]</span><br><span class="line">location = response.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">2</span>]</span><br><span class="line">price = response.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>这样必需是每一栏信息都没有缺少，否则抓取就会错位……暂时这么处理吧 &gt;.&lt;</p><h3 id="问题4：如何抓取多个专家信息"><a href="#问题4：如何抓取多个专家信息" class="headerlink" title="问题4：如何抓取多个专家信息"></a>问题4：如何抓取多个专家信息</h3><p>抓取好一个专家的信息后，要怎么把每个页面 10~11 个专家的信息都抓下来呢？看了页面的 html，每个专家都在 <code>&lt;a class=&quot;expert&quot; ...&gt;</code> 标签下面。于是用循环获取所有带有这个特征的标签。</p><p>为了缩小范围，在 <code>response.xpath(&#39;//a[@class=&quot;expert&quot;]&#39;)</code> 就传入了父节点的路径。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> response.xpath(<span class="string">'//a[@class="expert"]'</span>):</span><br><span class="line">    print(each)</span><br><span class="line">    item = JdxlItem()</span><br><span class="line">    <span class="comment"># 抓取姓名</span></span><br><span class="line">    item[<span class="string">'name'</span>] = each.xpath(<span class="string">'./div[@class="summary"]/strong/text()'</span>).extract()</span><br><span class="line">    <span class="comment"># 抓取 url</span></span><br><span class="line">    item[<span class="string">'url'</span>] = each.xpath(<span class="string">'./@href'</span>).extract()</span><br><span class="line">    <span class="comment"># 抓取简介</span></span><br><span class="line">    item[<span class="string">'info'</span>] = each.xpath(<span class="string">'./div[@class="summary"]//div[@class="content"]/text()'</span>).extract()</span><br><span class="line">    <span class="comment"># 抓取咨询方式、地点、价格等</span></span><br><span class="line">    item[<span class="string">'zx_type'</span>] = each.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">1</span>]</span><br><span class="line">    item[<span class="string">'location'</span>] = each.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">2</span>]</span><br><span class="line">    item[<span class="string">'price'</span>] = each.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><h2 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h2><p>在 <code>settings.py</code> 文件里添加模拟 user_agent 的模块（需要先 pip 安装 faker 包）、设置爬取间隔、头信息等：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> faker <span class="keyword">import</span> Factory</span><br><span class="line">f = Factory.create()</span><br><span class="line">USER_AGENT = f.user_agent()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">DOWNLOAD_DELAY = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'www.jiandanxinli.com'</span>,</span><br><span class="line">    <span class="string">'Accept'</span>: <span class="string">'*/*'</span>,</span><br><span class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8'</span>,</span><br><span class="line">    <span class="string">'Cache-Control'</span>: <span class="string">'no-cache'</span>,</span><br><span class="line">    <span class="string">'Connection'</span>: <span class="string">'Keep-Alive'</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="测试和抓取"><a href="#测试和抓取" class="headerlink" title="测试和抓取"></a>测试和抓取</h2><p>开始抓取的命令是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl counselor</span><br></pre></td></tr></table></figure><p>crawl 后面跟的是在 <code>class JdxlSpider(scrapy.Spider):</code> 中定义的爬虫名字。</p><p>先抓取 2 页试试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">3</span>):</span><br><span class="line">        start_url_list.extend([<span class="string">'http://jiandanxinli.com/experts?&amp;page='</span> + str(i)])</span><br></pre></td></tr></table></figure><p>调试过程主要问题是节点的 xpath 提供得不准确，没有抓取到内容。另外就是可能忘记在 <code>items.py</code> 里面设置 item。一般来说，根据报错慢慢找，总能找出问题，耐心一些就是了。</p><h2 id="输出-csv"><a href="#输出-csv" class="headerlink" title="输出 csv"></a>输出 csv</h2><p>查看了官方文档里面有关输出的部分 <a href="https://doc.scrapy.org/en/latest/topics/feed-exports.html" target="_blank" rel="noopener">Feed exports — Scrapy 1.4.0 documentation</a> 和 <a href="https://doc.scrapy.org/en/latest/topics/exporters.html" target="_blank" rel="noopener">Item Exporters — Scrapy 1.4.0 documentation</a>，试了一下写 pipelines，有点复杂，没有成功。</p><p>然后搜到 <a href="https://zhuanlan.zhihu.com/p/24769534" target="_blank" rel="noopener">Scrapy爬虫框架教程（二）– 爬取豆瓣电影TOP250</a>，只需要在执行爬虫时设置输出参数就可以了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl counselor -o output_file.csv</span><br></pre></td></tr></table></figure><h2 id="查看、清理数据"><a href="#查看、清理数据" class="headerlink" title="查看、清理数据"></a>查看、清理数据</h2><p>新建 Jupyter Notebook，import pandas 包，用 <code>pd.read_csv</code> 命令查看文件：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapyOutput.png" alt=""></p><p>抓取的链接不完整，补全并输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'url'</span>] = <span class="string">'http://jiandanxinli.com'</span>+df[<span class="string">'url'</span>]</span><br><span class="line">df.to_csv(<span class="string">'counselor.csv'</span>, index=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><p>下一篇继续介绍用 Pandas 和 Bokeh 做简单的数据统计和可视化。</p><p>项目源码请查看 <a href="https://github.com/kidult00/scrapy-jdxl" target="_blank" rel="noopener">00 的 github repo</a>：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/scrapy-jdxl-repo-qr.png" alt=""> </p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://doc.scrapy.org/en/latest/" target="_blank" rel="noopener">Scrapy 1.5 documentation</a></li><li><a href="https://www.wikiwand.com/en/XPath" target="_blank" rel="noopener">XPath - Wikiwand</a></li><li><a href="https://www.w3schools.com/xml/xpath_intro.asp" target="_blank" rel="noopener">XPath Tutorial</a></li><li><a href="https://www.zhihu.com/question/38080188" target="_blank" rel="noopener">如何用scrapy提取不在标签内的文字？</a></li><li><a href="https://zhuanlan.zhihu.com/p/24769534" target="_blank" rel="noopener">Scrapy爬虫框架教程（二）– 爬取豆瓣电影TOP250</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="爬虫" scheme="http://uegeek.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="http://uegeek.com/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>码以致用01 - Scrapy 爬虫框架简介</title>
    <link href="http://uegeek.com/180108python-scrapy-introduction.html"/>
    <id>http://uegeek.com/180108python-scrapy-introduction.html</id>
    <published>2018-01-08T09:26:12.000Z</published>
    <updated>2018-01-08T09:30:46.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg" alt=""></p><a id="more"></a> <h2 id="Scrapy-是什么"><a href="#Scrapy-是什么" class="headerlink" title="Scrapy 是什么"></a>Scrapy 是什么</h2><p><img src="https://scrapy.org/img/scrapylogo.png" alt=""></p><p>Scrapy 是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理或存储历史数据等程序中。</p><h2 id="Scrapy-的结构"><a href="#Scrapy-的结构" class="headerlink" title="Scrapy 的结构"></a>Scrapy 的结构</h2><p>Scrapy 的结构如下：</p><p><img src="https://doc.scrapy.org/en/latest/_images/scrapy_architecture_02.png" alt=""><br>via <a href="https://docs.scrapy.org/en/latest/topics/architecture.html" target="_blank" rel="noopener">Architecture Overview - Scrapy 1.5.0</a></p><p>在 Scrapy 中数据流是这样的：</p><ol><li>引擎从爬虫(Spider)获得初始抓取请求</li><li>引擎在 Scheduler 中安排好请求，获取下一个抓取请求</li><li>Scheduler 返回下一个抓取请求</li><li>引擎通过 Downloader 的 Middlewares 发送请求到 Downloader</li><li>完成页面下载后，Downloader 生成请求并通过 Middlewares 发送给引擎的</li><li>引擎接收来自 Downloader 的响应，通过 Spider Middlewares 发送给 Spider 处理</li><li>Spider 处理请求并返回爬取内容，向引擎提交下一个请求</li><li>引擎发送爬取内容到 Item Pipelines，然后发送处理请求到 Scheduler，获取下一个爬取请求</li><li>重复 1-8 步，直到没有新的请求</li></ol><h2 id="安装-Scrapy"><a href="#安装-Scrapy" class="headerlink" title="安装 Scrapy"></a>安装 Scrapy</h2><h3 id="新建-Python-虚拟环境"><a href="#新建-Python-虚拟环境" class="headerlink" title="新建 Python 虚拟环境"></a>新建 Python 虚拟环境</h3><p>比如用 <code>conda</code>，也可以用 <code>virtualenv</code> （参考：<a href="https://virtualenv.pypa.io/en/stable/installation/" target="_blank" rel="noopener">virtualenv installation instructions</a>)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n &#123;env_name&#125; &#123;list of packages&#125;</span><br></pre></td></tr></table></figure><p>上面的命令中，<code>env_name</code> 是用来折腾爬虫的项目环境名称，<code>list of package</code>是要一起安装的包，如 <code>scrapy</code>，<code>pandas</code>。</p><p>我新建了一个叫 <code>pyp</code> 的环境，打开这 Python 环境的命令是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> activate pyp</span><br></pre></td></tr></table></figure><p>如果你使用 <code>zsh</code>，可以在 <code>zshrc</code> 文件里面新建 alias，并 <code>source ~/.zshrc</code> 保存生效，下次就可以用别名快捷打开这个环境了。</p><h3 id="安装-Scrapy-1"><a href="#安装-Scrapy-1" class="headerlink" title="安装 Scrapy"></a>安装 Scrapy</h3><p>通过 <code>pip</code> 安装很方便</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Scrapy</span><br></pre></td></tr></table></figure><h3 id="新建-scrapy-项目"><a href="#新建-scrapy-项目" class="headerlink" title="新建 scrapy 项目"></a>新建 scrapy 项目</h3><p>进入存放项目的目录，用命令新建一个爬虫项目：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &#123;name&#125;</span><br></pre></td></tr></table></figure><p>新建好以后，可以看到起名为 lyrics 的爬虫项目，生成了以下目录和文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">├── lyrics</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── __pycache__</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── __pycache__</span><br><span class="line">└── scrapy.cfg</span><br><span class="line"></span><br><span class="line">4 directories, 7 files</span><br></pre></td></tr></table></figure><p>对照上面介绍的 Scrapy 引擎的结构，可以大概知道每个文件的作用。</p><p>下一篇我们尝试用 Scrapy 抓取一些简单的网页内容。</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://docs.scrapy.org/en/latest/index.html" target="_blank" rel="noopener">Scrapy 1.5 documentation</a></li><li><a href="https://zhuanlan.zhihu.com/p/24669128" target="_blank" rel="noopener">Scrapy爬虫框架教程（一）– Scrapy入门</a></li><li><a href="https://virtualenv.pypa.io/en/stable/installation/" target="_blank" rel="noopener">virtualenv installation instructions</a></li></ul><h3 id="你可能会感兴趣"><a href="#你可能会感兴趣" class="headerlink" title="你可能会感兴趣"></a>你可能会感兴趣</h3><ul><li><a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">DL笔记：用 python 实现梯度下降的算法</a></li><li><a href="http://www.uegeek.com/170929-DSNote3-NumPy-basic.html" target="_blank" rel="noopener">菜鸟数据科学入门03 - NumPy 数组基础和基本操作</a></li><li><a href="http://www.uegeek.com/coding-concepts.html" target="_blank" rel="noopener">设计师学编程 - 那些绕不过的概念</a></li><li><a href="http://www.uegeek.com/learngit.html" target="_blank" rel="noopener">多用Git少交税</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="爬虫" scheme="http://uegeek.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="http://uegeek.com/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>大哉问05 - 什么是学习中最大的误区？</title>
    <link href="http://uegeek.com/180106-the-learning-myth.html"/>
    <id>http://uegeek.com/180106-the-learning-myth.html</id>
    <published>2018-01-06T08:50:08.000Z</published>
    <updated>2018-01-06T08:55:50.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_drawing.png" alt=""></p><blockquote><p>我只想知道我将来会死在什么地方，这样我就可以永远不去那里啦。——查理·芒格</p></blockquote><a id="more"></a> <p>如果说学习是 hack yourself 的主要方式，那么时刻反思「学习」本身就极其重要。</p><p>芒格曾经这样总结他的成功经验：</p><blockquote><p>迅速歼灭不该做的事情，接着对该做的事情发起熟练的、跨学科的攻击，然后，当合适的机会来临——只有当合适的机会来临——就采取果断的行动。</p></blockquote><p>今天，我们一起来聊聊学习中应该「迅速歼灭」的事情。</p><h2 id="误区千千万，这个特别坑"><a href="#误区千千万，这个特别坑" class="headerlink" title="误区千千万，这个特别坑"></a>误区千千万，这个特别坑</h2><p>学习中可能的误区有哪些？这个列表会很长：</p><ul><li>没有开始去做</li><li>没有集中精力</li><li>学习材料不对</li><li>学习方法不对</li><li>缺少目标</li><li>缺少练习</li><li>缺少反馈</li><li>遗忘</li><li>……</li></ul><p>被大家戏称「学习机器」的 00 曾经有过很多无效的学（zhe）习（teng）经历，这些坑我都踩过。再次反思，发现其中最巨大的一个，我今天仍然会反复地跌进去。</p><p>这个误区就是：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/mythOfStudy.png" alt=""></p><p>我们以为，一本书接一本书地看，就是学习了；我们以为，买了各种各样的课程（甚至能坚持听完），就是学习了；我们以为，有人手把手地教，就是学习了……</p><p>买课、看书、做计划，甚至开始动手尝试、反复练习，都只是学习的「动作」，而不是学习本身。</p><p>这些都是我们为学习所缴纳的巨额税款，而且可能会一直这么交下去。</p><h2 id="反思「学习」这个概念"><a href="#反思「学习」这个概念" class="headerlink" title="反思「学习」这个概念"></a>反思「学习」这个概念</h2><p>在<a href="http://www.uegeek.com/learning-about-learn.html" target="_blank" rel="noopener">重启学习系统，做个知识炼金术士</a>一文中，00 曾经整理过学习的一些概念。一年多以后再次翻出来，发现自己虽然理解，但是并没有内化，也没有持续践行。</p><p>快速找出权威教材和一些大师对学习的定义，其中共同出现频率最高的词是：<strong>改变</strong>。</p><blockquote><p>学习是通过经历或练习所带来的行为上相对持久的改变。——「心理学最佳入门」</p><p>学习意味着从一种知识状态进入另一种知识状态，学习要使学习者的知识结构发生改变。——「变构模型—学习研究的新路径」</p><p>学习是在观察行动与结果联系的基础上，改变行动或行动规则。——马奇「经验的疆界」</p></blockquote><p>00 再做了一点简化：</p><blockquote><p>学习是一系列以改变为目的的探索活动</p></blockquote><p><strong>所以，学习的目的，甚至学习的本身，就是：改变。</strong></p><p>以这个标准衡量，80% 以上的学习都是徒劳。因为我们根本没有花哪怕 1 分钟去仔细想过：</p><ul><li>我现在处于什么状态（起点 A）？</li><li>想达到什么状态（终点 B）？</li><li>如何衡量这一改变？</li><li>为了达成这一改变，需要做哪些改变？</li></ul><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/rethinkingLearning.png" alt=""></p><p>于是我们在自己那模糊而远大的雄心之下，开始了漫长的西西弗斯式的「壮举」：开始学习，然后无疾而终。</p><h2 id="学习的陷阱"><a href="#学习的陷阱" class="headerlink" title="学习的陷阱"></a>学习的陷阱</h2><p>如同「不是所有的感情都能够被命名」，也不是所有的学习都能被描述和评估，尤其当我们没有去主动思考内隐学习的时候。内隐学习(implicit learning)，指人们对复杂规则知识的无意识获取。</p><p>包括内隐学习在内的许多学习主题，都很容易偏离目标，以致于无法形成最终的改变，因为它们：</p><ul><li>影响范围很模糊</li><li>结果无法标准化/描述</li><li>检验周期很长</li><li>层级模糊</li></ul><h3 id="目标层面的「内隐」"><a href="#目标层面的「内隐」" class="headerlink" title="目标层面的「内隐」"></a>目标层面的「内隐」</h3><p>从现状 A 到目标 B，B 永远都像梦境中的理想伴侣——面目模糊。</p><p>我说我要学日语。但我不去问，「学会」的标准，是在旅行时能流利交流呢，还是能听懂 80% 日剧的对话呢，还是能通过考试呢，还是能熟练对照五十音图发音……我也没有问，这一改变需要通过哪些以往没有做过的事情来达成。我甚至没有问，为什么学这个的优先级比 xx 高，为什么是现在？</p><p>我说我要学编程。但我不去问，「学会」的标准，是能写出简单的脚本处理一些任务呢，还是跟程序员更顺畅地沟通呢，还是找到一份编程的工作呢……我也没有问，这一改变需要通过哪些以往没有做过的事情来达成。我甚至没有问，为什么学这个的优先级比 xx 高，为什么是现在？</p><p>我说我要学如何做决策。但我不去问，「学会」的标准，是工作中做出更有理据的决策呢，是提高个人投资的回报率呢，还是了解决策的过程……我也没有问，这一改变需要通过哪些以往没有做过的事情来达成。我甚至没有问，为什么学这个的优先级比 xx 高，为什么是现在？</p><p>以上都还只是目标容易识别和描述的学习。如果涉及到关系处理、自我觉察、个人成长、构建知识体系等等话题，提炼目标会更加困难。</p><h3 id="行为层面的内隐"><a href="#行为层面的内隐" class="headerlink" title="行为层面的内隐"></a>行为层面的内隐</h3><p>假如目标能够清晰描述，接下来有更多难题等着我们：</p><ul><li>从 A 到 B，存在哪些路径，是否存在最优路径？</li><li>路径可以拆分吗？由哪些部分组成？</li><li>每一步拆分的 B 又是什么？</li><li>共性/规则/规律是什么？如何描述？</li><li>如果难以描述，又怎么判断学习效果和改进步骤呢？</li></ul><h3 id="等级层面的内隐"><a href="#等级层面的内隐" class="headerlink" title="等级层面的内隐"></a>等级层面的内隐</h3><p>如果本身就在三界和五行中，要怎么跳出三界外，不在五行中呢？？</p><p>比如，德雷弗斯模型划分了新手到专家的五个阶段。当我们还处于新手阶段，怎么能想象出成为专家需要具备哪些条件，如何做到呢？</p><table><thead><tr><th>阶段</th><th>特点</th><th>概述</th></tr></thead><tbody><tr><td>新手</td><td>没有经验或很少经验（通过实施技术促进了思维改变）。不知道自己的行为是对是错。新手不是特别想要学习，只是想实现一个立竿见影的目标。不知道如何应付错误。新手需要一份指令清单。</td><td>Novices need recipes</td></tr><tr><td>高阶新手</td><td>可以独自尝试任务，但仍难以解决问题。想要快速获取信息，不想在此刻寻根究底，或者重新温习一遍基础知识。能够开始形成一些总体原则，但不是全貌。情境理解有限。</td><td>Advanced beginners don’t want the big picture.</td></tr><tr><td>胜任者</td><td>能够建立问题域的概念模型，并有效使用它们，可以独立解决自己遇到的问题，并开始考虑如何解决新的问题。开始寻求和运用专家的意见并有效利用。如果没有更多经验，在解决问题时，他们难以确定关注哪些细节。</td><td>Competents can troubleshoot.</td></tr><tr><td>精通者</td><td>需要全局思维，寻找并想了解更大的概念框架。会自我改进，反思以前是如何做的，并修改做法期望下一次表现得更好。会学习他人的经验，如案例研究、观察、从故事中学习。可以在不同情境中理解和运用格言经验之谈。可以充分利用思考和反馈。</td><td>Proficient practitioners can self-correct.</td></tr><tr><td>专家</td><td>专家是各个领域知识和信息的主要来源。他们总是不断的寻找更好的方法和方式去做事。他们有丰富的经验，可以在恰当的情境中选取和应用这些经验。他们著书、写文章、做巡回演讲。专家根据直觉工作，而不需要理由。专家知道哪些是无关紧要的细节，哪些是非常重要的细节，非常擅长做有针对性的特征匹配。</td><td>Experts work from intuition.</td></tr></tbody></table><p>因为这种种的「不可描述」，学习其实是一件不确定性蛮高的事情。如果没有充分启动元认知去理解和反思我们的学习行动，就容易用行动替代实质。</p><p>所以，学习的尝试和学习是两回事。</p><p>所以，看书和学习是两回事。</p><p>如果把看书的目的分为：<strong>参考资料、获得体验、启发思路、重塑三观/知识体系</strong>，我们惯常的读书习惯，其实都是以获得体验为主，尤其是虚构类的书籍。当然，获得体验本身就是非常有价值的目标，只不过这非常奢侈。</p><p>如果以学习为侧重而去读书，可能可以这样分配比例：</p><table><thead><tr><th>目的</th><th>书籍比例</th><th>精力投入</th></tr></thead><tbody><tr><td>重塑三观</td><td>0.1%</td><td>70%</td></tr><tr><td>参考资料</td><td>10%</td><td>15%</td></tr><tr><td>获得体验</td><td>8%</td><td>10%</td></tr><tr><td>启发思考</td><td>1.9%</td><td>5%</td></tr><tr><td>没有营养</td><td>80%</td><td>0%</td></tr></tbody></table><h2 id="更新「学习」这个概念"><a href="#更新「学习」这个概念" class="headerlink" title="更新「学习」这个概念"></a>更新「学习」这个概念</h2><p>从今天开始，往头脑的概念库中重新写入「学习」这个概念吧！</p><p>马奇在「经验的疆界」中提出，学习会在三个层面同时发生：</p><ol><li>学习做什么：例如寻找好的技术、战略或合作伙伴</li><li>学习如何做：例如精炼并改进在某技术、战略或合作伙伴上的胜任力</li><li>学习期盼什么：例如调整绩效目标（经常出问题，开始设定太高或太低后续没有调整）</li></ol><p>所以，学习并不是「做了哪些代表学习的举动」，而是在清醒知道<strong>为什么学、如何学、如何评估</strong>的前提下，从 A 到 B 的过程。<strong>如果没有（一定程度上可描述的）改变，学习相当于没有发生。</strong></p><p>这么看来，学习真是一件远比我们想象要深刻且有用的事情。低效的学习，大都来自于对「学习」概念本身的误解。</p><p>既然找出了大坑，下一篇我们来详细讨论，学习中最应该养成的习惯是什么。</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://book.douban.com/subject/25858893/" target="_blank" rel="noopener">心理学最佳入门（原书第2版）</a></li><li><a href="http://book.douban.com/subject/6687032/" target="_blank" rel="noopener">经验的疆界</a></li><li><a href="https://book.douban.com/subject/5346110/" target="_blank" rel="noopener">穷查理宝典</a></li><li><a href="https://book.douban.com/subject/26268555/" target="_blank" rel="noopener">程序员思维修炼</a></li><li><a href="https://book.douban.com/subject/5388442/" target="_blank" rel="noopener">变构模型-学习研究的新路径</a></li></ul><h3 id="HackYourself-大哉问系列"><a href="#HackYourself-大哉问系列" class="headerlink" title="HackYourself 大哉问系列"></a>HackYourself 大哉问系列</h3><ul><li><a href="http://www.uegeek.com/171226MyYear2017.html" target="_blank" rel="noopener">小哉问：年终总结写什么？ | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171223-Why-Learn-Programming.html" target="_blank" rel="noopener">大哉问04 - 为什么要学编程 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171216HowToMakeMoney.html" target="_blank" rel="noopener">大哉问03 - 什么是赚钱之道？更新你的个人商业模式 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171204HowToLoveYourself.html" target="_blank" rel="noopener">大哉问02 - 如何爱自己？拟一份爱的宣言 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171126TimePerspective.html" target="_blank" rel="noopener">大哉问01 - 什么样的时间观值得拥有？ | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171112-HowToAskGoodQuestion.html" target="_blank" rel="noopener">用问题对话虚无 —— HackYourself 大哉问系列 | 00’s Adventure</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/HY_drawing.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我只想知道我将来会死在什么地方，这样我就可以永远不去那里啦。——查理·芒格&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="学习" scheme="http://uegeek.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="方法" scheme="http://uegeek.com/tags/%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>DeepLearning笔记：多节点神经网络</title>
    <link href="http://uegeek.com/180104DeepLearning8-MultiLayer-Perceptrons.html"/>
    <id>http://uegeek.com/180104DeepLearning8-MultiLayer-Perceptrons.html</id>
    <published>2018-01-04T09:03:50.000Z</published>
    <updated>2018-01-04T09:46:48.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：上回我们<a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">在 python 里面实现了单个神经元的梯度下降算法</a>。现在可以挑战一下多个神经元的网络了。</p><p><code>阿特</code>：那会不会很难哦？</p><p><code>阿扣</code>：也不会，原理其实是一样的，只是需要分辨清楚各个参数属于哪一层。</p><p><code>阿特</code>：（不祥预感）</p><p><code>阿扣</code>：比如说，下面这个网络：</p><ul><li>有 3 个输入 x1,x2,x3，2 个隐层节点 h1,h2</li><li>节点之间的权重用 w 表示，第一个下标为出发节点，第二个下标为目标节点，比如 $w_{11}$ 表示 x1 到 h1 的权重</li></ul><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/network-with-labeled-weights.png" alt=""></p><p>我们把权重存在一个矩阵中，每一行对应一个输入值的权重，每一列对应一个隐层节点的权重：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/multilayer-diagram-weights.png" alt=""></p><p>所以，隐层的第 j 个节点就表示为：$h_j = \sum<em>i w</em>{ij}x_i$</p><p>权重和输入值相乘时，需要用到矩阵乘法中的点乘（dot product）：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/input-times-weights.png" alt=""></p><p><code>阿特</code>：啊……矩阵，我好些已经忘得差不多了……</p><p><code>阿扣</code>：没关系，慢慢回忆起来。这里比较关键的是，两个矩阵相乘，<strong>左边矩阵的行数，必需跟右边矩阵的列数相等</strong>，不然没法相乘。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/matrix-mult-3.png" alt=""></p><p>比如我们要计算的神经网络的矩阵：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/matrix_eg1.png" alt=""></p><p>左边矩阵有 1 行 3 列，右边矩阵有 3 行 1 列，它们是可以相乘的。</p><p><code>阿特</code>：让我数一数……</p><p><code>阿扣</code>：记得矩阵需要「门当户对」就好 😄 。上面这个矩阵，我们也可以调换左右顺序，并且让两个矩阵都转置（就是行列互换）一下来满足相乘的条件：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/inputs-matrix.png" alt=""></p><p><code>阿特</code>：这跟上面那两个矩阵相乘的结果是一样的吗？</p><p><code>阿扣</code>：是的。按照矩阵点乘的公式 ($h_1=x<em>1w</em>{11} + x<em>2w</em>{21}+x<em>3w</em>{31}$) 把它们展开，会发现其实是一个东西。</p><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DeepLearning笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DeepLearning笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DeepLearning笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DeepLearning笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DeepLearning笔记：Cost function 损失函数</a></li><li><a href="http://www.uegeek.com/171222DLN6-GradientDescent.html" target="_blank" rel="noopener">DeepLearning笔记：梯度下降 Gradient Descent</a></li><li><a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">DeepLearning笔记：用 python 实现梯度下降的算法</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="神经网络" scheme="http://uegeek.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="线性代数" scheme="http://uegeek.com/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>小哉问：年终总结写什么？</title>
    <link href="http://uegeek.com/171226MyYear2017.html"/>
    <id>http://uegeek.com/171226MyYear2017.html</id>
    <published>2017-12-29T11:28:42.000Z</published>
    <updated>2017-12-31T09:30:20.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/2017sumTitle.jpg" alt=""></p><a id="more"></a> <p>马上要跨入本世纪第 19 个年头了（可怕不可怕……），大家都在忙着写总结和计划。</p><p>年终总结写什么，取决于想得到什么。</p><p>如果想记录一年都做了什么，那很简单，按时间记账就行。如果想盘点一年的得失，就需要费一点心力，思考哪些事情比较重要，自己从中获得了什么、失去了什么。</p><p>如果想给自己一个交代，总结过去就好。</p><p>如果想许自己一个未来，那值得再琢磨琢磨。</p><p>一天有一天的所得，一辈子有一辈子的教训。越是大时间周期的回顾，提取的信息应该越凝练。人能清醒地写年终总结的机会真的不多（也就二三十来次？）年末提供了一个强制的时间点去做盘点，以便搞清楚这一年有哪些新收获，最希望在来年谨记？有哪些切肤之痛，希望未来不要再经历？有哪b些或主动或被动的改变，希望来年继续？</p><p>一年一次的总结，也可以看成是一次内存整理：<strong>「卸载」那些无用、低效的想法和习惯，「加载」来年需要的认知和能力</strong>。</p><p>今年是出乎意料的一年，以没有料想过的方式，学习到一些被忽视已久的知识。虽然作品寥寥，倒是更懂自己了。</p><p>来到 2018 的门口，先放下背包，倒出这一年中收集的种种，仔细考虑哪些要丢弃，哪些需要重视起来，哪些要且行且珍惜。</p><h3 id="需要卸载"><a href="#需要卸载" class="headerlink" title="需要卸载"></a>需要卸载</h3><ul><li>会带来巨大认知失调的惯性</li><li>让别人的目标凌驾于自己的目标之上</li><li>自我剥夺价值感</li><li>陈旧的人设</li></ul><h3 id="需要保持"><a href="#需要保持" class="headerlink" title="需要保持"></a>需要保持</h3><ul><li>简单的生活方式</li><li>反碎片化</li><li>从知识源头获取信息（比如，跟踪人而不是五手信息）</li><li>以问题驱动思路，以试验驱动行动</li></ul><h3 id="需要加载"><a href="#需要加载" class="headerlink" title="需要加载"></a>需要加载</h3><p><strong>1. 进入新环境、新领域、新角色时，需要清内存，重建数据库</strong></p><p><strong>2. 正确看待人性的复杂</strong></p><ul><li>尤其不要低估人与人之间的差异</li><li>提升快速识别人的判断力，以及其他直觉</li><li>观察互动模式如何形成</li><li>设定关系的止损点</li></ul><p><strong>3. 爱自己</strong></p><ul><li>通过情绪快速识别问题</li><li>划定灵活而坚定的个人边界</li><li>优先处理自己的核心矛盾，保护内在动机</li></ul><p><strong>4. 建立「初心」的快捷方式，多拷问目标</strong></p><p><strong>5. 减少 90% 主流信息输入方式，在最优信息上增加十倍投入</strong></p><p><strong>6. 以身份和项目为导向，聚焦和持续输出</strong></p><hr><p>祝大家新年快乐！每天都有新收获</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/2017sumTitle.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="2017" scheme="http://uegeek.com/tags/2017/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：用 python 实现梯度下降的算法</title>
    <link href="http://uegeek.com/171226DLN7-GradientDescentinPython.html"/>
    <id>http://uegeek.com/171226DLN7-GradientDescentinPython.html</id>
    <published>2017-12-26T01:28:42.000Z</published>
    <updated>2018-01-04T09:46:06.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p>回顾上回讲的梯度下降算法，想实现梯度下降，需要不断更新 w：</p><p>$$ \Delta w_{ij} = \eta \delta_j x_i $$</p><p>具体步骤如下：</p><ul><li>初始化权重变化率为 0 ：$\Delta w_i = 0$</li><li>对训练集中的每一个数据：<ul><li>做正前传播计算：$\hat y=f(\sum_iw_ix_i)$</li><li>计算输出单元的 error term：$\delta=(y-\hat y) * f’(\sum_iw_ix_i)$</li><li>更新权重变化率：$\Delta w_i= \Delta w_i + \delta x_i$</li></ul></li><li>更新权重 $w_i = w_i + \eta \Delta w_i /m$</li><li>重复 e 次训练 epochs</li></ul><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><ol><li>初始化权重变化率为 0</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">del_w = np.zeros(weights.shape)</span><br></pre></td></tr></table></figure><ol><li>正向传播计算</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output = sigmoid(np.dot(x, weights))</span><br></pre></td></tr></table></figure><ol><li>计算输出单元的 error term</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">error = y - output</span><br><span class="line">error_term = error * output * (<span class="number">1</span>-output)</span><br></pre></td></tr></table></figure><ol><li>更新权重变化率</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">del_w += error_term * x</span><br></pre></td></tr></table></figure><ol><li>更新权重</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weights += learnrate * del_w / n_records</span><br></pre></td></tr></table></figure><ol><li>重复 epochs</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">    del_w = np.zeros(weights.shape)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(features.values, targets):</span><br><span class="line">        <span class="comment"># Loop through all records, x is the input, y is the target</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the output</span></span><br><span class="line">        output = sigmoid(np.dot(x, weights))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error</span></span><br><span class="line">        error = y - output</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error term</span></span><br><span class="line">        error_term = error * output * (<span class="number">1</span>-output)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the change in weights for this sample</span></span><br><span class="line">        <span class="comment"># and add it to the total weight change</span></span><br><span class="line">        del_w += error_term * x</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using the learning rate and the average change in weights</span></span><br><span class="line">    weights += learnrate * del_w / n_records</span><br></pre></td></tr></table></figure><p>完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> data_prep <span class="keyword">import</span> features, targets, features_test, targets_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># Defining the sigmoid function for activations</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># reserve seed</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">n_records, n_features = features.shape</span><br><span class="line">last_loss = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize weights</span></span><br><span class="line">weights = np.random.normal(scale=<span class="number">1</span> / n_features**<span class="number">.5</span>, size=n_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Neural Network hyperparameters</span></span><br><span class="line">epochs = <span class="number">1000</span></span><br><span class="line">learnrate = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">    del_w = np.zeros(weights.shape)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(features.values, targets):</span><br><span class="line">        <span class="comment"># Loop through all records, x is the input, y is the target</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the output</span></span><br><span class="line">        output = sigmoid(np.dot(x, weights))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error</span></span><br><span class="line">        error = y - output</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error term</span></span><br><span class="line">        error_term = error * output * (<span class="number">1</span>-output)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the change in weights for this sample</span></span><br><span class="line">        <span class="comment"># and add it to the total weight change</span></span><br><span class="line">        del_w += error_term * x</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using the learning rate and the average change in weights</span></span><br><span class="line">    weights += learnrate * del_w / n_records</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Printing out the mean square error on the training set</span></span><br><span class="line">    <span class="keyword">if</span> e % (epochs / <span class="number">10</span>) == <span class="number">0</span>:</span><br><span class="line">        out = sigmoid(np.dot(features, weights))</span><br><span class="line">        loss = np.mean((out - targets) ** <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> last_loss <span class="keyword">and</span> last_loss &lt; loss:</span><br><span class="line">            print(<span class="string">"Train loss: "</span>, loss, <span class="string">"  WARNING - Loss Increasing"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"Train loss: "</span>, loss)</span><br><span class="line">        last_loss = loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate accuracy on test data</span></span><br><span class="line">test_out = sigmoid(np.dot(features_test, weights))</span><br><span class="line">predictions = test_out &gt; <span class="number">0.5</span></span><br><span class="line">accuracy = np.mean(predictions == targets_test)</span><br><span class="line">print(<span class="string">"Prediction accuracy: &#123;:.3f&#125;"</span>.format(accuracy))</span><br></pre></td></tr></table></figure><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DL笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DL笔记：Cost Function 损失函数</a></li><li><a href="http://www.uegeek.com/171222DLN6-GradientDescent.html" target="_blank" rel="noopener">DL笔记：Gradient Descent 梯度下降</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>大哉问04 - 为什么要学编程？</title>
    <link href="http://uegeek.com/171223-Why-Learn-Programming.html"/>
    <id>http://uegeek.com/171223-Why-Learn-Programming.html</id>
    <published>2017-12-23T07:56:13.000Z</published>
    <updated>2018-01-06T08:54:20.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_code_illustration.jpg" alt=""></p><a id="more"></a> <blockquote><p>工欲善其事，必先鼓其志，然后利其器。 —— 00</p></blockquote><p>很多次失败的学习经历告诉我，最终能不能学会一样东西，跟聪不聪明没太大关系，而是看这件事到底有多生死攸关，或者有多意义重大。</p><p>学编程，对大龄、非专业的我来说，更是如此。动机因人而异，不管黑猫白猫，能加满油箱的就是好动机。</p><p>我找出了 5 个比喻，来说服自己为什么要学编程：</p><ol><li>数字化生存的工具</li><li>人机交互的语言</li><li>复杂系统的训练营</li><li>创作的可供性源头</li><li>心流的容器</li></ol><h2 id="1-数字化生存的工具"><a href="#1-数字化生存的工具" class="headerlink" title="1.数字化生存的工具"></a>1.数字化生存的工具</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/ub_2-3.png" alt=""></p><p>距离尼葛洛庞帝写出「Being Digital」已经过去 22 年了。我们真的已经生活在数字化的世界中。</p><p>世界很复杂。</p><p>人们通过「降维」，抽取并控制最基本的单元要素，把事物抽象成数理形式、逻辑，再进一步抽象成 0 和 1，从而获得了重构/再造世界的能力——这是强大的杠杆，使得效率暴涨、网络成型。</p><p>为什么能够做到？得益于我们抽象事物、提取共性、找到基本单元的能力。付出的是理解、灵活性和转化成本。</p><h3 id="数字化生存的三个阶段"><a href="#数字化生存的三个阶段" class="headerlink" title="数字化生存的三个阶段"></a>数字化生存的三个阶段</h3><p><strong>概念和形式的数字化</strong>。那些以虚拟概念、形式逻辑为核心的领域，比如金融，比如文字，比如音乐，早已经完成数字化。</p><p><strong>实体的数字化</strong>。O2O、自动化生产、智能家居、物联网，它们不仅仅是网红概念和风口，也是数字化卷积横扫物理世界的汹涌进程。物理世界被慢慢驯服的同时，构建虚拟化世界的技术 VR/AR/MR 们也快速发展——毕竟人们渴求对世界的完全「控制」，即便这种控制只停留在视觉层面。</p><p><strong>人的数字化</strong>。先是 ID 化，完成人与人的互联。碳基质的人类迟早（已经）意识到肉身的局限，就会开始去修改自己的出厂设置。基因技术，纳米计算，脑机接口……机器不会毁灭人类，因为人类会率先变成人机融合的可编程智能体。</p><p>人能够摆脱自然的桎梏，成为衣食无忧、没有天敌的物种，靠建造工具去改造环境，以适应自身的需求。要在越来越数字化的世界中生存，掌握改造周边环境的能力，或者说手握一本操纵现实和驱动生产的「指南」，确实很有必要。</p><p>何况，它还能让你找到一份工作。因为越来越多的工作内容，都转变成了建造和管理数字世界。</p><p>那么应该何时完成进化？</p><p>比你所在的行业/领域早一步完成。如果它正处在数字化进程的早期，那就赶紧开始吧。</p><p>总之</p><blockquote><p>学编程，是为了提高数字世界的生存效率。</p></blockquote><h2 id="2-人机交互的语言"><a href="#2-人机交互的语言" class="headerlink" title="2.人机交互的语言"></a>2.人机交互的语言</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/designing-for-humans-in-a-digital-world.jpg" alt=""></p><p>人机交互是我过去多年的工作内容，希望未来也是。</p><p>在人工智能的前夜，需要很多类似交互设计师、体验设计师这样的 AI 清道夫，帮助机器完成它们还比较笨拙的「沟通」工作。黑暗的前夜什么结束，我们不知道，可以肯定的是，只会越来越快。</p><p>当算法越来越智能，人与机器的交互大概会沿着两个方向发展：</p><ul><li><strong>在机器更擅长的领域，推动自动化</strong>。很多原本需要人干预的、相对机械的事情，都会逐渐自行运转——比如数字化生产、自动驾驶等等。</li><li><strong>在人更擅长的领域，推动人机合作</strong>。比如综合智能、文艺创作、理解和共情他人、面对面服务这些领域，机器如何帮助人完成工作，人和机器之间的「伙伴式」互动，是我更感兴趣的人机交互领域。</li></ul><p>「人机交互创作」，应该会成为一个有意思的领域，而且它会让编程语言改头换面——又或者是增加其他的方式，比如编程手势，编程舞蹈，编程表情？</p><p>总之</p><blockquote><p>学编程，是为了让人和机器更好地沟通。</p></blockquote><h2 id="3-复杂系统的训练营"><a href="#3-复杂系统的训练营" class="headerlink" title="3.复杂系统的训练营"></a>3.复杂系统的训练营</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_minecraftentrance.png" alt=""></p><p>如何构造复杂的系统？<strong>运用编程的思想，并且在沙盒里实践。</strong></p><p>再复杂的系统，都可以始于 「Hello world」。然后增加一条运算，增加一个循环，增加一个函数， 增加一个对象，增加一个 API，增加一个库，增加一个逻辑层，增加一个编译器，增加一个物理模组……处理好的部分就封装起来，眼不见心不烦，可以专注搭建下一个模块。如果随着现实需求的增加，发现造出来的「轮子」不好用，还可以拆了轮子重造。</p><p>罗马不是一天建成的，Minecraft 也不是。并非每个人都能承受物理世界推翻重建的高昂成本，但是每个人都能开 Sandbox，调通程序以后再 Git Push。</p><p>你看吸金无数的在线游戏，在虚拟世界的沙盒里，硬生生地再造了无数个传奇。</p><p>你看横空出世的比特币，在虚拟世界的沙盒里，硬生生地再造了一个金融系统。</p><blockquote><p>学编程，是为了训练构造复杂系统的能力。</p></blockquote><h2 id="4-创作的可供性源头"><a href="#4-创作的可供性源头" class="headerlink" title="4.创作的可供性源头"></a>4.创作的可供性源头</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_drawing.png" alt=""></p><p>音乐家以音符为符号，用乐器演奏。画家以画笔为工具，在实体材料上作画。</p><p>当我们把思想降维成文字，便拥有了生成新想法的可能；把建筑降维成骨架和砖块，我们拥有了建造形态万千的建筑的可能；把音乐降维为旋律、节奏、音色、和声，我们拥有了创造新作品的可能。</p><p>当然，这都只是「可能」，想要创造出鲜活而有深度的新事物，只有一个途径：<strong>在实践中改进，永不停息</strong>。</p><p>我想强调的是，一旦把事物拆解到原子/比特层级，就可以完全重组——一生二，二生三，三生万物，这释放了多少可供性！</p><p>代码本身是语言，<strong>是驱动系统为你创作的语言</strong>。音符和乐器合一，纸和笔合一，建筑场所和构件合一——这是多么不可思议的创造环境，表达、构造、呈现的载体合一了！</p><p>总之</p><blockquote><p>学编程，是为了能操控素材，创造属于自己的时间晶体。</p></blockquote><h2 id="5-心流的容器"><a href="#5-心流的容器" class="headerlink" title="5.心流的容器"></a>5.心流的容器</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_creative.png" alt=""></p><p>再怎么数字化生存，再怎么提高效率，也不能被轻易地被物化，这是人要守住的界限。人之为人，还是应该多以自身的福祉为出发点。</p><p>幸福是什么？对我而言，幸福就是「忘我但趋于有序」的状态，或者说，就是在创作中的心流状态。</p><p>写作是低成本的心流获取方式，而且自带生产属性。同样是用语言表达，编程也容易产生心流，而且改造现实的能力更强。写文字和写代码，都是心流体验的容器。</p><p>但是在获得心流之前，需要大量的练习。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/download.png" alt=""></p><p>via <a href="https://www.wikiwand.com/en/Flow_(psychology" target="_blank" rel="noopener">Flow (psychology) - Wikiwand</a>)</p><p><a href="https://www.wikiwand.com/en/Mihaly_Csikszentmihalyi" target="_blank" rel="noopener">Csikszentmihalyi</a> 这张心流的图示，大家可能都很熟悉了。只有当技能水平和任务难度都高的时候，心流才容易产生。<strong>编程就是一种需要专注、难度可控、反馈及时的活动。在心流中构建作品，还有什么事情比这个更值得投入吗</strong>？</p><p>总之</p><blockquote><p>学编程，是为了拥有进行创作的心流容器。</p></blockquote><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>在门口徘徊挣扎了 4、5 年，总算是磕磕碰碰上路了。</p><p>00 的编程学习笔记和项目都会记录在 ArtxCode 公众号上面，欢迎围观和一起学习。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/AC.IMG.QR.png" alt=""></p><p>先学为敬。</p><h3 id="HackYourself-大哉问系列"><a href="#HackYourself-大哉问系列" class="headerlink" title="HackYourself 大哉问系列"></a>HackYourself 大哉问系列</h3><ul><li><a href="http://www.uegeek.com/171226MyYear2017.html" target="_blank" rel="noopener">小哉问：年终总结写什么？ | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171216HowToMakeMoney.html" target="_blank" rel="noopener">大哉问03 - 什么是赚钱之道？更新你的个人商业模式 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171204HowToLoveYourself.html" target="_blank" rel="noopener">大哉问02 - 如何爱自己？拟一份爱的宣言 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171126TimePerspective.html" target="_blank" rel="noopener">大哉问01 - 什么样的时间观值得拥有？ | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171112-HowToAskGoodQuestion.html" target="_blank" rel="noopener">用问题对话虚无 —— HackYourself 大哉问系列 | 00’s Adventure</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/HY_code_illustration.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：梯度下降 Gradient Descent</title>
    <link href="http://uegeek.com/171222DLN6-GradientDescent.html"/>
    <id>http://uegeek.com/171222DLN6-GradientDescent.html</id>
    <published>2017-12-22T01:28:24.000Z</published>
    <updated>2017-12-31T12:25:56.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：上一次我们了解了<a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">损失函数</a>。为了找到使损失函数（比如用 SSE 计算）最小的 w (权重) 和 b (偏置项)，我们需要先了解一个重要的方法：梯度下降。</p><p><code>阿特</code>：听起来像坐滑滑梯~</p><p><code>阿扣</code>：是有那么点意思。</p><p><code>阿扣</code>：想象一下，我们对网络中的一些权重做了很小的改变，这些变化会让输出也有相应很小的变化：</p><p><img src="http://neuralnetworksanddeeplearning.com/images/tikz8.png" alt=""></p><p>via <a href="http://neuralnetworksanddeeplearning.com/chap1.html" target="_blank" rel="noopener">Neural networks and deep learning - chapter 1</a></p><p>然后拿这些微小的变化，跟目标值对比，看看误差是变大还是变小了，然后不断调整权重值，最终找到最合适的 w 和 b。</p><p><code>阿特</code>：那要怎么找到这些值呢？</p><p><code>阿扣</code>：下面有请「梯度下降」 Gradient Descent。</p><p><code>阿特</code>：终于能坐滑滑梯了……</p><p><code>阿扣</code>：坐这个滑滑梯可能有点晕 😄 。我先给你打个比方。想象一下，你在一个山峰的山顶，想用最快的速度到达山脚。</p><p><code>阿特</code>：坐缆车可以吗？</p><p><code>阿扣</code>：缆车，不存在的……只能靠走的。要往哪边下山呢？我们会选一个看起来「下降」最快的路径：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Gradient%20Descent-i1.png" alt=""></p><p>朝这个方向走一段后，我们再看下一步往哪个方向走，「下降」最快。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Gradient%20Descent-i2.png" alt=""></p><p>一直重复这个过程，就能最快的速度下到山脚。</p><p><code>阿特</code>：是这么个道理。</p><p><code>阿扣</code>：这个方法，就是「梯度下降」，在机器学习中很常见。所谓「梯度」，其实是指「变化率」或者「坡度 slope」，就是多变量函数的导数。</p><p><code>阿特</code>：导数？！你说的是微积分里面那个导数吗？ …… 瑟瑟发抖.gif</p><p><code>阿扣</code>：别紧张，先听我讲，回忆回忆。</p><p><code>阿特</code>：好吧。</p><p><code>阿扣</code>：你还记得怎么表示函数 f(x) 的导数吧？很简单，就是 f’(x) 。</p><p><code>阿特</code>：嗯嗯，记得。</p><p><code>阿扣</code>：所谓「梯度」，其实就是函数在某一点上的变化率，根据微分的知识，变化率可以通过这一点的切线求得，而切线其实就是函数的导数：f’(x)。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/derivative-example.png" alt=""></p><p>来，跟我念一遍：求梯度 = 求变化率 = 求导数</p><p><code>阿特</code>：求梯度 = 求变化率 = 求导数 （假装自己听懂了）</p><p><code>阿扣</code>：了解了「梯度」，然后我们来看看「下降」又是怎么回事。</p><p>切线代表函数在某个点的变化率。在上面这个图中，x = 2 位置上的切线，斜率是 &gt; 1 的。说明如果继续往 x = 2 的右边滑去，在曲线上的值就会变大。比如当 x = 3 时，y = 9。</p><p>但是我们想要到曲线最低的地方去，因为那里可以让误差（也就是 cost ）最小。所以，应该沿着梯度「相反」的方向滑动，也就朝着是 x = 2 的左边滑去。这就是「下降」的含义。</p><p><code>阿特</code>：沿着「上山」最快的反方向走，就能最快「下山」。啊原来这么直白……</p><p><code>阿扣</code>：对呀，原理并不复杂的。</p><p>这个视频讲解了线性回归和梯度下降的关系，来看看吧！</p><div class="video-container"><iframe src="//www.youtube.com/embed/L5QBqYDNJn0" frameborder="0" allowfullscreen></iframe></div><p><a href="https://www.youtube.com/watch?time_continue=194&amp;v=L5QBqYDNJn0" target="_blank" rel="noopener">Linear Regression Answer - YouTube</a></p><p><code>阿特</code>：这个视频不错，讲得挺清楚的~</p><p><code>阿扣</code>：我们来复习一下。用一个函数 f(h) 表示 x 和 y 的关系。x 和 y 其实是已知的，它们来自真实的数据集。我们的目标是求出 w 和 b，使得计算出来的 $\hat y$ 最接近实际的 y 值。为了得到某种类型的 y 值（比如只有 0 和 1 两种输出），我们会使用类似 Sigmoid 这样的激活函数，对 f(h) 做一下转换。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/simpleNN.png" alt=""></p><p><code>阿特</code>：哦，我说怎么有点难理解呢。因为以前碰到 x 和 y，它们都是未知数，现在它们变成了已知数，真正的目标其实是求 w 和 b！</p><p><code>阿扣</code>：没错！这是深度学习算法中一个需要调整的认知。</p><p>怎么得到 w 和 b 呢？用损失函数。如果损失函数的值大，说明模型预测得不准。我们要找到让损失函数的值最小的 w 和 b。更具体说，我们要找到 w 的变化幅度 $\Delta w$，每次调整一小步，看看误差 E 是不是变小了。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Gradient%20Descent-i3.png" alt=""></p><p>为了求出 $\Delta w$，我们引入「误差项」$\delta$ ，它表示 <code>误差 * 激活函数的导数</code>。然后用「误差项」$\delta$ 乘上学习率 $\eta$ （用来调整梯度的大小），再乘上 x，就是每次应该调整的权重值 $\Delta w_{ij}$</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/WX20171127-154242@2x.png" alt=""></p><p><code>阿扣</code>：比如说，如果激活函数是 Sigmoid 函数。</p><p>$$ f(h)=\frac {1}{1 + e^{−h}} $$ </p><p>$$ f’(h)=f(h)(1−f(h))$$ </p><p>$$ \Delta w_{ij}=\eta<em>(y_j-\hat y_j)</em>f(h)<em>(1−f(h))</em>x_i $$</p><p>…… 咦？人呢？</p><p>喂！别跑，还有好几个知识点没讲呢！……</p><h3 id="补充：求多个变量的偏导数"><a href="#补充：求多个变量的偏导数" class="headerlink" title="补充：求多个变量的偏导数"></a>补充：求多个变量的偏导数</h3><p>如果只有一个未知数，求梯度只需要计算导数。如果有多个变量，求梯度就需要计算偏导数。偏导数其实并不复杂，只需要掌握链式求导法则，就能进行大部分的计算。</p><p>$$ \frac{\partial}{\partial w} p(q(w)) = \frac{\partial p}{\partial q}\frac{\partial q}{\partial w} $$</p><p>比如，损失函数 C</p><p>$$ C = \sum(wx + b - y)^2 = \sum((wx + b)^2 + y^2 - 2y(wx + b)) = \sum(x^2w^2 + b^2 + 2xwb + y^2 - 2xyw - 2yb) $$</p><p>对 w 求偏导</p><p>$$ \frac{\partial C}{\partial w} = \frac{1}{N} \sum(wx + b - y)x $$</p><p>对 b 求偏导</p><p>$$ \frac{\partial C}{\partial b} = \frac{1}{N} \sum(wx + b - y) $$</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101" target="_blank" rel="noopener">Deep Learning Nanodegree | Udacity</a></li><li><a href="https://www.coursera.org/learn/neural-networks-deep-learning" target="_blank" rel="noopener">Neural Networks and Deep Learning | Coursera</a></li><li><a href="https://classroom.udacity.com/nanodegrees/nd101-cn/parts/ba124b66-b7f7-43ab-bc89-a390adb57f92/modules/2afd43e6-f4ce-4849-bde6-49d7164da71b/lessons/dc37fa92-75fd-4d41-b23e-9659dde80866/concepts/7d480208-0453-4457-97c3-56c720c23a89" target="_blank" rel="noopener">Gradient Descent with Squared Errors</a></li><li><a href="https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient" target="_blank" rel="noopener">Gradient (video) | Khan Academy</a></li><li><a href="http://ruder.io/optimizing-gradient-descent/index.html#momentum" target="_blank" rel="noopener">An overview of gradient descent optimization algorithms</a></li></ul><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DL笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DL笔记：Cost Function 损失函数</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：Cost function 损失函数</title>
    <link href="http://uegeek.com/171220DLN5-CostFunction.html"/>
    <id>http://uegeek.com/171220DLN5-CostFunction.html</id>
    <published>2017-12-20T01:31:16.000Z</published>
    <updated>2017-12-27T01:38:19.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：阿特，还记得训练神经网络的目标其实是什么吗？</p><p><code>阿特</code>：我记得好像是要找出最合适的权重(weights)，使得输出结果尽可能接近真实值。</p><p><code>阿扣</code>：Hin 棒！你说的没错。说回到训练神经网络，我们需要在训练中及时了解训练效果如何，是不是朝着训练目标在一点点靠近。如果偏离目标，就说明训练模型可能在「犯错」，就要纠正过来。</p><p><code>阿特</code>：那怎么知道模型是不是在「犯错」呢？</p><p><code>阿扣</code>：我们会找一个度量标准。一个常见的度量方法是计算误差的平方和（SSE, sum of the squared errors）：</p><p>$$ E=\frac{1}{2}\sum_\mu\sum_j[y^\mu_j - f(\sum<em>i w</em>{ij}x^\mu_i)]^2 $$</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/latex_9521ee448af952b9e073b5d31974241c.png" alt=""></p><p><code>阿特</code>：你……欺负人 &gt;.&lt;</p><p><code>阿扣</code>：别着急，我们来拆解这一坨是个什么东西。先看看各个字母的含义：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/il_for_SSE-1.png" alt=""></p><p>这个等式里面，有三个求和项（就是这个翻转了 90° 的 M： $\sum$ ）。</p><p>最右边的求和项 $\sum<em>i w</em>{ij}x^\mu_i$ ，表示我们训练出来的权重 w 乘上输入值 x 得出的目标值 $\hat y$（也就是我们给数据打算的标签），然后用这些结果跟实际的数据中的 y 值做比较，看看偏差有多大。</p><p>现在你理解了最右边的求和项了吗？</p><p><code>阿特</code>：大概意思是我们从数据中预测出来的 y ？</p><p><code>阿扣</code>：没错，我们先把这一坨替换成 $\hat y$，简化一下公式：</p><p>$$<br>E=\frac{1}{2}\sum_\mu\sum_j[y^\mu_j - f(\sum<em>i w</em>{ij}x^\mu<em>i)]^2<br>\<br>\downarrow<br>\<br>E=\frac{1}{2}\sum</em>\mu\sum_j[y^\mu_j - \hat y_j]^2<br>$$</p><p><code>阿特</code>：世界清静多了~</p><p><code>阿扣</code>：我们再来看右边这个求和项。j 表示有 j 个隐层节点，把每个节点的误差平方 $[y^\mu_j - \hat y_j]$ 计算出来。现在只剩下最后一个求和项了，它表示把 u 个输出节点的误差加起来。这样就得到了总体误差。</p><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DL笔记：Activation Function 激活函数</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：Activation Function 激活函数</title>
    <link href="http://uegeek.com/171218DLN4-ActivationFunction.html"/>
    <id>http://uegeek.com/171218DLN4-ActivationFunction.html</id>
    <published>2017-12-18T11:20:51.000Z</published>
    <updated>2017-12-18T11:59:31.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p>回顾:</p><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li></ul><p><code>阿扣</code>：阿特，今天我们来了解一下深度学习中的激活函数(Activation functions)。</p><p><code>阿特</code>：又是函数……为什么要了解这个哦……</p><p><code>阿扣</code>：在机器学习中，我们经常需要对输出结果打上「是」或「否」标签。比如对一张输入的图片，模型要判断图片里面有没有包含汪星人。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Col.DL.dog_detect.png" alt=""></p><p><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">上一回我们提到的逻辑回归</a>，可以用来减少预测值和真实值之间的误差。</p><p><code>阿特</code>：那要怎么做呢？</p><p><code>阿扣</code>：我们来用符号描述一下问题：</p><ul><li>x：训练数据中的 input</li><li>y：训练数据中已经做好标记的 output</li><li>w：逻辑回归的 weights</li><li>b：逻辑回归的 bias</li><li>模型的输出：$\hat y = \sigma (wx + b)$</li></ul><p><code>阿特</code>：老朋友 wx + b</p><p><code>阿扣</code>：好眼力。它就是一个线性模型。别忘了，我们想让输出只包含两个值：是，否。一般我们会用 1 表示「是」，用 0 表示「否」。</p><p><code>阿特</code>：就是我给模型图片 A，它说「0」；给图片 B，它说「1」；……这样？</p><p><code>阿扣</code>：没错~ 所以我们把结果的输出全部转换成或 0 或 1 的值。激活函数就是用来帮助我们实现这种转化的。</p><p><img src="https://ml4a.github.io/images/figures/sigmoid.png" alt=""></p><p>上面我们用到的激活函数叫做 Sigmoid 函数。它帮我们做到了：</p><ul><li>如果输入值 z 是一个大的正数，函数的输出值为 1；</li><li>如果输入值 z 是一个大的负数，函数的输出值为 0；</li><li>如果输入值 z = 0，那么输出值是 0.5</li></ul><p><code>阿特</code>：也就是说，不论我给什么样的整数，最后都会返回 0 或 1 的结果？</p><p><code>阿扣</code>：没错！这样我们得到分类的结果，或 0 或 1。在深度学习中，这种<strong>把输出转化为我们想要的形式的函数</strong>，我们叫它「激活函数」：</p><blockquote><p>激活函数的主要作用是提供网络的非线性建模能力。如果没有激活函数，即便有再多的隐藏层，其整个网络跟单层神经网络也是等价的。加入激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。</p></blockquote><p>上图就是其中的一种激活函数：sigmoid 函数。</p><p><code>阿特</code>：这么说，激活函数不止一种？</p><p><code>阿扣</code>：对呀。下面我列了一些常用的激活函数，作为今天的补充资料吧。现在可能还看不到，先混个脸熟就好。</p><p><code>阿特</code>：好的先刷脸。</p><h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p>$$ sigmoid(z)= \frac{1}{(1+e​^{−z})} $$</p><p>Sigmoid 函数取值范围为(0,1)，将一个实数映射到(0,1)的区间，可以用来做二分类。</p><p><img src="https://ml4a.github.io/images/figures/sigmoid.png" alt=""></p><p>Sigmoid 在特征相差比较复杂或是相差不是特别大时效果比较好。Sigmoid 的导数最大值为0.25。这意味着用来进行反向传播时，返回网络的 error 将会在每一层收缩至少75％（梯度消失问题）。对于接近输入层的层，如果有很多层， weights 更新会很小。</p><h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><p>$$tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}} $$</p><p>也称为双切正切函数，取值范围为[-1,1]。tanh 在特征相差明显时的效果会很好，在循环过程中会不断扩大特征效果。</p><p><img src="http://mathworld.wolfram.com/images/interactive/TanhReal.gif" alt=""></p><h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>$$ReLU(z) = max(z,0)$$</p><p>ReLU (rectified linear units) 是现在较常用的激活函数。如果输入 &lt; 0，ReLU 输出 0；如果输入 &gt;0，输出等于输入值。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/relu.png" alt=""></p><p>ReLU 计算量小（不涉及除法），一部分神经元的输出为 0 造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。</p><p>ReLU 的缺点是，梯度较大时，ReLU 单元可能大都是 0，产生大量无效的计算（特征屏蔽太多，导致模型无法学习到有效特征）。</p><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>$$ softmax(z) = \frac{e^z{<em>j}}{\sum^K</em>{k=1}e^z{_k}}$$</p><p>Softmax 函数将 K 维的实数向量压缩（映射）成另一个 K 维的实数向量，其中向量中的每个元素取值都介于(0，1)之间。<strong>常用于多分类问题</strong>。Softmax 把分数转换为概率分布，让正确的分类的概率接近 1，其他结果接近 0。相比 Sigmoid，它做了归一化处理。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/N_softmax.png" alt=""></p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101" target="_blank" rel="noopener">Deep Learning Nanodegree | Udacity</a></li><li><a href="https://www.coursera.org/learn/neural-networks-deep-learning" target="_blank" rel="noopener">Neural Networks and Deep Learning | Coursera</a></li><li><a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="noopener">Neural networks and deep learning</a></li><li><a href="http://cs231n.github.io/neural-networks-1/#nn" target="_blank" rel="noopener">Andrej Karpathy’s CS231n course</a></li><li><a href="http://blog.csdn.net/u014595019/article/details/52562159" target="_blank" rel="noopener">深度学习笔记(三)：激活函数和损失函数 - CSDN博客</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>大哉问03 - 什么是赚钱之道？更新你的个人商业模式</title>
    <link href="http://uegeek.com/171216HowToMakeMoney.html"/>
    <id>http://uegeek.com/171216HowToMakeMoney.html</id>
    <published>2017-12-16T11:03:13.000Z</published>
    <updated>2017-12-18T11:44:58.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/dzw03-title.png" alt=""></p><a id="more"></a> <p><a href="http://www.uegeek.com/171112-HowToAskGoodQuestion.html" target="_blank" rel="noopener">大哉问系列</a>讨论完<a href="http://www.uegeek.com/171126TimePerspective.html" target="_blank" rel="noopener">时间</a>和<a href="http://www.uegeek.com/171204HowToLoveYourself.html" target="_blank" rel="noopener">爱</a>，是时候来想想这个重大课题了。</p><p>这篇文章不是经验之谈，而是迟来的反省，也是下一步的行动大纲。</p><h2 id="财富迷思"><a href="#财富迷思" class="headerlink" title="财富迷思"></a>财富迷思</h2><h3 id="为什么要积累财富？"><a href="#为什么要积累财富？" class="headerlink" title="为什么要积累财富？"></a>为什么要积累财富？</h3><p>为了避免话题泛化，这里的「财富」，主要指物质财富、个人的资产。</p><p>有钱当然好。可是到底为什么好？这个问题我们真的有想过吗？到底是什么让我们有持续的动力去追求财富？这是破除迷思的第一个问题。因为赚钱的前提不是方法，而是<strong>欲望</strong>。</p><p>财富可能至少有三方面重要作用：</p><ul><li>提高生活质量：让自己和家人更自如地生活</li><li>缩短成长周期：换取时间，用于自我成长</li><li>获得更多可能性和选择权：贫穷真的真的会限制想象力</li></ul><p>钱越多越好，这毋庸置疑。但是赚钱的目标应该定在哪里合适呢？毕竟人生有限，只花在挣钱上也太枯燥了。大多数人的财务目标大概都会是：实现财务自由。</p><h3 id="什么是财务自由？"><a href="#什么是财务自由？" class="headerlink" title="什么是财务自由？"></a>什么是财务自由？</h3><p>财务自由有客观标准吗？500w？1000w？众说纷纭啊……</p><p>财务自由应该由具体的数值定义吗？我觉得很难。需要找一个定性但可操作的定义。</p><p>这个问题已经有非常多人思考和讨论过了，我比较认同这个目标：</p><blockquote><p>不需要被动出售自己的时间。</p></blockquote><p>换个说法，大概意思是时间都只花在完全由自己选择的事情上面。</p><h3 id="赚钱的瓶颈？"><a href="#赚钱的瓶颈？" class="headerlink" title="赚钱的瓶颈？"></a>赚钱的瓶颈？</h3><p>大部分人（包括我自己）是如何挣钱呢？——批量出售自己的时间（一般是以月为单位）给雇主，然后换取基本固定的薪水——无论干得怎样，薪水的浮动都不大。</p><p>这下子赚钱的天花板就出现了，因为每个人的时间都<strong>极其有限</strong>。</p><p>怎么突破瓶颈呢？一个方法是做薪酬更高的工作。于是我们去增强职场技能、提高工作效率、跳槽到更好的岗位等等，都是在想办法提升单位时间的报酬。</p><p>不过这样也容易掉入时空限制中的「空间」陷阱——「空间」局限意味着影响范围是有限的。一个人的劳动实际上只卖给了一个「空间」：就是这个公司、这个老板。无法 scalable，自然就会遇到瓶颈。（管理很多人是一种 scalable 的办法）</p><h3 id="思考财富的单位？"><a href="#思考财富的单位？" class="headerlink" title="思考财富的单位？"></a>思考财富的单位？</h3><p>想最大限度地保留自己的时间自主权和使用权，该怎么办？</p><p>可以考虑用空间换时间，而不是用时间换金钱。</p><p>怎样用空间换时间呢？——把每单位时间的产出，卖给更多人。</p><p>这里有两个变量：单位时间的产出，和更多人。</p><ul><li>增加单位时间的产出，可以让 1 小时可以写更多好文章、生产更好的产品、打造更完善的系统；也可以尽可能延长产出的寿命，畅销多年而不需要大规模维护。</li><li>同时出售给更多愿意购买的人</li></ul><p>这样，我们思考获得财富的单位，应该是<strong>有价值的结果</strong>，而不再是「月薪」，不再是一去不复返的时间。</p><h2 id="赚钱的三大途径"><a href="#赚钱的三大途径" class="headerlink" title="赚钱的三大途径"></a>赚钱的三大途径</h2><p>赚钱的方法何止千千万，但是<strong>从本质上讲，大概有三类：生产，服务和交易</strong>。</p><p>比如，制造可售卖的商品属于生产，搭建一个付费 APP 是生产；提供专属的理财咨询属于服务；炒币和投资房产属于交易。</p><p>那么上班属于哪一类？其实属于<strong>服务</strong>，因为肉身必需出现，而且离实际购买的消费者比较远，工作报酬受契约约束，而不是实际产出的市场价值本身的体现。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/wealth-title.jpg" alt=""></p><p>再深入一步，让我们想想这三大途径的特点：</p><table><thead><tr><th>方式</th><th>投入</th><th>产出</th><th>买单</th><th>瓶颈</th></tr></thead><tbody><tr><td>生产</td><td>原料，生产设备/技术/流程，销售</td><td>产品</td><td>顾客</td><td>生产率，获客成本</td></tr><tr><td>交易</td><td>资金/成本，决策信息，时间差</td><td>价格差</td><td>需方</td><td>时机，关键信息，资本</td></tr><tr><td>服务</td><td>时间，技能</td><td>交付物</td><td>雇主</td><td>时间，技能，消费频次</td></tr></tbody></table><p>我们的目标是提高赚钱能力，一个思路是从单一途径到覆盖三种途径，另外一个思路是想办法突破每个方式的瓶颈。</p><h3 id="一、优化生产"><a href="#一、优化生产" class="headerlink" title="一、优化生产"></a>一、优化生产</h3><p>什么是生产？有完整、有价值、可购买的产出。</p><p>我们大多数人有可能从来没有从事过正经的「生产」工作，因为我们可能没有想过，或者无法独立提供完整的产出。是的，从来！……细思极恐啊！</p><p>但其实绝大多数人都有个人生产的能力。</p><p>比如，门槛较低的内容生产——以文字、语言、视频等方式产出内容。内容生产的「原料」是什么？是经验，是思考，是感受，是对他人有帮助的对话。生产设备/技术/流程包括什么？构思，收集，整理，编写，修改，设计，发表，互动……瓶颈是什么？没有擅长/有积累的可持续创作的话题，拖延，没有读者……</p><p>这些问题很难解决吗？似乎不是，都有很多办法，而且身边容易找到有经验的人。最大的瓶颈大概是一没有开始，二没有持续，三没有改进。</p><p>尽早尝试适合自己的个人生产方式吧，早积累，早收获。</p><h4 id="升级1：产品化"><a href="#升级1：产品化" class="headerlink" title="升级1：产品化"></a>升级1：产品化</h4><p>产出可以分为两种：需要值守的，无需值守的。</p><p>如果每次生产都需要自己在一旁守着，时间还是被占用了啊。所以生产的第一个升级目标是：产品化。<strong>产品化意味着有明确的人群和需求定义，让生产流程和产出都遵循一定标准，以保证产出的稳定，成为可出售的「产品」</strong>。比如把零散的知识和文章整理成一门课程，录制一次，后期就不需要投入太多精力维护。</p><p>想办法让生产过程自动化，构建属于自己的生产系统，这大概就是个人商业模式的核心。</p><h4 id="升级2：关注生产效率"><a href="#升级2：关注生产效率" class="headerlink" title="升级2：关注生产效率"></a>升级2：关注生产效率</h4><p>生产的第一大指标（或者说瓶颈）就是生产效率。认真思考影响生产效率都有哪些因素。有没有可能通过购买的方式提高生产率？另外要注意，所谓效率，一定与时间周期有关，是否给自己设定了合理、可产生回报的生产周期?</p><h4 id="升级3：选择人群和经营渠道"><a href="#升级3：选择人群和经营渠道" class="headerlink" title="升级3：选择人群和经营渠道"></a>升级3：选择人群和经营渠道</h4><p>谁会购买你的产品？他们在哪里聚集？你在那里是否有影响力？如何获取信任？如何与他们互动？</p><h4 id="升级4：企业化"><a href="#升级4：企业化" class="headerlink" title="升级4：企业化"></a>升级4：企业化</h4><p>一个人再怎么提高效率也是有限的。下一步升级就要靠更多人参与了。以公司经营的方式维持产品的生产、运营和增长，将个人商业模式往公司商业模式迁移。所谓企业家，就是找到资源的更优组织方式，为大家的利益解决问题的人。</p><h3 id="二、优化交易"><a href="#二、优化交易" class="headerlink" title="二、优化交易"></a>二、优化交易</h3><p>成功的交易，大概是提前锚定价格差，寻找价值洼地并持有，并在合适时间出售。</p><p>从今天开始，经常问自己一个问题：</p><blockquote><p>什么会在未来很值钱？</p></blockquote><p><img src="https://cdn.dribbble.com/users/828451/screenshots/3088929/hf001_vestly-05.jpg" alt=""></p><p>投资那些未来很可能增值的资产，可能是公司股票，可能是房产，可能是古董，可能是火星矿产，也可能是——人，尤其是，自己。</p><p>好的交易，关乎资本大小，但更重要的是决策信息，而最最关键的是，时机。</p><p>好的决策来自思考质量和经验。建立起自己的思考模型，积累特定领域的知识和投资经验，这些都需要时间投入。选择合适的交易时机，更是需要了解人性的弱点和各种认知偏差，因为投资本来是件由概率这只大手所操控的事件，而概率实在太反直觉了。</p><p>想要获得更高收益，原理其实并不复杂：</p><p>$收益 = 本金 * (1+复合年化收益率)^{年数}$</p><p><strong>所以，要学好概率，练好头脑，控制风险，培养耐心。</strong></p><p>好吧，如何开始，交易的本金从哪里来？没有太多选择的话，只能从生产来。而且最好保证有持续的生产收益，作为交易的本金，而不是只依靠交易作为唯一的赚钱途径——因为那样太容易影响交易的心态和判断。</p><h3 id="三、优化服务"><a href="#三、优化服务" class="headerlink" title="三、优化服务"></a>三、优化服务</h3><p>服务其实是最特殊的挣钱方式，必需通过本人和服务过程去完成。因为在三种途径里面，这是最消耗时间的，所以更加应该找到优化的方式。</p><p>提高服务的收益的一个可能是，组织一个服务平台，聚集服务供需双方，把服务转化成生产。不过这又属于生产的话题了。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/illustration-04.jpg" alt=""></p><p>既然时间无法复制，那就只能打提高单位时间的服务收益的主意了。影响收益的，似乎最终可以归结为一个因素：稀缺性。</p><p>而稀缺性又由两方面影响：</p><ul><li>需求有多迫切，是不是高频、刚需。这就需要研究雇主/买主的需求了。比如招聘的公司处在什么阶段？最需要什么样的人才？</li><li>独特的核心竞争力组合。找单一领域的专家总是相对容易的，找到复合型大咖难度就高很多，同时横跨多个高速发展的领域，只能是炙手可热了。</li></ul><p>所以，尽早投资在需求会持续增长的服务领域，并且培养自己的独特竞争力、跨界能力，其他就交给时间吧！</p><h2 id="财富积累的放大器"><a href="#财富积累的放大器" class="headerlink" title="财富积累的放大器"></a>财富积累的放大器</h2><p>善用一些已经被反复验证过的原则，能够帮助我们放大为获取财富所付出的努力。</p><h3 id="铁律：生产率-gt-收入-gt-负债"><a href="#铁律：生产率-gt-收入-gt-负债" class="headerlink" title="铁律：生产率 &gt; 收入 &gt; 负债"></a>铁律：生产率 &gt; 收入 &gt; 负债</h3><p><strong>尽可能让个人生产率提升的速度，超过收入增长，远远超过负债的增加。</strong></p><p>这几乎就是个人积累财富的全部秘密了。这个不等式出自下面这个视频：</p><p><a href="https://v.qq.com/x/page/z01685nf12f.html" target="_blank" rel="noopener">三十分钟说清经济机器是怎样运行的</a></p><p>出自 Ray Dalio 大佬的视频把经济的底层规律总结得深入浅出。也许很多大学四年的经济学教育，还没有这十分钟的视频内容深刻且有效。墙裂推荐，值得每半年复习一次。</p><h3 id="善用过去的积累"><a href="#善用过去的积累" class="headerlink" title="善用过去的积累"></a>善用过去的积累</h3><p>不要觉得自己是从零开始。</p><p>如果你在职场有几年经验，不要忽视得到过的职业锻炼：自律，沟通和表达能力，学习能力，合作能力，自我/上下/平级的管理能力，等等。把它们通通用在生产和交易上，并且持续打磨这些技能。能服务好别人的人，更懂得如何生产出好的产品。一直练习交易的人，更容易发现应该在哪些领域持续打造自己的核心竞争力。</p><p>去发现那些在某些领域遍地都是、但是在另一个领域稀缺的东西，从中套利。</p><h3 id="尊重时间的复利"><a href="#尊重时间的复利" class="headerlink" title="尊重时间的复利"></a>尊重时间的复利</h3><p>经常回顾指数增长的曲线吧，那是我们的目标曲线——无论是财富增长也好，个人成长也好。</p><p><img src="https://dare2.dk/demo/wp-content/uploads/2015/09/Exponential-curve.png" alt=""><br>via <a href="https://dare2.dk/top-3-steps-for-becoming-an-exponential-organization/" target="_blank" rel="noopener">Top 3 Steps for Becoming an Exponential Organization | DARE2</a></p><p>不要忽视、低估积累期、平台期的长度和难度，但要想办法加快增长速度，尽快到达「奇点」。</p><h3 id="用财富换幸福"><a href="#用财富换幸福" class="headerlink" title="用财富换幸福"></a>用财富换幸福</h3><p>在积累财富的跑道上，不要忘记我们的目标和初心。赚钱可能没有你想象那么难，它可能没有你想象那么重要。（前提是你已经得到了它）</p><p><strong>实现财务自由是为了什么？获得自由的时间要用来做什么？</strong>这才是真正重要的问题。</p><p>努力赚钱之余，<strong>千万不要忘了发现和保护内在动机，去坚持做那些（现在）不但不能帮你赚钱，还需要你补贴钱或时间去做的事情</strong>，因为那些才是你的心头所好啊！我们这么努力，还不是为了能跟那些事情长相厮守在一起？</p><p>最终的最终，我们换取的可能都是用于创造心流的环境。如果现在就有这样的条件，保留一部分时间去体验创作的心流，还有什么理由不开始呢？</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>总结下来，道理其实都十分简单明了，不过 7 个要点：</p><ul><li>财务自由指不需要被动出售自己的时间，这是赚钱的阶段性目标</li><li>思考财富的单位应该是有价值的结果，而不是时间周期</li><li>生产、交易、服务是挣钱的三大途径</li><li>生产优化：让生产过程自动化，构建属于自己的生产系统</li><li>交易优化：形成有预见性的预判，寻找价值洼地并持有，并在合适时间出售</li><li>服务优化：满足高频、刚需的需求，不断积累出独特的核心竞争力组合</li><li>利用四大财富放大器：财富不等式，过去的积累，时间的复利，财富换幸福</li></ul><p>以及需要经常复习：</p><ul><li>一个问题：什么会在未来很值钱？</li><li>一个图表：指数增长</li><li>一个视频：经济是如何运行的</li></ul><p>好了，我想到的是这些了。</p><p>最后，对自己说：想明白了就去践行吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/dzw03-title.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="CriticalThinking" scheme="http://uegeek.com/tags/CriticalThinking/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="Love" scheme="http://uegeek.com/tags/Love/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：Linear regression 线性回归</title>
    <link href="http://uegeek.com/171213DLN3-LinearRegression.html"/>
    <id>http://uegeek.com/171213DLN3-LinearRegression.html</id>
    <published>2017-12-13T11:02:19.000Z</published>
    <updated>2017-12-18T11:20:12.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：今天带你了解一下线性回归。</p><p><code>阿特</code>：🙄 听起来就不是什么容易懂的东西……为什么要了解线……什么，线性回归呢？</p><p><code>阿扣</code>：什么<a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">机器学习啊深度学习啊</a>，最终目的之一不就是<strong>根据已有数据做出预测</strong>，回归和分类都是「做预测」的主要手段。在下面这张图中找找看，线性回归在机器学习中的位置：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/LinearRegressionInML.png" alt=""></p><p><code>阿特</code>：如果说目的都是做「预测」，回归分析和分类有什么不同呢?</p><p><code>阿扣</code>：<strong>回归得到预测的具体数值</strong>，比如股市的行情、未来的气温值。<strong>而分类得到一个「声明」，或者说对数据打上的标签</strong>。</p><p><code>阿特</code>：那什么是线性回归呢？</p><p><code>阿扣</code>：线性回归是最基础的回归类型，它的定义是这样：</p><blockquote><p>在统计学中，线性回归（Linear regression）是利用线性回归方程的最小平方函数，对一个或多个自变量和因变量之间关系建模的一种回归分析。这种函数是一个或多个回归系数的模型参数的线性组合。</p></blockquote><p><code>阿特</code>：好吧，看不懂……不过我主要不明白的是「回归」的意思，要回哪里哦……</p><p><code>阿扣</code>：初中时学的解方程还记得吧？方程左边有 X，求方程右边的 Y： ax + b =y 。</p><p><code>阿特</code>：这个还是记得的。</p><p><code>阿扣</code>：回归分析假设 X 和 Y 之间是有奸情哦不对是有关系的，用于了解只有一个自变量 X 时，因变量 Y 的变化。</p><ul><li>鬼话版：回归分析用来估计模型的参数，以便最好地拟合数据</li><li>人话版：「回归」的目的呢，就是<strong>找出一个最能够代表所有观测数据的函数，来表示 X 和 Y 的关系</strong>。这个函数只有一个变量，所以是类似这样的一条直线：</li></ul><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/640px-Linear_regression.svg.png?1512632790654" alt=""></p><p><code>阿特</code>：好像我记得那种方程在坐标轴上就是用一条直线来表示。不过怎么基于这条直线做预测呢？</p><p><code>阿扣</code>：其实不是基于这条线，而是 <strong>「找出」这条最符合 X 和 Y 的关系的线 (line of best fit)，认定这就是它们之间的「关系」，然后去做预测</strong>。</p><p>我们先来用符号把这个 X 和 Y 的关系表达式写出来。A 表示我们手上有的数据集，比如你每天的能量摄入和体重值，哈哈哈，然后可以用它来预测你什么时候会变成个胖纸~</p><p><code>阿特</code>：紧脏……</p><p><code>阿扣</code>：来看看这张图，我告诉你每个字母代表什么：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/linearClassifier1.png" alt=""></p><p><code>X</code> 是每天的能量摄入，<code>y</code> 是体重。我们想预测你的未来体重 $\hat y$ (给字母加个帽子一般表示它的预测值)，于是用 能量输入 乘以一个权重(weight) <code>W</code>，加上一个偏置项(bias) <code>b</code>，就是计算体重的函数了。</p><p>$$WX + b = y$$</p><p><code>阿特</code>：好像蛮简单的。</p><p><code>阿扣</code>：是啊。这个式子以后我们还会无数次看到，是老朋友来的。</p><p>关于回归分析，再多说两句。</p><p><code>阿特</code>：我有预感不止 20 句……</p><p><code>阿扣</code>：它有三个主要用途：</p><ul><li>因果分析：确定<strong>自变量对因变量的影响的强度</strong>。比如计算剂量和效应，销售和营销支出，年龄和收入之间的关系。</li><li>预测影响：预测影响或变化的影响，即<strong>因变量随着一个或多个自变量的变化而变化多少</strong>。典型的问题是，「增加一个单位 X， Y 能增加多少？」</li><li>趋势预测：<strong>预测趋势和未来价值</strong>。比如，「从现在起6个月，黄金的价格是多少？」，「任务 X 的总体成本是多少？」</li></ul><p><code>阿特</code>：好像很强大，那它有什么缺点呢？</p><p><code>阿扣</code>：有两个主要的缺点：</p><ul><li>只适用于本身是线性关系的数据</li><li>对 outliner 敏感</li></ul><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/lin-reg-w-outliers.png" alt=""></p><p>比如上图右上角的几个点，偏离平局值比较多，我们叫 outliner。出现这种情况，我们可以试试其他的回归分析类型，或者放弃回归分析，用其他的算法了。</p><table><thead><tr><th>Name</th><th>名称</th><th>因变量个数</th><th>自变量个数</th></tr></thead><tbody><tr><td>Simple linear regression</td><td>简单线性回归</td><td>1</td><td>1</td></tr><tr><td>Multiple linear regression</td><td>多元线性回归</td><td>1</td><td>2+</td></tr><tr><td>Logistic regression</td><td>逻辑回归</td><td>1</td><td>2+</td></tr><tr><td>Ordinal regression</td><td>序数回归</td><td>1</td><td>1+</td></tr><tr><td>Multinominal regression</td><td>多项式回归</td><td>1</td><td>1+</td></tr><tr><td>Discriminant analysis</td><td>判别分析</td><td>1</td><td>1+</td></tr></tbody></table><p>如果需要预测的结果依赖于多个变量，可以用多元线性回归，比如：</p><p>$$y = m_1x_1 + m_2x_2 + b$$</p><p>我们用一个三维平面来表示这个二元线性回归：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/just-a-2d-reg.png" alt=""></p><p><code>阿特</code>：那么多回归类型，不会都要掌握吧？</p><p><code>阿扣</code>：嗯，我们接触比较多的是逻辑回归(Logistic regression)。下回给你讲讲逻辑回归要用到的激活函数吧。</p><p><code>阿特</code>：🐵 </p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.wikiwand.com/zh/%E8%BF%B4%E6%AD%B8%E5%88%86%E6%9E%90" target="_blank" rel="noopener">迴歸分析 - Wikiwand</a></li><li><a href="https://www.wikiwand.com/zh/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8" target="_blank" rel="noopener">線性回歸 - Wikiwand</a></li><li><a href="http://www.statisticssolutions.com/what-is-linear-regression/" target="_blank" rel="noopener">What is Linear Regression? - Statistics Solutions</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
</feed>
