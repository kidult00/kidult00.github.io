<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>00&#39;s Adventure</title>
  
  <subtitle>Why join the navy if you can be a pirate</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://uegeek.com/"/>
  <updated>2018-01-25T08:10:30.322Z</updated>
  <id>http://uegeek.com/</id>
  
  <author>
    <name>kidult00</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DeepLearning笔记：Backpropagation 反向传播算法</title>
    <link href="http://uegeek.com/180125-DeepLearning9-backpropagation.html"/>
    <id>http://uegeek.com/180125-DeepLearning9-backpropagation.html</id>
    <published>2018-01-25T08:00:02.000Z</published>
    <updated>2018-01-25T08:10:30.322Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：今天我们来学习反向传播算法。</p><p><code>阿特</code>：为什么你一脸严肃哦？</p><p><code>阿扣</code>：咳咳，有吗……可能因为当初被 Backpropagation 这个词吓得不轻吧…… 反向传播算法是深度学习的核心之一，不过也没有很难，放轻松~</p><p><code>阿特</code>：你是说你还是说我 😄</p><p><code>阿扣</code>：来，我们先回忆一下，对多层神经网络，我们用梯度下降法去训练。之前已经学过如何计算输出节点的误差项 $\delta =(y-\hat y)f’(h)$，借助梯度下降算法，用误差项训练<strong>隐层到输出层的权重</strong>。</p><p><code>阿特</code>：隐层到输出层。我记得最简单的神经网络应该有 3 层——是不是还有输入层到隐层？</p><p><code>阿扣</code>：没错。</p><p><code>阿特</code>：那该怎么求隐层节点对应的误差项呢？</p><p><code>阿扣</code>：在神经网络里，输出节点的误差项，跟隐层的权重是成比例的。</p><p><code>阿特</code>：意思是误差项越大，隐层节点的权重也越大？</p><p><code>阿扣</code>：可以这么理解。既然我们知道输出的误差项，就可以用它来「反向传播」，求出隐层的误差项，再用于求输入节点的权重。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/vlcsnap-2017-12-19-15h02m16s033.png" alt=""></p><p><code>阿特</code>：咦，那不是反过来了？先知道输出结果，再反推输入权重？</p><p><code>阿扣</code>：对的，所以叫做「反向」呀。</p><p>比如，输出层 k 个节点对应的误差项是 $\delta^o_k$ 。隐层有 j 个节点，那么隐层节点到输出节点的 j 个误差项是：</p><p>$\delta^h<em>j=\sum W</em>{jk} \delta^o_k f’(h_j)$</p><p><code>阿特</code>：等等！先让我复习一下误差项是什么……</p><p><code>阿扣</code>：嗯！误差项 δ 表示 <code>误差 * 激活函数的导数</code>，$\delta_j=(y-\hat y)f’(h_j)$。对比一下 $\delta^h<em>j=\sum W</em>{jk} \delta^o_k f’(h_j)$，看看有什么不同？</p><p><code>阿特</code>：隐层到输出层的误差 (y-y^) 变成了 $\sum W_{jk} \delta^o_k$</p><p><code>阿扣</code>：很棒！你发现了吧，$\delta_k$ 成为了 wx + b 中的变量 x：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/vlcsnap-2017-12-19-15h06m32s756.png" alt=""></p><p><code>阿特</code>：啊，又要来算这个了……</p><p><code>阿扣</code>：没关系，虽然看上去麻烦一些，但是跟正向传播的做法很类似，权重的更新为 $\Delta w_{ij}=\eta \delta^h_jx_i$ 。</p><p><code>阿特</code>：每次都要来一遍，要死不少脑细胞啊……</p><p><code>阿扣</code>：那我给你列个清单吧，每次照着做就好。</p><p>假设我们考虑最简单的神经网络：只有一个隐层节点，只有一个输出节点。用反向传播算法更新权重的算法如下：</p><ul><li>给每一层的权重赋值为 0<ul><li>输入层→隐层的权重 $\Delta w_{ij}=0$</li><li>隐层→输出层的权重 $\Delta W_j=0$<br>​</li></ul></li><li>对训练集里的每一个数据：<ul><li>使用 forward pass，计算输出节点的值 $\hat y$</li><li>计算输出节点的误差梯度 $\delta^o=(y-\hat y)f’(z)$，  这里的 $z=\sum_jW_ja_j$</li><li>将误差反向传递到隐层 $\delta^h_j=\delta^oW_jf’(h_j)$</li><li>更新权重步长<ul><li>$\Delta W_j = \Delta W_j + \delta^oa_j$</li><li>$\Delta w<em>{ij} = \Delta w</em>{ij} + \delta^h_ja_i$</li></ul></li></ul></li><li>更新权重（η 为学习率，m 为输入节点的个数):<ul><li>$W_j = W_j + \eta \Delta W_j /m$</li><li>$w<em>{ij} = w</em>{ij} + \eta \Delta w_{ij} /m$</li></ul></li><li>重复 e 次训练步骤 (epochs)</li></ul><p><code>阿特</code>：天！看上去好复杂。</p><p><code>阿扣</code>：练习两次就能熟悉起来了，别担心。下一次我带你用 Python 实现反向传播算法。</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101" target="_blank" rel="noopener">Deep Learning Nanodegree | Udacity</a></li><li><a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" target="_blank" rel="noopener">Yes you should understand backprop – Medium</a></li><li><a href="https://www.youtube.com/watch?v=59Hbtz7XgjM" target="_blank" rel="noopener">CS231n Winter 2016 Lecture 4 Backpropagation, Neural Networks 1-Q_UWHTY_TEQ.mp4 - YouTube</a></li></ul><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DeepLearning笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DeepLearning笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DeepLearning笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DeepLearning笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DeepLearning笔记：Cost function 损失函数</a></li><li><a href="http://www.uegeek.com/171222DLN6-GradientDescent.html" target="_blank" rel="noopener">DeepLearning笔记：梯度下降 Gradient Descent</a></li><li><a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">DeepLearning笔记：用 python 实现梯度下降的算法</a></li><li><a href="http://www.uegeek.com/180104DeepLearning8-MultiLayer-Perceptrons.html" target="_blank" rel="noopener">DeepLearning笔记：多节点神经网络</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="神经网络" scheme="http://uegeek.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="Backpro" scheme="http://uegeek.com/tags/Backpro/"/>
    
      <category term="反向传播" scheme="http://uegeek.com/tags/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    
  </entry>
  
  <entry>
    <title>码以致用03 - 用 Pandas 分析爬虫抓取的数据</title>
    <link href="http://uegeek.com/180118-python-pandas-data-analysis.html"/>
    <id>http://uegeek.com/180118-python-pandas-data-analysis.html</id>
    <published>2018-01-18T09:04:46.000Z</published>
    <updated>2018-01-18T09:10:00.561Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg" alt=""></p><a id="more"></a> <p>上一篇，我们<a href="http://www.uegeek.com/180112python-scrapy-jdxl.html" target="_blank" rel="noopener">用 Scrapy 从简单心理网站上抓取了心理咨询师的信息</a>。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapyOutput.png" alt=""></p><p>接下来试着分析一下咨询师的价格。</p><h3 id="如何去掉某一列中不需要的字符？"><a href="#如何去掉某一列中不需要的字符？" class="headerlink" title="如何去掉某一列中不需要的字符？"></a>如何去掉某一列中不需要的字符？</h3><p>在 <code>price</code> 列中，数据格式是 <code>600 元/次</code>。很明显，中文字符会给统计价格带来不便，需要想办法去掉。</p><ul><li>取 <code>price</code> 列：<code>df[&#39;name&#39;]</code></li><li>去掉<code>元/次</code> 字符：<code>str.rstrip()</code></li><li>把剩下字符转换成数字：<code>pd.to_numeric</code></li></ul><p>Pandas 语句可以这样写：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'price'</span>].str.rstrip(<span class="string">'元/次'</span>).apply(pd.to_numeric)</span><br></pre></td></tr></table></figure><p>结果：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-01-18%20at%203.53.32%20PM.png" alt=""></p><h3 id="如何统计价格？"><a href="#如何统计价格？" class="headerlink" title="如何统计价格？"></a>如何统计价格？</h3><p>用 Pandas 做基本的数据统计如均值、最大值、最小值等，非常方便，分别用 <code>mean()</code>, <code>max()</code>, <code>min()</code>就可以：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"平均价格：&#123;:.1f&#125;元 \n最高价格：&#123;&#125;元 \n最低价格：&#123;&#125;元"</span>.format(df[<span class="string">'price'</span>].mean(),df[<span class="string">'price'</span>].max(),df[<span class="string">'price'</span>].min()))</span><br></pre></td></tr></table></figure><ul><li>平均价格：570.9元 </li><li>最高价格：3000元 </li><li>最低价格：100元</li></ul><p>另外，Pandas 还提供了 <code>describe()</code> 函数，快速给出概要统计值：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-01-18%20at%203.57.36%20PM.png" alt=""></p><p>然后单独取出收费最高和最低的咨询师资料：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df.loc[df[<span class="string">'price'</span>].idxmax()]</span><br><span class="line">df.loc[df[<span class="string">'price'</span>].idxmin()]</span><br></pre></td></tr></table></figure><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-01-18%20at%203.58.52%20PM.png" alt=""></p><h3 id="如何统计咨询师介绍里的词频？"><a href="#如何统计咨询师介绍里的词频？" class="headerlink" title="如何统计咨询师介绍里的词频？"></a>如何统计咨询师介绍里的词频？</h3><p><strong>方法 1 ：用 jieba 分词，用 Counter 统计</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单独导出咨询师介绍列</span></span><br><span class="line">df[<span class="string">'info'</span>].to_csv(<span class="string">'info.txt'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'info.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line"></span><br><span class="line">wordlist = Counter()</span><br><span class="line">words = jieba.cut(text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    <span class="keyword">if</span> len(word) &gt; <span class="number">1</span>: </span><br><span class="line">        wordlist[word] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_cloud_word</span><span class="params">()</span>:</span></span><br><span class="line">    words = []</span><br><span class="line">    <span class="keyword">for</span> word,cnt <span class="keyword">in</span> wordlist.most_common(<span class="number">30</span>):</span><br><span class="line">        words.append(word)</span><br><span class="line">    <span class="keyword">return</span> words</span><br></pre></td></tr></table></figure><p>列出前 30 个高频词：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Screen%20Shot%202018-01-18%20at%204.10.14%20PM.png" alt=""></p><p><strong>方法 2 ：用 wordcloud 直接制作标签云</strong></p><p>word cloud 是一个 python 的标签云生成库，可以直接输入文本，得到标签云图片，还可以定制图片形状和颜色，小巧好用。(<a href="https://github.com/amueller/word_cloud" target="_blank" rel="noopener">https://github.com/amueller/word_cloud</a>)</p><p>结合 matplotlib，很快就可以画出高频词的标签云：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format=<span class="string">'retina'</span></span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud, ImageColorGenerator</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">d = path.dirname(<span class="string">'info.txt'</span>)</span><br><span class="line"><span class="comment"># 设置字体</span></span><br><span class="line">font = <span class="string">r'/Users/kidult/Library/Fonts/MFKeSong_Noncommercial-Regular.TTF'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Read the whole text</span></span><br><span class="line">text = open(path.join(d, <span class="string">'info.txt'</span>)).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 排除词</span></span><br><span class="line">stopwords=(<span class="string">'Dr'</span>,<span class="string">'of'</span>,<span class="string">'to'</span>,<span class="string">'and'</span>,<span class="string">'The'</span>,<span class="string">'in'</span>,<span class="string">'zx'</span>,<span class="string">'至今'</span>,<span class="string">'中国'</span>,<span class="string">'同时'</span>,<span class="string">'当然'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用图片截取并取色</span></span><br><span class="line">heart_coloring = np.array(Image.open(path.join(d, <span class="string">"heart.png"</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate a word cloud image</span></span><br><span class="line">wordcloud = WordCloud(max_words=<span class="number">80</span>, background_color=<span class="string">'white'</span>, mask=heart_coloring,</span><br><span class="line">                      max_font_size=<span class="number">60</span>, relative_scaling=<span class="number">0.4</span>, font_path=font,stopwords=stopwords, random_state=<span class="number">42</span>)</span><br><span class="line">wordcloud.generate(text)</span><br><span class="line"></span><br><span class="line">image_colors = ImageColorGenerator(heart_coloring)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">8</span>))</span><br><span class="line">plt.axis(<span class="string">"off"</span>)</span><br><span class="line">plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=<span class="string">"bilinear"</span>);</span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxl-wordcloud.png" alt=""></p><p>完整的 Jupyter Notebook，请查看 <a href="https://github.com/kidult00/scrapy-jdxl/blob/master/jdxl/output/jdxl_experts_analysis.ipynb" target="_blank" rel="noopener">00 的 Github</a>。</p><iframe src="http://nbviewer.jupyter.org/github/kidult00/scrapy-jdxl/blob/master/jdxl/output/jdxl_experts_analysis.ipynb" width="780" height="500"></iframe><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="http://blog.csdn.net/weixin_37226516/article/details/64134643" target="_blank" rel="noopener">PANDAS 数据合并与重塑（concat篇） - CSDN博客</a></li><li><a href="http://blog.csdn.net/u010770993/article/details/70312506" target="_blank" rel="noopener">初学pandas（八）条件选取行的便捷… - CSDN博客</a></li><li><a href="http://blog.csdn.net/zhili8866/article/details/68134481" target="_blank" rel="noopener">pandas数据清洗，排序，索引设置，数据选取 - CSDN博客</a></li><li><a href="https://github.com/amueller/word_cloud" target="_blank" rel="noopener">amueller/word_cloud: A little word cloud generator in Python</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="爬虫" scheme="http://uegeek.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="http://uegeek.com/tags/Scrapy/"/>
    
      <category term="Pandas" scheme="http://uegeek.com/tags/Pandas/"/>
    
      <category term="数据分析" scheme="http://uegeek.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>大哉问06 - 学习中最应该养成什么习惯？</title>
    <link href="http://uegeek.com/180113-first-principle-of-learning.html"/>
    <id>http://uegeek.com/180113-first-principle-of-learning.html</id>
    <published>2018-01-13T11:35:45.000Z</published>
    <updated>2018-01-13T11:43:49.424Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇大哉问我们讨论了这个问题：<a href="http://www.uegeek.com/180106-the-learning-myth.html" target="_blank" rel="noopener">什么是学习中最大的误区？</a></p><blockquote><p>以为学习的行动，就是学习本身</p></blockquote><p>学习是以改变为目的的一系列探索活动。如果改变没有发生，没有形成新的视角或行动或规则，那么学习基本上可以说无效。</p><p>明确了应该避开「不改变」这个误区，那么下一个大问题来了：</p><blockquote><p>什么是学习中最应该养成的习惯？</p></blockquote><p>00 思考了很久，目前的回答是：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HabitOfStudy.png" alt=""></p><a id="more"></a> <h2 id="学习是一种训练"><a href="#学习是一种训练" class="headerlink" title="学习是一种训练"></a>学习是一种训练</h2><p>学习不是看书、做实验这些行为本身，<strong>学习是围绕目标和薄弱点的「训练」，它们指向思想或行动的改变。</strong></p><p>学习不是孤立的阅读、孤立的理解、孤立的运用，一个学习的「迭代」包括：</p><blockquote><p>设定目标 - 模块拆解 - 刻意练习 - 评估调整</p></blockquote><p>完整的学习由很多个迭代循环构成，迭代的结果是行为改变。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/rethinkingLearning.png" alt=""></p><h2 id="向机器学习「学习」"><a href="#向机器学习「学习」" class="headerlink" title="向机器学习「学习」"></a>向机器学习「学习」</h2><p>最近在学习机器学习和深度学习。机器如何学习给我非常多启发。</p><p>机器的学习为什么高效？除了它计算能力超强、根本不会疲劳以外，它们学习的方法——所谓算法——都是最聪明的人类精心设计的。</p><p>深度学习的基本思路是：</p><ul><li>设定目标 Y</li><li>找到真实数据集（包含自变量 x 和输出值 y）</li><li>给出初始模型，喂入真实数据集</li><li>观察模型输出的损失（目标 Y 和实际值 y 的差值）</li><li>调整模型参数，使损失函数最小</li><li>（重复循环）</li><li>达到目标 Y ，停止训练</li></ul><p><img src="https://viniciusarruda.github.io/images/mp_neuron.png" alt=""></p><p><img src="https://cdn-images-1.medium.com/max/880/1*fbMYoMRFR_Mr8tNoFI0_Jw.jpeg" alt=""></p><p>再打开「刻意练习」这本书复习一下。</p><p>刻意练习聚焦于提高绩效和表现，它的特点：</p><ul><li>有定义明确的特定目标</li><li>专注的</li><li>包含反馈</li><li>需要走出舒适区</li><li>产生有效的心理表征</li><li>构建或修改那些过去已经获得的技能</li></ul><p>See? 机器学习完全遵守了这些规则，能不高效吗？！</p><h2 id="GEXTE-：学习循环的模板"><a href="#GEXTE-：学习循环的模板" class="headerlink" title="GEXTE ：学习循环的模板"></a>GEXTE ：学习循环的模板</h2><p>事不宜迟，在我们下一个学习计划，启用 00 为你准备的「GEXTE 学习循环模板」吧！</p><p>在定义一个学习项目时，我们需要把学习的循环拆分成几个部分：</p><p><strong>目标是什么？怎么评估做到了？可以拆分为哪些训练模块？模仿什么？训练步骤是？</strong></p><table><thead><tr><th>代号</th><th>循环项</th><th>定义</th><th>每次循环时</th></tr></thead><tbody><tr><td>G</td><td>目标 / Goal</td><td>明确可描述的目标，从现状 A 到终点 B</td><td>回顾目标</td></tr><tr><td>E</td><td>评估方法 / Error</td><td>如何评估是否达成目标</td><td>获得反馈</td></tr><tr><td>X</td><td>技能模块 / X</td><td>影响 Error 的模块、技能点</td><td>检查是否有遗漏</td></tr><tr><td>T</td><td>模仿对象 / Target</td><td>具体的模仿对象和结果</td><td>比较的结果差别</td></tr><tr><td>E</td><td>单次训练 / Epoch</td><td>每一次训练要做什么</td><td>调整行动或目标</td></tr></tbody></table><p>可打印的模板也做好了。HackYourself 公众号回复 「学习模板」即可获得：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/GEXTE_Template.png" alt=""></p><p>看吧，学习是远比我们想象要复杂但也更有趣的挑战。不妨在每个循环后面，增加一些奖励来激励自己。</p><p>虽然正儿八经地学个什么颇费力，但总比数十年喊着口号却原地打转强得多，是不是？</p><p>下面来看两个例子：编程学习和产品决策能力训练。</p><h2 id="栗子1：学习用-Processing-模拟自然现象"><a href="#栗子1：学习用-Processing-模拟自然现象" class="headerlink" title="栗子1：学习用 Processing 模拟自然现象"></a>栗子1：学习用 Processing 模拟自然现象</h2><p>Processing 是基于 Java 的一套编程语言和环境，有很强的图形、动画生成能力，被称为「设计师的编程语言」。现在我们就来尝试用 GEXTE 模板定义完整的学习循环。</p><h3 id="G-目标"><a href="#G-目标" class="headerlink" title="G 目标"></a>G 目标</h3><blockquote><p>目标1：学习如何用代码可视化表达随机性、力与运动、震荡、粒子、分形等自然现象</p></blockquote><p>现状 A</p><ul><li>不了解模拟自然现象的算法</li><li>不知道如何用 Processing 实现</li></ul><p>终点 B</p><ul><li>能用基础的公式表示自然现象背后的数学和物理原理</li><li>用 Processing 实现动画程序</li></ul><blockquote><p>目标2：练习巩固 Python 语法</p></blockquote><p>现状 A</p><ul><li>会基本的 Python 语法</li><li>能看懂简单的 Java 程序</li></ul><p>终点 B：用 Python 实现 Processing 动画程序</p><h3 id="E-评估"><a href="#E-评估" class="headerlink" title="E 评估"></a>E 评估</h3><p>用 processing.py 实现模拟自然现象的动画程序</p><ul><li>程序运行结果是否如预期</li><li>抄程序：Java 没问题但 Python 有问题的地方，是需要加强的薄弱点</li><li>重写程序<ul><li>是否理解原理</li><li>是否理解 Processing 如何实现</li><li>是否理清实现的思路</li></ul></li></ul><h3 id="X-模块"><a href="#X-模块" class="headerlink" title="X 模块"></a>X 模块</h3><ul><li>自然现象的原理</li><li>Processing 语法和模块</li><li>Python 语法</li><li>debug 方法</li></ul><h3 id="T-对象"><a href="#T-对象" class="headerlink" title="T 对象"></a>T 对象</h3><p>「The Nature of Code」配套视频和例子</p><h3 id="E-训练"><a href="#E-训练" class="headerlink" title="E 训练"></a>E 训练</h3><ul><li>看 youtube 视频和书，学习自然现象的原理</li><li>看 Java 代码</li><li>用 Python 抄一遍</li><li>用 Python 自己写一遍</li><li>填写训练反馈</li><li>完成 9 个单元，把所有例子翻译成 python 版本</li></ul><h3 id="Bonus"><a href="#Bonus" class="headerlink" title="Bonus"></a>Bonus</h3><ul><li>上传 NOC python version 到 Github</li><li>每一章实现一个有意思的小动画</li></ul><p>上面这个例子可能比较特殊，因为学习对象是界定非常明确的编程练习，学习产出也容易评估。</p><p>下面再举一个不太容易定义的例子。</p><h2 id="栗子2：产品决策能力训练"><a href="#栗子2：产品决策能力训练" class="headerlink" title="栗子2：产品决策能力训练"></a>栗子2：产品决策能力训练</h2><h3 id="G-目标-1"><a href="#G-目标-1" class="headerlink" title="G 目标"></a>G 目标</h3><p>提升决策的质量并优化决策的流程</p><h3 id="E-评估-1"><a href="#E-评估-1" class="headerlink" title="E 评估"></a>E 评估</h3><p>决策是否达到预期目标</p><h3 id="X-模块-1"><a href="#X-模块-1" class="headerlink" title="X 模块"></a>X 模块</h3><ul><li>逻辑思维、抽象、演绎、分析、综合等能力</li><li>决策信息的收集</li><li>提炼、表达和沟通能力</li><li>决策落地</li><li>评估标准制定和信息收集</li></ul><h3 id="T-对象-1"><a href="#T-对象-1" class="headerlink" title="T 对象"></a>T 对象</h3><ul><li>自己的决策：拥有最全面的信息，方便评估</li><li>上级/团队的决策：观察、评估上级或团队的决策，也是绝佳的练习机会</li></ul><h3 id="E-训练-1"><a href="#E-训练-1" class="headerlink" title="E 训练"></a>E 训练</h3><ul><li>决策问题产生和定义</li><li>情报收集和分析</li><li>决策制定和描述</li><li>推进和项目组织</li><li>结果评估</li><li>决策方法总结</li></ul><p>每一步可能还有很多细分的练习模块，这里就不具体展开，产品同学们开启脑洞吧。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HabitOfStudy.png" alt=""></p><p>打造有效的学习循环很难，几乎就像是打造一个产品循环。</p><p>这也就是为什么学习容易成为西西弗斯式壮（xiao）举（hua）的原因。因为富有成效的学习，太不符合大脑喜欢最短路径的构造，所以我们总是自欺自人。</p><p>但总有一些奖赏，要在经历之后才深明其义。</p><blockquote><p>One of the first rules of science is if somebody delivers a secret weapon to you, you better use it. — Herbert Simon</p></blockquote><hr><p>HackYourself 学习专题：</p><ul><li><a href="http://www.uegeek.com/180106-the-learning-myth.html" target="_blank" rel="noopener">大哉问05 - 什么是学习中最大的误区？</a></li><li><a href="http://www.uegeek.com/learning-about-learn.html" target="_blank" rel="noopener">重启学习系统，做个知识炼金术士</a></li><li><a href="http://www.uegeek.com/learning-guide-v1.html" target="_blank" rel="noopener">知识炼金术士行动指南 1.0</a></li><li><a href="http://www.uegeek.com/mindlego1.html" target="_blank" rel="noopener">心智乐高01 - 寻找智慧组块</a></li><li><a href="http://www.uegeek.com/effective-learning.html" target="_blank" rel="noopener">别傻了，傲娇大脑爱学习？</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇大哉问我们讨论了这个问题：&lt;a href=&quot;http://www.uegeek.com/180106-the-learning-myth.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;什么是学习中最大的误区？&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;以为学习的行动，就是学习本身&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;学习是以改变为目的的一系列探索活动。如果改变没有发生，没有形成新的视角或行动或规则，那么学习基本上可以说无效。&lt;/p&gt;
&lt;p&gt;明确了应该避开「不改变」这个误区，那么下一个大问题来了：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;什么是学习中最应该养成的习惯？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;00 思考了很久，目前的回答是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/HabitOfStudy.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="学习" scheme="http://uegeek.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="方法" scheme="http://uegeek.com/tags/%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>码以致用02 - 用 Scrapy 爬虫抓取简单心理咨询师资料</title>
    <link href="http://uegeek.com/180112python-scrapy-jdxl.html"/>
    <id>http://uegeek.com/180112python-scrapy-jdxl.html</id>
    <published>2018-01-12T11:33:34.000Z</published>
    <updated>2018-01-12T11:41:02.009Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg" alt=""></p><a id="more"></a> <h2 id="目标和步骤"><a href="#目标和步骤" class="headerlink" title="目标和步骤"></a>目标和步骤</h2><p>爬虫目标：从简单心理网站上抓取心理咨询师列表和信息。</p><p>学习目标：</p><ul><li>熟悉 Scrapy 框架，理解如何使用</li><li>初步掌握 xpath 语法</li><li>导出爬取信息为 csv</li><li>用 Pandas 查看和清理数据</li></ul><p><a href="http://jiandanxinli.com" target="_blank" rel="noopener">简单心理网站</a>上有「咨询咨询」和「精神科顾问」两类专家，这里先尝试抓取咨询师资料。</p><p>咨询师展示列表比较简单，一共有 49 页，每页有 10 或 11 个咨询师（真是有点坑……）。抓取每页上的信息即可。</p><p>步骤分解：</p><ul><li>抓取每一页上面所有咨询师的信息，包括姓名、简介、地点、咨询方式、地点、价格等</li><li>按页面顺序抓取全部咨询师资料</li><li>导出信息为 csv</li><li>用 pandas 查看信息</li></ul><h2 id="新建项目和爬虫"><a href="#新建项目和爬虫" class="headerlink" title="新建项目和爬虫"></a>新建项目和爬虫</h2><p><a href="http://www.uegeek.com/180108python-scrapy-introduction.html" target="_blank" rel="noopener">上一篇</a>已经介绍过 Scrapy 爬虫框架和如何新建 Python 虚拟环境。现在来新建一个 Scrapy 爬虫项目：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject jdxl</span><br></pre></td></tr></table></figure><p>Scrapy 生成了以下文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">├── jdxl</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       └── __init__.py</span><br><span class="line">└── scrapy.cfg</span><br></pre></td></tr></table></figure><p>我们在 <code>spiders</code> 文件夹里新建爬虫文件 <code>counselor.py</code>。</p><p>然后在 <code>items.py</code> 里面定义要抓取的项目：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JdxlItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    name = scrapy.Field() <span class="comment">#姓名</span></span><br><span class="line">    url = scrapy.Field() <span class="comment">#链接</span></span><br><span class="line">    info = scrapy.Field() <span class="comment">#简介</span></span><br><span class="line">    zx_type = scrapy.Field() <span class="comment">#咨询类型</span></span><br><span class="line">    location = scrapy.Field() <span class="comment">#地点</span></span><br><span class="line">    price = scrapy.Field() <span class="comment">#价格</span></span><br></pre></td></tr></table></figure><h2 id="抓取页面信息"><a href="#抓取页面信息" class="headerlink" title="抓取页面信息"></a>抓取页面信息</h2><p>打开爬虫 <code>counselor.py</code>，开始写爬取的程序。</p><p>不要忘记先 import 上面定义好对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> jdxl.items <span class="keyword">import</span> JdxlItem</span><br></pre></td></tr></table></figure><h3 id="问题1：如何设置起始-URL？"><a href="#问题1：如何设置起始-URL？" class="headerlink" title="问题1：如何设置起始 URL？"></a>问题1：如何设置起始 URL？</h3><p>打开<a href="https://www.jiandanxinli.com/experts" target="_blank" rel="noopener">心理咨询师列表页面</a>，然后翻到第二页，发现 url 是很长的一串：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://www.jiandanxinli.com/experts?filter%5Bcity_id%5D=&amp;filter%5Bfield_id%5D=&amp;filter%5Bgender%5D=&amp;filter%5Bonly_available%5D=&amp;filter%5Bonly_junior%5D=&amp;filter%5Bonly_online%5D=&amp;filter%5Bprice%5D=&amp;filter%5Bq%5D=&amp;filter%5Bsect_id%5D=&amp;filter%5Btarget_id%5D=&amp;filter%5Btime%5D=&amp;filter%5Btype_id%5D=&amp;page=2</span><br></pre></td></tr></table></figure><p>中间都是传递的筛选参数，只有最后 <code>&amp;page=2</code> 才是关键。也就是说抓取的页面URL是这样的：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">https://www.jiandanxinli.com/experts?&amp;page=1</span><br><span class="line">https://www.jiandanxinli.com/experts?&amp;page=2</span><br><span class="line">...</span><br><span class="line">https://www.jiandanxinli.com/experts?&amp;page=49</span><br></pre></td></tr></table></figure><p>在 <code>class JdxlSpider(scrapy.Spider):</code> 下面开始定义起始 URL：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">allowed_domains = [<span class="string">"jiandanxinli.com"</span>]</span><br><span class="line">   start_urls = [<span class="string">'http://jiandanxinli.com/experts'</span>]</span><br><span class="line">   start_url_list = []</span><br><span class="line"></span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">50</span>):</span><br><span class="line">       start_url_list.extend([<span class="string">'http://jiandanxinli.com/experts?&amp;page='</span> + str(i)])</span><br><span class="line"></span><br><span class="line">   start_urls = start_url_list</span><br></pre></td></tr></table></figure><h3 id="问题2：如何抓取一个节点的信息"><a href="#问题2：如何抓取一个节点的信息" class="headerlink" title="问题2：如何抓取一个节点的信息"></a>问题2：如何抓取一个节点的信息</h3><p>在 <code>def parse(self, response):</code> 函数中定义要抓取内容，用 <a href="https://www.wikiwand.com/en/XPath" target="_blank" rel="noopener">XPath</a> 语法告诉爬虫要抓取的节点位置。</p><p>什么是「叉怕死」呢？</p><blockquote><p>XPath (XML Path Language) is a query language for selecting nodes from an XML document. In addition, XPath may be used to compute values (e.g., strings, numbers, or Boolean values) from the content of an XML document. —— Wiki</p></blockquote><p>那怎么写 XPath 呢？</p><p>感谢 Chrome，直接提供了 XPath 选取功能。对需要抓取的位置单击右键，点击 <code>Inspect</code>，打开 chrome-devtools 面板：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapy1.png" alt=""></p><p>对准要抓取的节点，再次右键，点击 <code>Copy XPath</code>，XPath 路径就复制好了。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapy2.png" alt=""></p><p>别高兴得太早，在调试坑里跌倒无数次的 00 颤抖地告诉你：<strong>直接复制的 XPath 往往不能直接用……</strong></p><p>比如上面的咨询师姓名这里，chrome 提供的路径是：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">//*[@id="content_wrapper"]/div[2]/div[2]/a[5]/div[1]/strong/text()</span><br></pre></td></tr></table></figure><p>但更准确的路径是：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/div[@class="summary"]/strong/text()</span><br></pre></td></tr></table></figure><p>.</p><p>对初学者来说，如果之前没有太多写 html 和 css 的经验，每一个 xpath 都需要摸索好半天。不过这也是必经之路吧。折腾多了，就学会老老实实去看 <a href="https://www.w3schools.com/xml/xpath_intro.asp" target="_blank" rel="noopener">XPath 的文档</a>了。</p><h3 id="问题3：内容没有节点怎么办？"><a href="#问题3：内容没有节点怎么办？" class="headerlink" title="问题3：内容没有节点怎么办？"></a>问题3：内容没有节点怎么办？</h3><p>抓到咨询师的咨询方式、地点、价格等信息的时候，坑爹的事情来了。</p><p>这一坨的结构是：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapy3.png" alt=""></p><p>文字竟然没有包括在标签之内！前后都是个 i 标签！要怎么抓！</p><p>然后开始了漫漫 Google 之路。最后终于找到了这篇：<a href="https://www.zhihu.com/question/38080188" target="_blank" rel="noopener">如何用scrapy提取不在标签内的文字？</a></p><p>用 <code>following::text()</code> 的方式抓取了几个信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zx_type = response.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">1</span>]</span><br><span class="line">location = response.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">2</span>]</span><br><span class="line">price = response.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">3</span>]</span><br></pre></td></tr></table></figure><p>这样必需是每一栏信息都没有缺少，否则抓取就会错位……暂时这么处理吧 &gt;.&lt;</p><h3 id="问题4：如何抓取多个专家信息"><a href="#问题4：如何抓取多个专家信息" class="headerlink" title="问题4：如何抓取多个专家信息"></a>问题4：如何抓取多个专家信息</h3><p>抓取好一个专家的信息后，要怎么把每个页面 10~11 个专家的信息都抓下来呢？看了页面的 html，每个专家都在 <code>&lt;a class=&quot;expert&quot; ...&gt;</code> 标签下面。于是用循环获取所有带有这个特征的标签。</p><p>为了缩小范围，在 <code>response.xpath(&#39;//a[@class=&quot;expert&quot;]&#39;)</code> 就传入了父节点的路径。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> each <span class="keyword">in</span> response.xpath(<span class="string">'//a[@class="expert"]'</span>):</span><br><span class="line">    print(each)</span><br><span class="line">    item = JdxlItem()</span><br><span class="line">    <span class="comment"># 抓取姓名</span></span><br><span class="line">    item[<span class="string">'name'</span>] = each.xpath(<span class="string">'./div[@class="summary"]/strong/text()'</span>).extract()</span><br><span class="line">    <span class="comment"># 抓取 url</span></span><br><span class="line">    item[<span class="string">'url'</span>] = each.xpath(<span class="string">'./@href'</span>).extract()</span><br><span class="line">    <span class="comment"># 抓取简介</span></span><br><span class="line">    item[<span class="string">'info'</span>] = each.xpath(<span class="string">'./div[@class="summary"]//div[@class="content"]/text()'</span>).extract()</span><br><span class="line">    <span class="comment"># 抓取咨询方式、地点、价格等</span></span><br><span class="line">    item[<span class="string">'zx_type'</span>] = each.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">1</span>]</span><br><span class="line">    item[<span class="string">'location'</span>] = each.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">2</span>]</span><br><span class="line">    item[<span class="string">'price'</span>] = each.xpath(<span class="string">'./div[@class="info"]/i/following::text()'</span>).extract()[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><h2 id="其他配置"><a href="#其他配置" class="headerlink" title="其他配置"></a>其他配置</h2><p>在 <code>settings.py</code> 文件里添加模拟 user_agent 的模块（需要先 pip 安装 faker 包）、设置爬取间隔、头信息等：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> faker <span class="keyword">import</span> Factory</span><br><span class="line">f = Factory.create()</span><br><span class="line">USER_AGENT = f.user_agent()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">DOWNLOAD_DELAY = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">DEFAULT_REQUEST_HEADERS = &#123;</span><br><span class="line">    <span class="string">'Host'</span>: <span class="string">'www.jiandanxinli.com'</span>,</span><br><span class="line">    <span class="string">'Accept'</span>: <span class="string">'*/*'</span>,</span><br><span class="line">    <span class="string">'Accept-Encoding'</span>: <span class="string">'gzip, deflate, br'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8'</span>,</span><br><span class="line">    <span class="string">'Cache-Control'</span>: <span class="string">'no-cache'</span>,</span><br><span class="line">    <span class="string">'Connection'</span>: <span class="string">'Keep-Alive'</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="测试和抓取"><a href="#测试和抓取" class="headerlink" title="测试和抓取"></a>测试和抓取</h2><p>开始抓取的命令是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl counselor</span><br></pre></td></tr></table></figure><p>crawl 后面跟的是在 <code>class JdxlSpider(scrapy.Spider):</code> 中定义的爬虫名字。</p><p>先抓取 2 页试试：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">3</span>):</span><br><span class="line">        start_url_list.extend([<span class="string">'http://jiandanxinli.com/experts?&amp;page='</span> + str(i)])</span><br></pre></td></tr></table></figure><p>调试过程主要问题是节点的 xpath 提供得不准确，没有抓取到内容。另外就是可能忘记在 <code>items.py</code> 里面设置 item。一般来说，根据报错慢慢找，总能找出问题，耐心一些就是了。</p><h2 id="输出-csv"><a href="#输出-csv" class="headerlink" title="输出 csv"></a>输出 csv</h2><p>查看了官方文档里面有关输出的部分 <a href="https://doc.scrapy.org/en/latest/topics/feed-exports.html" target="_blank" rel="noopener">Feed exports — Scrapy 1.4.0 documentation</a> 和 <a href="https://doc.scrapy.org/en/latest/topics/exporters.html" target="_blank" rel="noopener">Item Exporters — Scrapy 1.4.0 documentation</a>，试了一下写 pipelines，有点复杂，没有成功。</p><p>然后搜到 <a href="https://zhuanlan.zhihu.com/p/24769534" target="_blank" rel="noopener">Scrapy爬虫框架教程（二）– 爬取豆瓣电影TOP250</a>，只需要在执行爬虫时设置输出参数就可以了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl counselor -o output_file.csv</span><br></pre></td></tr></table></figure><h2 id="查看、清理数据"><a href="#查看、清理数据" class="headerlink" title="查看、清理数据"></a>查看、清理数据</h2><p>新建 Jupyter Notebook，import pandas 包，用 <code>pd.read_csv</code> 命令查看文件：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/jdxlScrapyOutput.png" alt=""></p><p>抓取的链接不完整，补全并输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'url'</span>] = <span class="string">'http://jiandanxinli.com'</span>+df[<span class="string">'url'</span>]</span><br><span class="line">df.to_csv(<span class="string">'counselor.csv'</span>, index=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><p>下一篇继续介绍用 Pandas 和 Bokeh 做简单的数据统计和可视化。</p><p>项目源码请查看 <a href="https://github.com/kidult00/scrapy-jdxl" target="_blank" rel="noopener">00 的 github repo</a>：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/scrapy-jdxl-repo-qr.png" alt=""> </p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://doc.scrapy.org/en/latest/" target="_blank" rel="noopener">Scrapy 1.5 documentation</a></li><li><a href="https://www.wikiwand.com/en/XPath" target="_blank" rel="noopener">XPath - Wikiwand</a></li><li><a href="https://www.w3schools.com/xml/xpath_intro.asp" target="_blank" rel="noopener">XPath Tutorial</a></li><li><a href="https://www.zhihu.com/question/38080188" target="_blank" rel="noopener">如何用scrapy提取不在标签内的文字？</a></li><li><a href="https://zhuanlan.zhihu.com/p/24769534" target="_blank" rel="noopener">Scrapy爬虫框架教程（二）– 爬取豆瓣电影TOP250</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="爬虫" scheme="http://uegeek.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="http://uegeek.com/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>码以致用01 - Scrapy 爬虫框架简介</title>
    <link href="http://uegeek.com/180108python-scrapy-introduction.html"/>
    <id>http://uegeek.com/180108python-scrapy-introduction.html</id>
    <published>2018-01-08T09:26:12.000Z</published>
    <updated>2018-01-08T09:30:46.507Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg" alt=""></p><a id="more"></a> <h2 id="Scrapy-是什么"><a href="#Scrapy-是什么" class="headerlink" title="Scrapy 是什么"></a>Scrapy 是什么</h2><p><img src="https://scrapy.org/img/scrapylogo.png" alt=""></p><p>Scrapy 是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理或存储历史数据等程序中。</p><h2 id="Scrapy-的结构"><a href="#Scrapy-的结构" class="headerlink" title="Scrapy 的结构"></a>Scrapy 的结构</h2><p>Scrapy 的结构如下：</p><p><img src="https://doc.scrapy.org/en/latest/_images/scrapy_architecture_02.png" alt=""><br>via <a href="https://docs.scrapy.org/en/latest/topics/architecture.html" target="_blank" rel="noopener">Architecture Overview - Scrapy 1.5.0</a></p><p>在 Scrapy 中数据流是这样的：</p><ol><li>引擎从爬虫(Spider)获得初始抓取请求</li><li>引擎在 Scheduler 中安排好请求，获取下一个抓取请求</li><li>Scheduler 返回下一个抓取请求</li><li>引擎通过 Downloader 的 Middlewares 发送请求到 Downloader</li><li>完成页面下载后，Downloader 生成请求并通过 Middlewares 发送给引擎的</li><li>引擎接收来自 Downloader 的响应，通过 Spider Middlewares 发送给 Spider 处理</li><li>Spider 处理请求并返回爬取内容，向引擎提交下一个请求</li><li>引擎发送爬取内容到 Item Pipelines，然后发送处理请求到 Scheduler，获取下一个爬取请求</li><li>重复 1-8 步，直到没有新的请求</li></ol><h2 id="安装-Scrapy"><a href="#安装-Scrapy" class="headerlink" title="安装 Scrapy"></a>安装 Scrapy</h2><h3 id="新建-Python-虚拟环境"><a href="#新建-Python-虚拟环境" class="headerlink" title="新建 Python 虚拟环境"></a>新建 Python 虚拟环境</h3><p>比如用 <code>conda</code>，也可以用 <code>virtualenv</code> （参考：<a href="https://virtualenv.pypa.io/en/stable/installation/" target="_blank" rel="noopener">virtualenv installation instructions</a>)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n &#123;env_name&#125; &#123;list of packages&#125;</span><br></pre></td></tr></table></figure><p>上面的命令中，<code>env_name</code> 是用来折腾爬虫的项目环境名称，<code>list of package</code>是要一起安装的包，如 <code>scrapy</code>，<code>pandas</code>。</p><p>我新建了一个叫 <code>pyp</code> 的环境，打开这 Python 环境的命令是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> activate pyp</span><br></pre></td></tr></table></figure><p>如果你使用 <code>zsh</code>，可以在 <code>zshrc</code> 文件里面新建 alias，并 <code>source ~/.zshrc</code> 保存生效，下次就可以用别名快捷打开这个环境了。</p><h3 id="安装-Scrapy-1"><a href="#安装-Scrapy-1" class="headerlink" title="安装 Scrapy"></a>安装 Scrapy</h3><p>通过 <code>pip</code> 安装很方便</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install Scrapy</span><br></pre></td></tr></table></figure><h3 id="新建-scrapy-项目"><a href="#新建-scrapy-项目" class="headerlink" title="新建 scrapy 项目"></a>新建 scrapy 项目</h3><p>进入存放项目的目录，用命令新建一个爬虫项目：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &#123;name&#125;</span><br></pre></td></tr></table></figure><p>新建好以后，可以看到起名为 lyrics 的爬虫项目，生成了以下目录和文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">├── lyrics</span><br><span class="line">│   ├── __init__.py</span><br><span class="line">│   ├── __pycache__</span><br><span class="line">│   ├── items.py</span><br><span class="line">│   ├── middlewares.py</span><br><span class="line">│   ├── pipelines.py</span><br><span class="line">│   ├── settings.py</span><br><span class="line">│   └── spiders</span><br><span class="line">│       ├── __init__.py</span><br><span class="line">│       └── __pycache__</span><br><span class="line">└── scrapy.cfg</span><br><span class="line"></span><br><span class="line">4 directories, 7 files</span><br></pre></td></tr></table></figure><p>对照上面介绍的 Scrapy 引擎的结构，可以大概知道每个文件的作用。</p><p>下一篇我们尝试用 Scrapy 抓取一些简单的网页内容。</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://docs.scrapy.org/en/latest/index.html" target="_blank" rel="noopener">Scrapy 1.5 documentation</a></li><li><a href="https://zhuanlan.zhihu.com/p/24669128" target="_blank" rel="noopener">Scrapy爬虫框架教程（一）– Scrapy入门</a></li><li><a href="https://virtualenv.pypa.io/en/stable/installation/" target="_blank" rel="noopener">virtualenv installation instructions</a></li></ul><h3 id="你可能会感兴趣"><a href="#你可能会感兴趣" class="headerlink" title="你可能会感兴趣"></a>你可能会感兴趣</h3><ul><li><a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">DL笔记：用 python 实现梯度下降的算法</a></li><li><a href="http://www.uegeek.com/170929-DSNote3-NumPy-basic.html" target="_blank" rel="noopener">菜鸟数据科学入门03 - NumPy 数组基础和基本操作</a></li><li><a href="http://www.uegeek.com/coding-concepts.html" target="_blank" rel="noopener">设计师学编程 - 那些绕不过的概念</a></li><li><a href="http://www.uegeek.com/learngit.html" target="_blank" rel="noopener">多用Git少交税</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/robot_rock_dribbble.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
      <category term="爬虫" scheme="http://uegeek.com/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="Scrapy" scheme="http://uegeek.com/tags/Scrapy/"/>
    
  </entry>
  
  <entry>
    <title>大哉问05 - 什么是学习中最大的误区？</title>
    <link href="http://uegeek.com/180106-the-learning-myth.html"/>
    <id>http://uegeek.com/180106-the-learning-myth.html</id>
    <published>2018-01-06T08:50:08.000Z</published>
    <updated>2018-01-06T08:55:50.908Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_drawing.png" alt=""></p><blockquote><p>我只想知道我将来会死在什么地方，这样我就可以永远不去那里啦。——查理·芒格</p></blockquote><a id="more"></a> <p>如果说学习是 hack yourself 的主要方式，那么时刻反思「学习」本身就极其重要。</p><p>芒格曾经这样总结他的成功经验：</p><blockquote><p>迅速歼灭不该做的事情，接着对该做的事情发起熟练的、跨学科的攻击，然后，当合适的机会来临——只有当合适的机会来临——就采取果断的行动。</p></blockquote><p>今天，我们一起来聊聊学习中应该「迅速歼灭」的事情。</p><h2 id="误区千千万，这个特别坑"><a href="#误区千千万，这个特别坑" class="headerlink" title="误区千千万，这个特别坑"></a>误区千千万，这个特别坑</h2><p>学习中可能的误区有哪些？这个列表会很长：</p><ul><li>没有开始去做</li><li>没有集中精力</li><li>学习材料不对</li><li>学习方法不对</li><li>缺少目标</li><li>缺少练习</li><li>缺少反馈</li><li>遗忘</li><li>……</li></ul><p>被大家戏称「学习机器」的 00 曾经有过很多无效的学（zhe）习（teng）经历，这些坑我都踩过。再次反思，发现其中最巨大的一个，我今天仍然会反复地跌进去。</p><p>这个误区就是：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/mythOfStudy.png" alt=""></p><p>我们以为，一本书接一本书地看，就是学习了；我们以为，买了各种各样的课程（甚至能坚持听完），就是学习了；我们以为，有人手把手地教，就是学习了……</p><p>买课、看书、做计划，甚至开始动手尝试、反复练习，都只是学习的「动作」，而不是学习本身。</p><p>这些都是我们为学习所缴纳的巨额税款，而且可能会一直这么交下去。</p><h2 id="反思「学习」这个概念"><a href="#反思「学习」这个概念" class="headerlink" title="反思「学习」这个概念"></a>反思「学习」这个概念</h2><p>在<a href="http://www.uegeek.com/learning-about-learn.html" target="_blank" rel="noopener">重启学习系统，做个知识炼金术士</a>一文中，00 曾经整理过学习的一些概念。一年多以后再次翻出来，发现自己虽然理解，但是并没有内化，也没有持续践行。</p><p>快速找出权威教材和一些大师对学习的定义，其中共同出现频率最高的词是：<strong>改变</strong>。</p><blockquote><p>学习是通过经历或练习所带来的行为上相对持久的改变。——「心理学最佳入门」</p><p>学习意味着从一种知识状态进入另一种知识状态，学习要使学习者的知识结构发生改变。——「变构模型—学习研究的新路径」</p><p>学习是在观察行动与结果联系的基础上，改变行动或行动规则。——马奇「经验的疆界」</p></blockquote><p>00 再做了一点简化：</p><blockquote><p>学习是一系列以改变为目的的探索活动</p></blockquote><p><strong>所以，学习的目的，甚至学习的本身，就是：改变。</strong></p><p>以这个标准衡量，80% 以上的学习都是徒劳。因为我们根本没有花哪怕 1 分钟去仔细想过：</p><ul><li>我现在处于什么状态（起点 A）？</li><li>想达到什么状态（终点 B）？</li><li>如何衡量这一改变？</li><li>为了达成这一改变，需要做哪些改变？</li></ul><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/rethinkingLearning.png" alt=""></p><p>于是我们在自己那模糊而远大的雄心之下，开始了漫长的西西弗斯式的「壮举」：开始学习，然后无疾而终。</p><h2 id="学习的陷阱"><a href="#学习的陷阱" class="headerlink" title="学习的陷阱"></a>学习的陷阱</h2><p>如同「不是所有的感情都能够被命名」，也不是所有的学习都能被描述和评估，尤其当我们没有去主动思考内隐学习的时候。内隐学习(implicit learning)，指人们对复杂规则知识的无意识获取。</p><p>包括内隐学习在内的许多学习主题，都很容易偏离目标，以致于无法形成最终的改变，因为它们：</p><ul><li>影响范围很模糊</li><li>结果无法标准化/描述</li><li>检验周期很长</li><li>层级模糊</li></ul><h3 id="目标层面的「内隐」"><a href="#目标层面的「内隐」" class="headerlink" title="目标层面的「内隐」"></a>目标层面的「内隐」</h3><p>从现状 A 到目标 B，B 永远都像梦境中的理想伴侣——面目模糊。</p><p>我说我要学日语。但我不去问，「学会」的标准，是在旅行时能流利交流呢，还是能听懂 80% 日剧的对话呢，还是能通过考试呢，还是能熟练对照五十音图发音……我也没有问，这一改变需要通过哪些以往没有做过的事情来达成。我甚至没有问，为什么学这个的优先级比 xx 高，为什么是现在？</p><p>我说我要学编程。但我不去问，「学会」的标准，是能写出简单的脚本处理一些任务呢，还是跟程序员更顺畅地沟通呢，还是找到一份编程的工作呢……我也没有问，这一改变需要通过哪些以往没有做过的事情来达成。我甚至没有问，为什么学这个的优先级比 xx 高，为什么是现在？</p><p>我说我要学如何做决策。但我不去问，「学会」的标准，是工作中做出更有理据的决策呢，是提高个人投资的回报率呢，还是了解决策的过程……我也没有问，这一改变需要通过哪些以往没有做过的事情来达成。我甚至没有问，为什么学这个的优先级比 xx 高，为什么是现在？</p><p>以上都还只是目标容易识别和描述的学习。如果涉及到关系处理、自我觉察、个人成长、构建知识体系等等话题，提炼目标会更加困难。</p><h3 id="行为层面的内隐"><a href="#行为层面的内隐" class="headerlink" title="行为层面的内隐"></a>行为层面的内隐</h3><p>假如目标能够清晰描述，接下来有更多难题等着我们：</p><ul><li>从 A 到 B，存在哪些路径，是否存在最优路径？</li><li>路径可以拆分吗？由哪些部分组成？</li><li>每一步拆分的 B 又是什么？</li><li>共性/规则/规律是什么？如何描述？</li><li>如果难以描述，又怎么判断学习效果和改进步骤呢？</li></ul><h3 id="等级层面的内隐"><a href="#等级层面的内隐" class="headerlink" title="等级层面的内隐"></a>等级层面的内隐</h3><p>如果本身就在三界和五行中，要怎么跳出三界外，不在五行中呢？？</p><p>比如，德雷弗斯模型划分了新手到专家的五个阶段。当我们还处于新手阶段，怎么能想象出成为专家需要具备哪些条件，如何做到呢？</p><table><thead><tr><th>阶段</th><th>特点</th><th>概述</th></tr></thead><tbody><tr><td>新手</td><td>没有经验或很少经验（通过实施技术促进了思维改变）。不知道自己的行为是对是错。新手不是特别想要学习，只是想实现一个立竿见影的目标。不知道如何应付错误。新手需要一份指令清单。</td><td>Novices need recipes</td></tr><tr><td>高阶新手</td><td>可以独自尝试任务，但仍难以解决问题。想要快速获取信息，不想在此刻寻根究底，或者重新温习一遍基础知识。能够开始形成一些总体原则，但不是全貌。情境理解有限。</td><td>Advanced beginners don’t want the big picture.</td></tr><tr><td>胜任者</td><td>能够建立问题域的概念模型，并有效使用它们，可以独立解决自己遇到的问题，并开始考虑如何解决新的问题。开始寻求和运用专家的意见并有效利用。如果没有更多经验，在解决问题时，他们难以确定关注哪些细节。</td><td>Competents can troubleshoot.</td></tr><tr><td>精通者</td><td>需要全局思维，寻找并想了解更大的概念框架。会自我改进，反思以前是如何做的，并修改做法期望下一次表现得更好。会学习他人的经验，如案例研究、观察、从故事中学习。可以在不同情境中理解和运用格言经验之谈。可以充分利用思考和反馈。</td><td>Proficient practitioners can self-correct.</td></tr><tr><td>专家</td><td>专家是各个领域知识和信息的主要来源。他们总是不断的寻找更好的方法和方式去做事。他们有丰富的经验，可以在恰当的情境中选取和应用这些经验。他们著书、写文章、做巡回演讲。专家根据直觉工作，而不需要理由。专家知道哪些是无关紧要的细节，哪些是非常重要的细节，非常擅长做有针对性的特征匹配。</td><td>Experts work from intuition.</td></tr></tbody></table><p>因为这种种的「不可描述」，学习其实是一件不确定性蛮高的事情。如果没有充分启动元认知去理解和反思我们的学习行动，就容易用行动替代实质。</p><p>所以，学习的尝试和学习是两回事。</p><p>所以，看书和学习是两回事。</p><p>如果把看书的目的分为：<strong>参考资料、获得体验、启发思路、重塑三观/知识体系</strong>，我们惯常的读书习惯，其实都是以获得体验为主，尤其是虚构类的书籍。当然，获得体验本身就是非常有价值的目标，只不过这非常奢侈。</p><p>如果以学习为侧重而去读书，可能可以这样分配比例：</p><table><thead><tr><th>目的</th><th>书籍比例</th><th>精力投入</th></tr></thead><tbody><tr><td>重塑三观</td><td>0.1%</td><td>70%</td></tr><tr><td>参考资料</td><td>10%</td><td>15%</td></tr><tr><td>获得体验</td><td>8%</td><td>10%</td></tr><tr><td>启发思考</td><td>1.9%</td><td>5%</td></tr><tr><td>没有营养</td><td>80%</td><td>0%</td></tr></tbody></table><h2 id="更新「学习」这个概念"><a href="#更新「学习」这个概念" class="headerlink" title="更新「学习」这个概念"></a>更新「学习」这个概念</h2><p>从今天开始，往头脑的概念库中重新写入「学习」这个概念吧！</p><p>马奇在「经验的疆界」中提出，学习会在三个层面同时发生：</p><ol><li>学习做什么：例如寻找好的技术、战略或合作伙伴</li><li>学习如何做：例如精炼并改进在某技术、战略或合作伙伴上的胜任力</li><li>学习期盼什么：例如调整绩效目标（经常出问题，开始设定太高或太低后续没有调整）</li></ol><p>所以，学习并不是「做了哪些代表学习的举动」，而是在清醒知道<strong>为什么学、如何学、如何评估</strong>的前提下，从 A 到 B 的过程。<strong>如果没有（一定程度上可描述的）改变，学习相当于没有发生。</strong></p><p>这么看来，学习真是一件远比我们想象要深刻且有用的事情。低效的学习，大都来自于对「学习」概念本身的误解。</p><p>既然找出了大坑，下一篇我们来详细讨论，学习中最应该养成的习惯是什么。</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://book.douban.com/subject/25858893/" target="_blank" rel="noopener">心理学最佳入门（原书第2版）</a></li><li><a href="http://book.douban.com/subject/6687032/" target="_blank" rel="noopener">经验的疆界</a></li><li><a href="https://book.douban.com/subject/5346110/" target="_blank" rel="noopener">穷查理宝典</a></li><li><a href="https://book.douban.com/subject/26268555/" target="_blank" rel="noopener">程序员思维修炼</a></li><li><a href="https://book.douban.com/subject/5388442/" target="_blank" rel="noopener">变构模型-学习研究的新路径</a></li></ul><h3 id="HackYourself-大哉问系列"><a href="#HackYourself-大哉问系列" class="headerlink" title="HackYourself 大哉问系列"></a>HackYourself 大哉问系列</h3><ul><li><a href="http://www.uegeek.com/171226MyYear2017.html" target="_blank" rel="noopener">小哉问：年终总结写什么？ | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171223-Why-Learn-Programming.html" target="_blank" rel="noopener">大哉问04 - 为什么要学编程 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171216HowToMakeMoney.html" target="_blank" rel="noopener">大哉问03 - 什么是赚钱之道？更新你的个人商业模式 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171204HowToLoveYourself.html" target="_blank" rel="noopener">大哉问02 - 如何爱自己？拟一份爱的宣言 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171126TimePerspective.html" target="_blank" rel="noopener">大哉问01 - 什么样的时间观值得拥有？ | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171112-HowToAskGoodQuestion.html" target="_blank" rel="noopener">用问题对话虚无 —— HackYourself 大哉问系列 | 00’s Adventure</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/HY_drawing.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我只想知道我将来会死在什么地方，这样我就可以永远不去那里啦。——查理·芒格&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="学习" scheme="http://uegeek.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="方法" scheme="http://uegeek.com/tags/%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>DeepLearning笔记：多节点神经网络</title>
    <link href="http://uegeek.com/180104DeepLearning8-MultiLayer-Perceptrons.html"/>
    <id>http://uegeek.com/180104DeepLearning8-MultiLayer-Perceptrons.html</id>
    <published>2018-01-04T09:03:50.000Z</published>
    <updated>2018-01-04T09:46:48.893Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：上回我们<a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">在 python 里面实现了单个神经元的梯度下降算法</a>。现在可以挑战一下多个神经元的网络了。</p><p><code>阿特</code>：那会不会很难哦？</p><p><code>阿扣</code>：也不会，原理其实是一样的，只是需要分辨清楚各个参数属于哪一层。</p><p><code>阿特</code>：（不祥预感）</p><p><code>阿扣</code>：比如说，下面这个网络：</p><ul><li>有 3 个输入 x1,x2,x3，2 个隐层节点 h1,h2</li><li>节点之间的权重用 w 表示，第一个下标为出发节点，第二个下标为目标节点，比如 $w_{11}$ 表示 x1 到 h1 的权重</li></ul><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/network-with-labeled-weights.png" alt=""></p><p>我们把权重存在一个矩阵中，每一行对应一个输入值的权重，每一列对应一个隐层节点的权重：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/multilayer-diagram-weights.png" alt=""></p><p>所以，隐层的第 j 个节点就表示为：$h_j = \sum<em>i w</em>{ij}x_i$</p><p>权重和输入值相乘时，需要用到矩阵乘法中的点乘（dot product）：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/input-times-weights.png" alt=""></p><p><code>阿特</code>：啊……矩阵，我好些已经忘得差不多了……</p><p><code>阿扣</code>：没关系，慢慢回忆起来。这里比较关键的是，两个矩阵相乘，<strong>左边矩阵的行数，必需跟右边矩阵的列数相等</strong>，不然没法相乘。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/matrix-mult-3.png" alt=""></p><p>比如我们要计算的神经网络的矩阵：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/matrix_eg1.png" alt=""></p><p>左边矩阵有 1 行 3 列，右边矩阵有 3 行 1 列，它们是可以相乘的。</p><p><code>阿特</code>：让我数一数……</p><p><code>阿扣</code>：记得矩阵需要「门当户对」就好 😄 。上面这个矩阵，我们也可以调换左右顺序，并且让两个矩阵都转置（就是行列互换）一下来满足相乘的条件：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/inputs-matrix.png" alt=""></p><p><code>阿特</code>：这跟上面那两个矩阵相乘的结果是一样的吗？</p><p><code>阿扣</code>：是的。按照矩阵点乘的公式 ($h_1=x<em>1w</em>{11} + x<em>2w</em>{21}+x<em>3w</em>{31}$) 把它们展开，会发现其实是一个东西。</p><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DeepLearning笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DeepLearning笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DeepLearning笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DeepLearning笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DeepLearning笔记：Cost function 损失函数</a></li><li><a href="http://www.uegeek.com/171222DLN6-GradientDescent.html" target="_blank" rel="noopener">DeepLearning笔记：梯度下降 Gradient Descent</a></li><li><a href="http://www.uegeek.com/171226DLN7-GradientDescentinPython.html" target="_blank" rel="noopener">DeepLearning笔记：用 python 实现梯度下降的算法</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="神经网络" scheme="http://uegeek.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
      <category term="线性代数" scheme="http://uegeek.com/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>小哉问：年终总结写什么？</title>
    <link href="http://uegeek.com/171226MyYear2017.html"/>
    <id>http://uegeek.com/171226MyYear2017.html</id>
    <published>2017-12-29T11:28:42.000Z</published>
    <updated>2017-12-31T09:30:20.150Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/2017sumTitle.jpg" alt=""></p><a id="more"></a> <p>马上要跨入本世纪第 19 个年头了（可怕不可怕……），大家都在忙着写总结和计划。</p><p>年终总结写什么，取决于想得到什么。</p><p>如果想记录一年都做了什么，那很简单，按时间记账就行。如果想盘点一年的得失，就需要费一点心力，思考哪些事情比较重要，自己从中获得了什么、失去了什么。</p><p>如果想给自己一个交代，总结过去就好。</p><p>如果想许自己一个未来，那值得再琢磨琢磨。</p><p>一天有一天的所得，一辈子有一辈子的教训。越是大时间周期的回顾，提取的信息应该越凝练。人能清醒地写年终总结的机会真的不多（也就二三十来次？）年末提供了一个强制的时间点去做盘点，以便搞清楚这一年有哪些新收获，最希望在来年谨记？有哪些切肤之痛，希望未来不要再经历？有哪b些或主动或被动的改变，希望来年继续？</p><p>一年一次的总结，也可以看成是一次内存整理：<strong>「卸载」那些无用、低效的想法和习惯，「加载」来年需要的认知和能力</strong>。</p><p>今年是出乎意料的一年，以没有料想过的方式，学习到一些被忽视已久的知识。虽然作品寥寥，倒是更懂自己了。</p><p>来到 2018 的门口，先放下背包，倒出这一年中收集的种种，仔细考虑哪些要丢弃，哪些需要重视起来，哪些要且行且珍惜。</p><h3 id="需要卸载"><a href="#需要卸载" class="headerlink" title="需要卸载"></a>需要卸载</h3><ul><li>会带来巨大认知失调的惯性</li><li>让别人的目标凌驾于自己的目标之上</li><li>自我剥夺价值感</li><li>陈旧的人设</li></ul><h3 id="需要保持"><a href="#需要保持" class="headerlink" title="需要保持"></a>需要保持</h3><ul><li>简单的生活方式</li><li>反碎片化</li><li>从知识源头获取信息（比如，跟踪人而不是五手信息）</li><li>以问题驱动思路，以试验驱动行动</li></ul><h3 id="需要加载"><a href="#需要加载" class="headerlink" title="需要加载"></a>需要加载</h3><p><strong>1. 进入新环境、新领域、新角色时，需要清内存，重建数据库</strong></p><p><strong>2. 正确看待人性的复杂</strong></p><ul><li>尤其不要低估人与人之间的差异</li><li>提升快速识别人的判断力，以及其他直觉</li><li>观察互动模式如何形成</li><li>设定关系的止损点</li></ul><p><strong>3. 爱自己</strong></p><ul><li>通过情绪快速识别问题</li><li>划定灵活而坚定的个人边界</li><li>优先处理自己的核心矛盾，保护内在动机</li></ul><p><strong>4. 建立「初心」的快捷方式，多拷问目标</strong></p><p><strong>5. 减少 90% 主流信息输入方式，在最优信息上增加十倍投入</strong></p><p><strong>6. 以身份和项目为导向，聚焦和持续输出</strong></p><hr><p>祝大家新年快乐！每天都有新收获</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/2017sumTitle.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="2017" scheme="http://uegeek.com/tags/2017/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：用 python 实现梯度下降的算法</title>
    <link href="http://uegeek.com/171226DLN7-GradientDescentinPython.html"/>
    <id>http://uegeek.com/171226DLN7-GradientDescentinPython.html</id>
    <published>2017-12-26T01:28:42.000Z</published>
    <updated>2018-01-04T09:46:06.361Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p>回顾上回讲的梯度下降算法，想实现梯度下降，需要不断更新 w：</p><p>$$ \Delta w_{ij} = \eta \delta_j x_i $$</p><p>具体步骤如下：</p><ul><li>初始化权重变化率为 0 ：$\Delta w_i = 0$</li><li>对训练集中的每一个数据：<ul><li>做正前传播计算：$\hat y=f(\sum_iw_ix_i)$</li><li>计算输出单元的 error term：$\delta=(y-\hat y) * f’(\sum_iw_ix_i)$</li><li>更新权重变化率：$\Delta w_i= \Delta w_i + \delta x_i$</li></ul></li><li>更新权重 $w_i = w_i + \eta \Delta w_i /m$</li><li>重复 e 次训练 epochs</li></ul><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><ol><li>初始化权重变化率为 0</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">del_w = np.zeros(weights.shape)</span><br></pre></td></tr></table></figure><ol><li>正向传播计算</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output = sigmoid(np.dot(x, weights))</span><br></pre></td></tr></table></figure><ol><li>计算输出单元的 error term</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">error = y - output</span><br><span class="line">error_term = error * output * (<span class="number">1</span>-output)</span><br></pre></td></tr></table></figure><ol><li>更新权重变化率</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">del_w += error_term * x</span><br></pre></td></tr></table></figure><ol><li>更新权重</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weights += learnrate * del_w / n_records</span><br></pre></td></tr></table></figure><ol><li>重复 epochs</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">    del_w = np.zeros(weights.shape)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(features.values, targets):</span><br><span class="line">        <span class="comment"># Loop through all records, x is the input, y is the target</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the output</span></span><br><span class="line">        output = sigmoid(np.dot(x, weights))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error</span></span><br><span class="line">        error = y - output</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error term</span></span><br><span class="line">        error_term = error * output * (<span class="number">1</span>-output)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the change in weights for this sample</span></span><br><span class="line">        <span class="comment"># and add it to the total weight change</span></span><br><span class="line">        del_w += error_term * x</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using the learning rate and the average change in weights</span></span><br><span class="line">    weights += learnrate * del_w / n_records</span><br></pre></td></tr></table></figure><p>完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> data_prep <span class="keyword">import</span> features, targets, features_test, targets_test</span><br><span class="line"></span><br><span class="line"><span class="comment"># Defining the sigmoid function for activations</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># reserve seed</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">n_records, n_features = features.shape</span><br><span class="line">last_loss = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize weights</span></span><br><span class="line">weights = np.random.normal(scale=<span class="number">1</span> / n_features**<span class="number">.5</span>, size=n_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Neural Network hyperparameters</span></span><br><span class="line">epochs = <span class="number">1000</span></span><br><span class="line">learnrate = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(epochs):</span><br><span class="line">    del_w = np.zeros(weights.shape)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> zip(features.values, targets):</span><br><span class="line">        <span class="comment"># Loop through all records, x is the input, y is the target</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the output</span></span><br><span class="line">        output = sigmoid(np.dot(x, weights))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error</span></span><br><span class="line">        error = y - output</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the error term</span></span><br><span class="line">        error_term = error * output * (<span class="number">1</span>-output)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate the change in weights for this sample</span></span><br><span class="line">        <span class="comment"># and add it to the total weight change</span></span><br><span class="line">        del_w += error_term * x</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Update weights using the learning rate and the average change in weights</span></span><br><span class="line">    weights += learnrate * del_w / n_records</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Printing out the mean square error on the training set</span></span><br><span class="line">    <span class="keyword">if</span> e % (epochs / <span class="number">10</span>) == <span class="number">0</span>:</span><br><span class="line">        out = sigmoid(np.dot(features, weights))</span><br><span class="line">        loss = np.mean((out - targets) ** <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> last_loss <span class="keyword">and</span> last_loss &lt; loss:</span><br><span class="line">            print(<span class="string">"Train loss: "</span>, loss, <span class="string">"  WARNING - Loss Increasing"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">"Train loss: "</span>, loss)</span><br><span class="line">        last_loss = loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Calculate accuracy on test data</span></span><br><span class="line">test_out = sigmoid(np.dot(features_test, weights))</span><br><span class="line">predictions = test_out &gt; <span class="number">0.5</span></span><br><span class="line">accuracy = np.mean(predictions == targets_test)</span><br><span class="line">print(<span class="string">"Prediction accuracy: &#123;:.3f&#125;"</span>.format(accuracy))</span><br></pre></td></tr></table></figure><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DL笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DL笔记：Cost Function 损失函数</a></li><li><a href="http://www.uegeek.com/171222DLN6-GradientDescent.html" target="_blank" rel="noopener">DL笔记：Gradient Descent 梯度下降</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>大哉问04 - 为什么要学编程？</title>
    <link href="http://uegeek.com/171223-Why-Learn-Programming.html"/>
    <id>http://uegeek.com/171223-Why-Learn-Programming.html</id>
    <published>2017-12-23T07:56:13.000Z</published>
    <updated>2018-01-06T08:54:20.279Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_code_illustration.jpg" alt=""></p><a id="more"></a> <blockquote><p>工欲善其事，必先鼓其志，然后利其器。 —— 00</p></blockquote><p>很多次失败的学习经历告诉我，最终能不能学会一样东西，跟聪不聪明没太大关系，而是看这件事到底有多生死攸关，或者有多意义重大。</p><p>学编程，对大龄、非专业的我来说，更是如此。动机因人而异，不管黑猫白猫，能加满油箱的就是好动机。</p><p>我找出了 5 个比喻，来说服自己为什么要学编程：</p><ol><li>数字化生存的工具</li><li>人机交互的语言</li><li>复杂系统的训练营</li><li>创作的可供性源头</li><li>心流的容器</li></ol><h2 id="1-数字化生存的工具"><a href="#1-数字化生存的工具" class="headerlink" title="1.数字化生存的工具"></a>1.数字化生存的工具</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/ub_2-3.png" alt=""></p><p>距离尼葛洛庞帝写出「Being Digital」已经过去 22 年了。我们真的已经生活在数字化的世界中。</p><p>世界很复杂。</p><p>人们通过「降维」，抽取并控制最基本的单元要素，把事物抽象成数理形式、逻辑，再进一步抽象成 0 和 1，从而获得了重构/再造世界的能力——这是强大的杠杆，使得效率暴涨、网络成型。</p><p>为什么能够做到？得益于我们抽象事物、提取共性、找到基本单元的能力。付出的是理解、灵活性和转化成本。</p><h3 id="数字化生存的三个阶段"><a href="#数字化生存的三个阶段" class="headerlink" title="数字化生存的三个阶段"></a>数字化生存的三个阶段</h3><p><strong>概念和形式的数字化</strong>。那些以虚拟概念、形式逻辑为核心的领域，比如金融，比如文字，比如音乐，早已经完成数字化。</p><p><strong>实体的数字化</strong>。O2O、自动化生产、智能家居、物联网，它们不仅仅是网红概念和风口，也是数字化卷积横扫物理世界的汹涌进程。物理世界被慢慢驯服的同时，构建虚拟化世界的技术 VR/AR/MR 们也快速发展——毕竟人们渴求对世界的完全「控制」，即便这种控制只停留在视觉层面。</p><p><strong>人的数字化</strong>。先是 ID 化，完成人与人的互联。碳基质的人类迟早（已经）意识到肉身的局限，就会开始去修改自己的出厂设置。基因技术，纳米计算，脑机接口……机器不会毁灭人类，因为人类会率先变成人机融合的可编程智能体。</p><p>人能够摆脱自然的桎梏，成为衣食无忧、没有天敌的物种，靠建造工具去改造环境，以适应自身的需求。要在越来越数字化的世界中生存，掌握改造周边环境的能力，或者说手握一本操纵现实和驱动生产的「指南」，确实很有必要。</p><p>何况，它还能让你找到一份工作。因为越来越多的工作内容，都转变成了建造和管理数字世界。</p><p>那么应该何时完成进化？</p><p>比你所在的行业/领域早一步完成。如果它正处在数字化进程的早期，那就赶紧开始吧。</p><p>总之</p><blockquote><p>学编程，是为了提高数字世界的生存效率。</p></blockquote><h2 id="2-人机交互的语言"><a href="#2-人机交互的语言" class="headerlink" title="2.人机交互的语言"></a>2.人机交互的语言</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/designing-for-humans-in-a-digital-world.jpg" alt=""></p><p>人机交互是我过去多年的工作内容，希望未来也是。</p><p>在人工智能的前夜，需要很多类似交互设计师、体验设计师这样的 AI 清道夫，帮助机器完成它们还比较笨拙的「沟通」工作。黑暗的前夜什么结束，我们不知道，可以肯定的是，只会越来越快。</p><p>当算法越来越智能，人与机器的交互大概会沿着两个方向发展：</p><ul><li><strong>在机器更擅长的领域，推动自动化</strong>。很多原本需要人干预的、相对机械的事情，都会逐渐自行运转——比如数字化生产、自动驾驶等等。</li><li><strong>在人更擅长的领域，推动人机合作</strong>。比如综合智能、文艺创作、理解和共情他人、面对面服务这些领域，机器如何帮助人完成工作，人和机器之间的「伙伴式」互动，是我更感兴趣的人机交互领域。</li></ul><p>「人机交互创作」，应该会成为一个有意思的领域，而且它会让编程语言改头换面——又或者是增加其他的方式，比如编程手势，编程舞蹈，编程表情？</p><p>总之</p><blockquote><p>学编程，是为了让人和机器更好地沟通。</p></blockquote><h2 id="3-复杂系统的训练营"><a href="#3-复杂系统的训练营" class="headerlink" title="3.复杂系统的训练营"></a>3.复杂系统的训练营</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_minecraftentrance.png" alt=""></p><p>如何构造复杂的系统？<strong>运用编程的思想，并且在沙盒里实践。</strong></p><p>再复杂的系统，都可以始于 「Hello world」。然后增加一条运算，增加一个循环，增加一个函数， 增加一个对象，增加一个 API，增加一个库，增加一个逻辑层，增加一个编译器，增加一个物理模组……处理好的部分就封装起来，眼不见心不烦，可以专注搭建下一个模块。如果随着现实需求的增加，发现造出来的「轮子」不好用，还可以拆了轮子重造。</p><p>罗马不是一天建成的，Minecraft 也不是。并非每个人都能承受物理世界推翻重建的高昂成本，但是每个人都能开 Sandbox，调通程序以后再 Git Push。</p><p>你看吸金无数的在线游戏，在虚拟世界的沙盒里，硬生生地再造了无数个传奇。</p><p>你看横空出世的比特币，在虚拟世界的沙盒里，硬生生地再造了一个金融系统。</p><blockquote><p>学编程，是为了训练构造复杂系统的能力。</p></blockquote><h2 id="4-创作的可供性源头"><a href="#4-创作的可供性源头" class="headerlink" title="4.创作的可供性源头"></a>4.创作的可供性源头</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_drawing.png" alt=""></p><p>音乐家以音符为符号，用乐器演奏。画家以画笔为工具，在实体材料上作画。</p><p>当我们把思想降维成文字，便拥有了生成新想法的可能；把建筑降维成骨架和砖块，我们拥有了建造形态万千的建筑的可能；把音乐降维为旋律、节奏、音色、和声，我们拥有了创造新作品的可能。</p><p>当然，这都只是「可能」，想要创造出鲜活而有深度的新事物，只有一个途径：<strong>在实践中改进，永不停息</strong>。</p><p>我想强调的是，一旦把事物拆解到原子/比特层级，就可以完全重组——一生二，二生三，三生万物，这释放了多少可供性！</p><p>代码本身是语言，<strong>是驱动系统为你创作的语言</strong>。音符和乐器合一，纸和笔合一，建筑场所和构件合一——这是多么不可思议的创造环境，表达、构造、呈现的载体合一了！</p><p>总之</p><blockquote><p>学编程，是为了能操控素材，创造属于自己的时间晶体。</p></blockquote><h2 id="5-心流的容器"><a href="#5-心流的容器" class="headerlink" title="5.心流的容器"></a>5.心流的容器</h2><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HY_creative.png" alt=""></p><p>再怎么数字化生存，再怎么提高效率，也不能被轻易地被物化，这是人要守住的界限。人之为人，还是应该多以自身的福祉为出发点。</p><p>幸福是什么？对我而言，幸福就是「忘我但趋于有序」的状态，或者说，就是在创作中的心流状态。</p><p>写作是低成本的心流获取方式，而且自带生产属性。同样是用语言表达，编程也容易产生心流，而且改造现实的能力更强。写文字和写代码，都是心流体验的容器。</p><p>但是在获得心流之前，需要大量的练习。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/download.png" alt=""></p><p>via <a href="https://www.wikiwand.com/en/Flow_(psychology" target="_blank" rel="noopener">Flow (psychology) - Wikiwand</a>)</p><p><a href="https://www.wikiwand.com/en/Mihaly_Csikszentmihalyi" target="_blank" rel="noopener">Csikszentmihalyi</a> 这张心流的图示，大家可能都很熟悉了。只有当技能水平和任务难度都高的时候，心流才容易产生。<strong>编程就是一种需要专注、难度可控、反馈及时的活动。在心流中构建作品，还有什么事情比这个更值得投入吗</strong>？</p><p>总之</p><blockquote><p>学编程，是为了拥有进行创作的心流容器。</p></blockquote><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>在门口徘徊挣扎了 4、5 年，总算是磕磕碰碰上路了。</p><p>00 的编程学习笔记和项目都会记录在 ArtxCode 公众号上面，欢迎围观和一起学习。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/AC.IMG.QR.png" alt=""></p><p>先学为敬。</p><h3 id="HackYourself-大哉问系列"><a href="#HackYourself-大哉问系列" class="headerlink" title="HackYourself 大哉问系列"></a>HackYourself 大哉问系列</h3><ul><li><a href="http://www.uegeek.com/171226MyYear2017.html" target="_blank" rel="noopener">小哉问：年终总结写什么？ | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171216HowToMakeMoney.html" target="_blank" rel="noopener">大哉问03 - 什么是赚钱之道？更新你的个人商业模式 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171204HowToLoveYourself.html" target="_blank" rel="noopener">大哉问02 - 如何爱自己？拟一份爱的宣言 | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171126TimePerspective.html" target="_blank" rel="noopener">大哉问01 - 什么样的时间观值得拥有？ | 00’s Adventure</a></li><li><a href="http://www.uegeek.com/171112-HowToAskGoodQuestion.html" target="_blank" rel="noopener">用问题对话虚无 —— HackYourself 大哉问系列 | 00’s Adventure</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/HY_code_illustration.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
      <category term="编程" scheme="http://uegeek.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：梯度下降 Gradient Descent</title>
    <link href="http://uegeek.com/171222DLN6-GradientDescent.html"/>
    <id>http://uegeek.com/171222DLN6-GradientDescent.html</id>
    <published>2017-12-22T01:28:24.000Z</published>
    <updated>2017-12-31T12:25:56.385Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：上一次我们了解了<a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">损失函数</a>。为了找到使损失函数（比如用 SSE 计算）最小的 w (权重) 和 b (偏置项)，我们需要先了解一个重要的方法：梯度下降。</p><p><code>阿特</code>：听起来像坐滑滑梯~</p><p><code>阿扣</code>：是有那么点意思。</p><p><code>阿扣</code>：想象一下，我们对网络中的一些权重做了很小的改变，这些变化会让输出也有相应很小的变化：</p><p><img src="http://neuralnetworksanddeeplearning.com/images/tikz8.png" alt=""></p><p>via <a href="http://neuralnetworksanddeeplearning.com/chap1.html" target="_blank" rel="noopener">Neural networks and deep learning - chapter 1</a></p><p>然后拿这些微小的变化，跟目标值对比，看看误差是变大还是变小了，然后不断调整权重值，最终找到最合适的 w 和 b。</p><p><code>阿特</code>：那要怎么找到这些值呢？</p><p><code>阿扣</code>：下面有请「梯度下降」 Gradient Descent。</p><p><code>阿特</code>：终于能坐滑滑梯了……</p><p><code>阿扣</code>：坐这个滑滑梯可能有点晕 😄 。我先给你打个比方。想象一下，你在一个山峰的山顶，想用最快的速度到达山脚。</p><p><code>阿特</code>：坐缆车可以吗？</p><p><code>阿扣</code>：缆车，不存在的……只能靠走的。要往哪边下山呢？我们会选一个看起来「下降」最快的路径：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Gradient%20Descent-i1.png" alt=""></p><p>朝这个方向走一段后，我们再看下一步往哪个方向走，「下降」最快。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Gradient%20Descent-i2.png" alt=""></p><p>一直重复这个过程，就能最快的速度下到山脚。</p><p><code>阿特</code>：是这么个道理。</p><p><code>阿扣</code>：这个方法，就是「梯度下降」，在机器学习中很常见。所谓「梯度」，其实是指「变化率」或者「坡度 slope」，就是多变量函数的导数。</p><p><code>阿特</code>：导数？！你说的是微积分里面那个导数吗？ …… 瑟瑟发抖.gif</p><p><code>阿扣</code>：别紧张，先听我讲，回忆回忆。</p><p><code>阿特</code>：好吧。</p><p><code>阿扣</code>：你还记得怎么表示函数 f(x) 的导数吧？很简单，就是 f’(x) 。</p><p><code>阿特</code>：嗯嗯，记得。</p><p><code>阿扣</code>：所谓「梯度」，其实就是函数在某一点上的变化率，根据微分的知识，变化率可以通过这一点的切线求得，而切线其实就是函数的导数：f’(x)。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/derivative-example.png" alt=""></p><p>来，跟我念一遍：求梯度 = 求变化率 = 求导数</p><p><code>阿特</code>：求梯度 = 求变化率 = 求导数 （假装自己听懂了）</p><p><code>阿扣</code>：了解了「梯度」，然后我们来看看「下降」又是怎么回事。</p><p>切线代表函数在某个点的变化率。在上面这个图中，x = 2 位置上的切线，斜率是 &gt; 1 的。说明如果继续往 x = 2 的右边滑去，在曲线上的值就会变大。比如当 x = 3 时，y = 9。</p><p>但是我们想要到曲线最低的地方去，因为那里可以让误差（也就是 cost ）最小。所以，应该沿着梯度「相反」的方向滑动，也就朝着是 x = 2 的左边滑去。这就是「下降」的含义。</p><p><code>阿特</code>：沿着「上山」最快的反方向走，就能最快「下山」。啊原来这么直白……</p><p><code>阿扣</code>：对呀，原理并不复杂的。</p><p>这个视频讲解了线性回归和梯度下降的关系，来看看吧！</p><div class="video-container"><iframe src="//www.youtube.com/embed/L5QBqYDNJn0" frameborder="0" allowfullscreen></iframe></div><p><a href="https://www.youtube.com/watch?time_continue=194&amp;v=L5QBqYDNJn0" target="_blank" rel="noopener">Linear Regression Answer - YouTube</a></p><p><code>阿特</code>：这个视频不错，讲得挺清楚的~</p><p><code>阿扣</code>：我们来复习一下。用一个函数 f(h) 表示 x 和 y 的关系。x 和 y 其实是已知的，它们来自真实的数据集。我们的目标是求出 w 和 b，使得计算出来的 $\hat y$ 最接近实际的 y 值。为了得到某种类型的 y 值（比如只有 0 和 1 两种输出），我们会使用类似 Sigmoid 这样的激活函数，对 f(h) 做一下转换。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/simpleNN.png" alt=""></p><p><code>阿特</code>：哦，我说怎么有点难理解呢。因为以前碰到 x 和 y，它们都是未知数，现在它们变成了已知数，真正的目标其实是求 w 和 b！</p><p><code>阿扣</code>：没错！这是深度学习算法中一个需要调整的认知。</p><p>怎么得到 w 和 b 呢？用损失函数。如果损失函数的值大，说明模型预测得不准。我们要找到让损失函数的值最小的 w 和 b。更具体说，我们要找到 w 的变化幅度 $\Delta w$，每次调整一小步，看看误差 E 是不是变小了。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Gradient%20Descent-i3.png" alt=""></p><p>为了求出 $\Delta w$，我们引入「误差项」$\delta$ ，它表示 <code>误差 * 激活函数的导数</code>。然后用「误差项」$\delta$ 乘上学习率 $\eta$ （用来调整梯度的大小），再乘上 x，就是每次应该调整的权重值 $\Delta w_{ij}$</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/WX20171127-154242@2x.png" alt=""></p><p><code>阿扣</code>：比如说，如果激活函数是 Sigmoid 函数。</p><p>$$ f(h)=\frac {1}{1 + e^{−h}} $$ </p><p>$$ f’(h)=f(h)(1−f(h))$$ </p><p>$$ \Delta w_{ij}=\eta<em>(y_j-\hat y_j)</em>f(h)<em>(1−f(h))</em>x_i $$</p><p>…… 咦？人呢？</p><p>喂！别跑，还有好几个知识点没讲呢！……</p><h3 id="补充：求多个变量的偏导数"><a href="#补充：求多个变量的偏导数" class="headerlink" title="补充：求多个变量的偏导数"></a>补充：求多个变量的偏导数</h3><p>如果只有一个未知数，求梯度只需要计算导数。如果有多个变量，求梯度就需要计算偏导数。偏导数其实并不复杂，只需要掌握链式求导法则，就能进行大部分的计算。</p><p>$$ \frac{\partial}{\partial w} p(q(w)) = \frac{\partial p}{\partial q}\frac{\partial q}{\partial w} $$</p><p>比如，损失函数 C</p><p>$$ C = \sum(wx + b - y)^2 = \sum((wx + b)^2 + y^2 - 2y(wx + b)) = \sum(x^2w^2 + b^2 + 2xwb + y^2 - 2xyw - 2yb) $$</p><p>对 w 求偏导</p><p>$$ \frac{\partial C}{\partial w} = \frac{1}{N} \sum(wx + b - y)x $$</p><p>对 b 求偏导</p><p>$$ \frac{\partial C}{\partial b} = \frac{1}{N} \sum(wx + b - y) $$</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101" target="_blank" rel="noopener">Deep Learning Nanodegree | Udacity</a></li><li><a href="https://www.coursera.org/learn/neural-networks-deep-learning" target="_blank" rel="noopener">Neural Networks and Deep Learning | Coursera</a></li><li><a href="https://classroom.udacity.com/nanodegrees/nd101-cn/parts/ba124b66-b7f7-43ab-bc89-a390adb57f92/modules/2afd43e6-f4ce-4849-bde6-49d7164da71b/lessons/dc37fa92-75fd-4d41-b23e-9659dde80866/concepts/7d480208-0453-4457-97c3-56c720c23a89" target="_blank" rel="noopener">Gradient Descent with Squared Errors</a></li><li><a href="https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient" target="_blank" rel="noopener">Gradient (video) | Khan Academy</a></li><li><a href="http://ruder.io/optimizing-gradient-descent/index.html#momentum" target="_blank" rel="noopener">An overview of gradient descent optimization algorithms</a></li></ul><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DL笔记：Activation Function 激活函数</a></li><li><a href="http://www.uegeek.com/171220DLN5-CostFunction.html" target="_blank" rel="noopener">DL笔记：Cost Function 损失函数</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：Cost function 损失函数</title>
    <link href="http://uegeek.com/171220DLN5-CostFunction.html"/>
    <id>http://uegeek.com/171220DLN5-CostFunction.html</id>
    <published>2017-12-20T01:31:16.000Z</published>
    <updated>2017-12-27T01:38:19.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：阿特，还记得训练神经网络的目标其实是什么吗？</p><p><code>阿特</code>：我记得好像是要找出最合适的权重(weights)，使得输出结果尽可能接近真实值。</p><p><code>阿扣</code>：Hin 棒！你说的没错。说回到训练神经网络，我们需要在训练中及时了解训练效果如何，是不是朝着训练目标在一点点靠近。如果偏离目标，就说明训练模型可能在「犯错」，就要纠正过来。</p><p><code>阿特</code>：那怎么知道模型是不是在「犯错」呢？</p><p><code>阿扣</code>：我们会找一个度量标准。一个常见的度量方法是计算误差的平方和（SSE, sum of the squared errors）：</p><p>$$ E=\frac{1}{2}\sum_\mu\sum_j[y^\mu_j - f(\sum<em>i w</em>{ij}x^\mu_i)]^2 $$</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/latex_9521ee448af952b9e073b5d31974241c.png" alt=""></p><p><code>阿特</code>：你……欺负人 &gt;.&lt;</p><p><code>阿扣</code>：别着急，我们来拆解这一坨是个什么东西。先看看各个字母的含义：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/il_for_SSE-1.png" alt=""></p><p>这个等式里面，有三个求和项（就是这个翻转了 90° 的 M： $\sum$ ）。</p><p>最右边的求和项 $\sum<em>i w</em>{ij}x^\mu_i$ ，表示我们训练出来的权重 w 乘上输入值 x 得出的目标值 $\hat y$（也就是我们给数据打算的标签），然后用这些结果跟实际的数据中的 y 值做比较，看看偏差有多大。</p><p>现在你理解了最右边的求和项了吗？</p><p><code>阿特</code>：大概意思是我们从数据中预测出来的 y ？</p><p><code>阿扣</code>：没错，我们先把这一坨替换成 $\hat y$，简化一下公式：</p><p>$$<br>E=\frac{1}{2}\sum_\mu\sum_j[y^\mu_j - f(\sum<em>i w</em>{ij}x^\mu<em>i)]^2<br>\<br>\downarrow<br>\<br>E=\frac{1}{2}\sum</em>\mu\sum_j[y^\mu_j - \hat y_j]^2<br>$$</p><p><code>阿特</code>：世界清静多了~</p><p><code>阿扣</code>：我们再来看右边这个求和项。j 表示有 j 个隐层节点，把每个节点的误差平方 $[y^\mu_j - \hat y_j]$ 计算出来。现在只剩下最后一个求和项了，它表示把 u 个输出节点的误差加起来。这样就得到了总体误差。</p><h3 id="00-的-DeepLearning-笔记"><a href="#00-的-DeepLearning-笔记" class="headerlink" title="00 的 DeepLearning 笔记"></a>00 的 DeepLearning 笔记</h3><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li><li><a href="http://www.uegeek.com/171218DLN4-ActivationFunction.html" target="_blank" rel="noopener">DL笔记：Activation Function 激活函数</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：Activation Function 激活函数</title>
    <link href="http://uegeek.com/171218DLN4-ActivationFunction.html"/>
    <id>http://uegeek.com/171218DLN4-ActivationFunction.html</id>
    <published>2017-12-18T11:20:51.000Z</published>
    <updated>2017-12-18T11:59:31.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p>回顾:</p><ul><li><a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></li><li><a href="http://www.uegeek.com/171209DLN2-NeuralNetworks.html" target="_blank" rel="noopener">DL笔记：Neural Networks 神经网络</a></li><li><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">DL笔记：Linear regression 线性回归</a></li></ul><p><code>阿扣</code>：阿特，今天我们来了解一下深度学习中的激活函数(Activation functions)。</p><p><code>阿特</code>：又是函数……为什么要了解这个哦……</p><p><code>阿扣</code>：在机器学习中，我们经常需要对输出结果打上「是」或「否」标签。比如对一张输入的图片，模型要判断图片里面有没有包含汪星人。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Col.DL.dog_detect.png" alt=""></p><p><a href="http://www.uegeek.com/171213DLN3-LinearRegression.html" target="_blank" rel="noopener">上一回我们提到的逻辑回归</a>，可以用来减少预测值和真实值之间的误差。</p><p><code>阿特</code>：那要怎么做呢？</p><p><code>阿扣</code>：我们来用符号描述一下问题：</p><ul><li>x：训练数据中的 input</li><li>y：训练数据中已经做好标记的 output</li><li>w：逻辑回归的 weights</li><li>b：逻辑回归的 bias</li><li>模型的输出：$\hat y = \sigma (wx + b)$</li></ul><p><code>阿特</code>：老朋友 wx + b</p><p><code>阿扣</code>：好眼力。它就是一个线性模型。别忘了，我们想让输出只包含两个值：是，否。一般我们会用 1 表示「是」，用 0 表示「否」。</p><p><code>阿特</code>：就是我给模型图片 A，它说「0」；给图片 B，它说「1」；……这样？</p><p><code>阿扣</code>：没错~ 所以我们把结果的输出全部转换成或 0 或 1 的值。激活函数就是用来帮助我们实现这种转化的。</p><p><img src="https://ml4a.github.io/images/figures/sigmoid.png" alt=""></p><p>上面我们用到的激活函数叫做 Sigmoid 函数。它帮我们做到了：</p><ul><li>如果输入值 z 是一个大的正数，函数的输出值为 1；</li><li>如果输入值 z 是一个大的负数，函数的输出值为 0；</li><li>如果输入值 z = 0，那么输出值是 0.5</li></ul><p><code>阿特</code>：也就是说，不论我给什么样的整数，最后都会返回 0 或 1 的结果？</p><p><code>阿扣</code>：没错！这样我们得到分类的结果，或 0 或 1。在深度学习中，这种<strong>把输出转化为我们想要的形式的函数</strong>，我们叫它「激活函数」：</p><blockquote><p>激活函数的主要作用是提供网络的非线性建模能力。如果没有激活函数，即便有再多的隐藏层，其整个网络跟单层神经网络也是等价的。加入激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。</p></blockquote><p>上图就是其中的一种激活函数：sigmoid 函数。</p><p><code>阿特</code>：这么说，激活函数不止一种？</p><p><code>阿扣</code>：对呀。下面我列了一些常用的激活函数，作为今天的补充资料吧。现在可能还看不到，先混个脸熟就好。</p><p><code>阿特</code>：好的先刷脸。</p><h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p>$$ sigmoid(z)= \frac{1}{(1+e​^{−z})} $$</p><p>Sigmoid 函数取值范围为(0,1)，将一个实数映射到(0,1)的区间，可以用来做二分类。</p><p><img src="https://ml4a.github.io/images/figures/sigmoid.png" alt=""></p><p>Sigmoid 在特征相差比较复杂或是相差不是特别大时效果比较好。Sigmoid 的导数最大值为0.25。这意味着用来进行反向传播时，返回网络的 error 将会在每一层收缩至少75％（梯度消失问题）。对于接近输入层的层，如果有很多层， weights 更新会很小。</p><h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><p>$$tanh(z)=\frac{e^z-e^{-z}}{e^z+e^{-z}} $$</p><p>也称为双切正切函数，取值范围为[-1,1]。tanh 在特征相差明显时的效果会很好，在循环过程中会不断扩大特征效果。</p><p><img src="http://mathworld.wolfram.com/images/interactive/TanhReal.gif" alt=""></p><h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p>$$ReLU(z) = max(z,0)$$</p><p>ReLU (rectified linear units) 是现在较常用的激活函数。如果输入 &lt; 0，ReLU 输出 0；如果输入 &gt;0，输出等于输入值。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/relu.png" alt=""></p><p>ReLU 计算量小（不涉及除法），一部分神经元的输出为 0 造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。</p><p>ReLU 的缺点是，梯度较大时，ReLU 单元可能大都是 0，产生大量无效的计算（特征屏蔽太多，导致模型无法学习到有效特征）。</p><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>$$ softmax(z) = \frac{e^z{<em>j}}{\sum^K</em>{k=1}e^z{_k}}$$</p><p>Softmax 函数将 K 维的实数向量压缩（映射）成另一个 K 维的实数向量，其中向量中的每个元素取值都介于(0，1)之间。<strong>常用于多分类问题</strong>。Softmax 把分数转换为概率分布，让正确的分类的概率接近 1，其他结果接近 0。相比 Sigmoid，它做了归一化处理。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/N_softmax.png" alt=""></p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101" target="_blank" rel="noopener">Deep Learning Nanodegree | Udacity</a></li><li><a href="https://www.coursera.org/learn/neural-networks-deep-learning" target="_blank" rel="noopener">Neural Networks and Deep Learning | Coursera</a></li><li><a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="noopener">Neural networks and deep learning</a></li><li><a href="http://cs231n.github.io/neural-networks-1/#nn" target="_blank" rel="noopener">Andrej Karpathy’s CS231n course</a></li><li><a href="http://blog.csdn.net/u014595019/article/details/52562159" target="_blank" rel="noopener">深度学习笔记(三)：激活函数和损失函数 - CSDN博客</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>大哉问03 - 什么是赚钱之道？更新你的个人商业模式</title>
    <link href="http://uegeek.com/171216HowToMakeMoney.html"/>
    <id>http://uegeek.com/171216HowToMakeMoney.html</id>
    <published>2017-12-16T11:03:13.000Z</published>
    <updated>2017-12-18T11:44:58.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/dzw03-title.png" alt=""></p><a id="more"></a> <p><a href="http://www.uegeek.com/171112-HowToAskGoodQuestion.html" target="_blank" rel="noopener">大哉问系列</a>讨论完<a href="http://www.uegeek.com/171126TimePerspective.html" target="_blank" rel="noopener">时间</a>和<a href="http://www.uegeek.com/171204HowToLoveYourself.html" target="_blank" rel="noopener">爱</a>，是时候来想想这个重大课题了。</p><p>这篇文章不是经验之谈，而是迟来的反省，也是下一步的行动大纲。</p><h2 id="财富迷思"><a href="#财富迷思" class="headerlink" title="财富迷思"></a>财富迷思</h2><h3 id="为什么要积累财富？"><a href="#为什么要积累财富？" class="headerlink" title="为什么要积累财富？"></a>为什么要积累财富？</h3><p>为了避免话题泛化，这里的「财富」，主要指物质财富、个人的资产。</p><p>有钱当然好。可是到底为什么好？这个问题我们真的有想过吗？到底是什么让我们有持续的动力去追求财富？这是破除迷思的第一个问题。因为赚钱的前提不是方法，而是<strong>欲望</strong>。</p><p>财富可能至少有三方面重要作用：</p><ul><li>提高生活质量：让自己和家人更自如地生活</li><li>缩短成长周期：换取时间，用于自我成长</li><li>获得更多可能性和选择权：贫穷真的真的会限制想象力</li></ul><p>钱越多越好，这毋庸置疑。但是赚钱的目标应该定在哪里合适呢？毕竟人生有限，只花在挣钱上也太枯燥了。大多数人的财务目标大概都会是：实现财务自由。</p><h3 id="什么是财务自由？"><a href="#什么是财务自由？" class="headerlink" title="什么是财务自由？"></a>什么是财务自由？</h3><p>财务自由有客观标准吗？500w？1000w？众说纷纭啊……</p><p>财务自由应该由具体的数值定义吗？我觉得很难。需要找一个定性但可操作的定义。</p><p>这个问题已经有非常多人思考和讨论过了，我比较认同这个目标：</p><blockquote><p>不需要被动出售自己的时间。</p></blockquote><p>换个说法，大概意思是时间都只花在完全由自己选择的事情上面。</p><h3 id="赚钱的瓶颈？"><a href="#赚钱的瓶颈？" class="headerlink" title="赚钱的瓶颈？"></a>赚钱的瓶颈？</h3><p>大部分人（包括我自己）是如何挣钱呢？——批量出售自己的时间（一般是以月为单位）给雇主，然后换取基本固定的薪水——无论干得怎样，薪水的浮动都不大。</p><p>这下子赚钱的天花板就出现了，因为每个人的时间都<strong>极其有限</strong>。</p><p>怎么突破瓶颈呢？一个方法是做薪酬更高的工作。于是我们去增强职场技能、提高工作效率、跳槽到更好的岗位等等，都是在想办法提升单位时间的报酬。</p><p>不过这样也容易掉入时空限制中的「空间」陷阱——「空间」局限意味着影响范围是有限的。一个人的劳动实际上只卖给了一个「空间」：就是这个公司、这个老板。无法 scalable，自然就会遇到瓶颈。（管理很多人是一种 scalable 的办法）</p><h3 id="思考财富的单位？"><a href="#思考财富的单位？" class="headerlink" title="思考财富的单位？"></a>思考财富的单位？</h3><p>想最大限度地保留自己的时间自主权和使用权，该怎么办？</p><p>可以考虑用空间换时间，而不是用时间换金钱。</p><p>怎样用空间换时间呢？——把每单位时间的产出，卖给更多人。</p><p>这里有两个变量：单位时间的产出，和更多人。</p><ul><li>增加单位时间的产出，可以让 1 小时可以写更多好文章、生产更好的产品、打造更完善的系统；也可以尽可能延长产出的寿命，畅销多年而不需要大规模维护。</li><li>同时出售给更多愿意购买的人</li></ul><p>这样，我们思考获得财富的单位，应该是<strong>有价值的结果</strong>，而不再是「月薪」，不再是一去不复返的时间。</p><h2 id="赚钱的三大途径"><a href="#赚钱的三大途径" class="headerlink" title="赚钱的三大途径"></a>赚钱的三大途径</h2><p>赚钱的方法何止千千万，但是<strong>从本质上讲，大概有三类：生产，服务和交易</strong>。</p><p>比如，制造可售卖的商品属于生产，搭建一个付费 APP 是生产；提供专属的理财咨询属于服务；炒币和投资房产属于交易。</p><p>那么上班属于哪一类？其实属于<strong>服务</strong>，因为肉身必需出现，而且离实际购买的消费者比较远，工作报酬受契约约束，而不是实际产出的市场价值本身的体现。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/wealth-title.jpg" alt=""></p><p>再深入一步，让我们想想这三大途径的特点：</p><table><thead><tr><th>方式</th><th>投入</th><th>产出</th><th>买单</th><th>瓶颈</th></tr></thead><tbody><tr><td>生产</td><td>原料，生产设备/技术/流程，销售</td><td>产品</td><td>顾客</td><td>生产率，获客成本</td></tr><tr><td>交易</td><td>资金/成本，决策信息，时间差</td><td>价格差</td><td>需方</td><td>时机，关键信息，资本</td></tr><tr><td>服务</td><td>时间，技能</td><td>交付物</td><td>雇主</td><td>时间，技能，消费频次</td></tr></tbody></table><p>我们的目标是提高赚钱能力，一个思路是从单一途径到覆盖三种途径，另外一个思路是想办法突破每个方式的瓶颈。</p><h3 id="一、优化生产"><a href="#一、优化生产" class="headerlink" title="一、优化生产"></a>一、优化生产</h3><p>什么是生产？有完整、有价值、可购买的产出。</p><p>我们大多数人有可能从来没有从事过正经的「生产」工作，因为我们可能没有想过，或者无法独立提供完整的产出。是的，从来！……细思极恐啊！</p><p>但其实绝大多数人都有个人生产的能力。</p><p>比如，门槛较低的内容生产——以文字、语言、视频等方式产出内容。内容生产的「原料」是什么？是经验，是思考，是感受，是对他人有帮助的对话。生产设备/技术/流程包括什么？构思，收集，整理，编写，修改，设计，发表，互动……瓶颈是什么？没有擅长/有积累的可持续创作的话题，拖延，没有读者……</p><p>这些问题很难解决吗？似乎不是，都有很多办法，而且身边容易找到有经验的人。最大的瓶颈大概是一没有开始，二没有持续，三没有改进。</p><p>尽早尝试适合自己的个人生产方式吧，早积累，早收获。</p><h4 id="升级1：产品化"><a href="#升级1：产品化" class="headerlink" title="升级1：产品化"></a>升级1：产品化</h4><p>产出可以分为两种：需要值守的，无需值守的。</p><p>如果每次生产都需要自己在一旁守着，时间还是被占用了啊。所以生产的第一个升级目标是：产品化。<strong>产品化意味着有明确的人群和需求定义，让生产流程和产出都遵循一定标准，以保证产出的稳定，成为可出售的「产品」</strong>。比如把零散的知识和文章整理成一门课程，录制一次，后期就不需要投入太多精力维护。</p><p>想办法让生产过程自动化，构建属于自己的生产系统，这大概就是个人商业模式的核心。</p><h4 id="升级2：关注生产效率"><a href="#升级2：关注生产效率" class="headerlink" title="升级2：关注生产效率"></a>升级2：关注生产效率</h4><p>生产的第一大指标（或者说瓶颈）就是生产效率。认真思考影响生产效率都有哪些因素。有没有可能通过购买的方式提高生产率？另外要注意，所谓效率，一定与时间周期有关，是否给自己设定了合理、可产生回报的生产周期?</p><h4 id="升级3：选择人群和经营渠道"><a href="#升级3：选择人群和经营渠道" class="headerlink" title="升级3：选择人群和经营渠道"></a>升级3：选择人群和经营渠道</h4><p>谁会购买你的产品？他们在哪里聚集？你在那里是否有影响力？如何获取信任？如何与他们互动？</p><h4 id="升级4：企业化"><a href="#升级4：企业化" class="headerlink" title="升级4：企业化"></a>升级4：企业化</h4><p>一个人再怎么提高效率也是有限的。下一步升级就要靠更多人参与了。以公司经营的方式维持产品的生产、运营和增长，将个人商业模式往公司商业模式迁移。所谓企业家，就是找到资源的更优组织方式，为大家的利益解决问题的人。</p><h3 id="二、优化交易"><a href="#二、优化交易" class="headerlink" title="二、优化交易"></a>二、优化交易</h3><p>成功的交易，大概是提前锚定价格差，寻找价值洼地并持有，并在合适时间出售。</p><p>从今天开始，经常问自己一个问题：</p><blockquote><p>什么会在未来很值钱？</p></blockquote><p><img src="https://cdn.dribbble.com/users/828451/screenshots/3088929/hf001_vestly-05.jpg" alt=""></p><p>投资那些未来很可能增值的资产，可能是公司股票，可能是房产，可能是古董，可能是火星矿产，也可能是——人，尤其是，自己。</p><p>好的交易，关乎资本大小，但更重要的是决策信息，而最最关键的是，时机。</p><p>好的决策来自思考质量和经验。建立起自己的思考模型，积累特定领域的知识和投资经验，这些都需要时间投入。选择合适的交易时机，更是需要了解人性的弱点和各种认知偏差，因为投资本来是件由概率这只大手所操控的事件，而概率实在太反直觉了。</p><p>想要获得更高收益，原理其实并不复杂：</p><p>$收益 = 本金 * (1+复合年化收益率)^{年数}$</p><p><strong>所以，要学好概率，练好头脑，控制风险，培养耐心。</strong></p><p>好吧，如何开始，交易的本金从哪里来？没有太多选择的话，只能从生产来。而且最好保证有持续的生产收益，作为交易的本金，而不是只依靠交易作为唯一的赚钱途径——因为那样太容易影响交易的心态和判断。</p><h3 id="三、优化服务"><a href="#三、优化服务" class="headerlink" title="三、优化服务"></a>三、优化服务</h3><p>服务其实是最特殊的挣钱方式，必需通过本人和服务过程去完成。因为在三种途径里面，这是最消耗时间的，所以更加应该找到优化的方式。</p><p>提高服务的收益的一个可能是，组织一个服务平台，聚集服务供需双方，把服务转化成生产。不过这又属于生产的话题了。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/illustration-04.jpg" alt=""></p><p>既然时间无法复制，那就只能打提高单位时间的服务收益的主意了。影响收益的，似乎最终可以归结为一个因素：稀缺性。</p><p>而稀缺性又由两方面影响：</p><ul><li>需求有多迫切，是不是高频、刚需。这就需要研究雇主/买主的需求了。比如招聘的公司处在什么阶段？最需要什么样的人才？</li><li>独特的核心竞争力组合。找单一领域的专家总是相对容易的，找到复合型大咖难度就高很多，同时横跨多个高速发展的领域，只能是炙手可热了。</li></ul><p>所以，尽早投资在需求会持续增长的服务领域，并且培养自己的独特竞争力、跨界能力，其他就交给时间吧！</p><h2 id="财富积累的放大器"><a href="#财富积累的放大器" class="headerlink" title="财富积累的放大器"></a>财富积累的放大器</h2><p>善用一些已经被反复验证过的原则，能够帮助我们放大为获取财富所付出的努力。</p><h3 id="铁律：生产率-gt-收入-gt-负债"><a href="#铁律：生产率-gt-收入-gt-负债" class="headerlink" title="铁律：生产率 &gt; 收入 &gt; 负债"></a>铁律：生产率 &gt; 收入 &gt; 负债</h3><p><strong>尽可能让个人生产率提升的速度，超过收入增长，远远超过负债的增加。</strong></p><p>这几乎就是个人积累财富的全部秘密了。这个不等式出自下面这个视频：</p><p><a href="https://v.qq.com/x/page/z01685nf12f.html" target="_blank" rel="noopener">三十分钟说清经济机器是怎样运行的</a></p><p>出自 Ray Dalio 大佬的视频把经济的底层规律总结得深入浅出。也许很多大学四年的经济学教育，还没有这十分钟的视频内容深刻且有效。墙裂推荐，值得每半年复习一次。</p><h3 id="善用过去的积累"><a href="#善用过去的积累" class="headerlink" title="善用过去的积累"></a>善用过去的积累</h3><p>不要觉得自己是从零开始。</p><p>如果你在职场有几年经验，不要忽视得到过的职业锻炼：自律，沟通和表达能力，学习能力，合作能力，自我/上下/平级的管理能力，等等。把它们通通用在生产和交易上，并且持续打磨这些技能。能服务好别人的人，更懂得如何生产出好的产品。一直练习交易的人，更容易发现应该在哪些领域持续打造自己的核心竞争力。</p><p>去发现那些在某些领域遍地都是、但是在另一个领域稀缺的东西，从中套利。</p><h3 id="尊重时间的复利"><a href="#尊重时间的复利" class="headerlink" title="尊重时间的复利"></a>尊重时间的复利</h3><p>经常回顾指数增长的曲线吧，那是我们的目标曲线——无论是财富增长也好，个人成长也好。</p><p><img src="https://dare2.dk/demo/wp-content/uploads/2015/09/Exponential-curve.png" alt=""><br>via <a href="https://dare2.dk/top-3-steps-for-becoming-an-exponential-organization/" target="_blank" rel="noopener">Top 3 Steps for Becoming an Exponential Organization | DARE2</a></p><p>不要忽视、低估积累期、平台期的长度和难度，但要想办法加快增长速度，尽快到达「奇点」。</p><h3 id="用财富换幸福"><a href="#用财富换幸福" class="headerlink" title="用财富换幸福"></a>用财富换幸福</h3><p>在积累财富的跑道上，不要忘记我们的目标和初心。赚钱可能没有你想象那么难，它可能没有你想象那么重要。（前提是你已经得到了它）</p><p><strong>实现财务自由是为了什么？获得自由的时间要用来做什么？</strong>这才是真正重要的问题。</p><p>努力赚钱之余，<strong>千万不要忘了发现和保护内在动机，去坚持做那些（现在）不但不能帮你赚钱，还需要你补贴钱或时间去做的事情</strong>，因为那些才是你的心头所好啊！我们这么努力，还不是为了能跟那些事情长相厮守在一起？</p><p>最终的最终，我们换取的可能都是用于创造心流的环境。如果现在就有这样的条件，保留一部分时间去体验创作的心流，还有什么理由不开始呢？</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>总结下来，道理其实都十分简单明了，不过 7 个要点：</p><ul><li>财务自由指不需要被动出售自己的时间，这是赚钱的阶段性目标</li><li>思考财富的单位应该是有价值的结果，而不是时间周期</li><li>生产、交易、服务是挣钱的三大途径</li><li>生产优化：让生产过程自动化，构建属于自己的生产系统</li><li>交易优化：形成有预见性的预判，寻找价值洼地并持有，并在合适时间出售</li><li>服务优化：满足高频、刚需的需求，不断积累出独特的核心竞争力组合</li><li>利用四大财富放大器：财富不等式，过去的积累，时间的复利，财富换幸福</li></ul><p>以及需要经常复习：</p><ul><li>一个问题：什么会在未来很值钱？</li><li>一个图表：指数增长</li><li>一个视频：经济是如何运行的</li></ul><p>好了，我想到的是这些了。</p><p>最后，对自己说：想明白了就去践行吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/dzw03-title.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="CriticalThinking" scheme="http://uegeek.com/tags/CriticalThinking/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="Love" scheme="http://uegeek.com/tags/Love/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：Linear regression 线性回归</title>
    <link href="http://uegeek.com/171213DLN3-LinearRegression.html"/>
    <id>http://uegeek.com/171213DLN3-LinearRegression.html</id>
    <published>2017-12-13T11:02:19.000Z</published>
    <updated>2017-12-18T11:20:12.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p><code>阿扣</code>：今天带你了解一下线性回归。</p><p><code>阿特</code>：🙄 听起来就不是什么容易懂的东西……为什么要了解线……什么，线性回归呢？</p><p><code>阿扣</code>：什么<a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">机器学习啊深度学习啊</a>，最终目的之一不就是<strong>根据已有数据做出预测</strong>，回归和分类都是「做预测」的主要手段。在下面这张图中找找看，线性回归在机器学习中的位置：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/LinearRegressionInML.png" alt=""></p><p><code>阿特</code>：如果说目的都是做「预测」，回归分析和分类有什么不同呢?</p><p><code>阿扣</code>：<strong>回归得到预测的具体数值</strong>，比如股市的行情、未来的气温值。<strong>而分类得到一个「声明」，或者说对数据打上的标签</strong>。</p><p><code>阿特</code>：那什么是线性回归呢？</p><p><code>阿扣</code>：线性回归是最基础的回归类型，它的定义是这样：</p><blockquote><p>在统计学中，线性回归（Linear regression）是利用线性回归方程的最小平方函数，对一个或多个自变量和因变量之间关系建模的一种回归分析。这种函数是一个或多个回归系数的模型参数的线性组合。</p></blockquote><p><code>阿特</code>：好吧，看不懂……不过我主要不明白的是「回归」的意思，要回哪里哦……</p><p><code>阿扣</code>：初中时学的解方程还记得吧？方程左边有 X，求方程右边的 Y： ax + b =y 。</p><p><code>阿特</code>：这个还是记得的。</p><p><code>阿扣</code>：回归分析假设 X 和 Y 之间是有奸情哦不对是有关系的，用于了解只有一个自变量 X 时，因变量 Y 的变化。</p><ul><li>鬼话版：回归分析用来估计模型的参数，以便最好地拟合数据</li><li>人话版：「回归」的目的呢，就是<strong>找出一个最能够代表所有观测数据的函数，来表示 X 和 Y 的关系</strong>。这个函数只有一个变量，所以是类似这样的一条直线：</li></ul><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/640px-Linear_regression.svg.png?1512632790654" alt=""></p><p><code>阿特</code>：好像我记得那种方程在坐标轴上就是用一条直线来表示。不过怎么基于这条直线做预测呢？</p><p><code>阿扣</code>：其实不是基于这条线，而是 <strong>「找出」这条最符合 X 和 Y 的关系的线 (line of best fit)，认定这就是它们之间的「关系」，然后去做预测</strong>。</p><p>我们先来用符号把这个 X 和 Y 的关系表达式写出来。A 表示我们手上有的数据集，比如你每天的能量摄入和体重值，哈哈哈，然后可以用它来预测你什么时候会变成个胖纸~</p><p><code>阿特</code>：紧脏……</p><p><code>阿扣</code>：来看看这张图，我告诉你每个字母代表什么：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/linearClassifier1.png" alt=""></p><p><code>X</code> 是每天的能量摄入，<code>y</code> 是体重。我们想预测你的未来体重 $\hat y$ (给字母加个帽子一般表示它的预测值)，于是用 能量输入 乘以一个权重(weight) <code>W</code>，加上一个偏置项(bias) <code>b</code>，就是计算体重的函数了。</p><p>$$WX + b = y$$</p><p><code>阿特</code>：好像蛮简单的。</p><p><code>阿扣</code>：是啊。这个式子以后我们还会无数次看到，是老朋友来的。</p><p>关于回归分析，再多说两句。</p><p><code>阿特</code>：我有预感不止 20 句……</p><p><code>阿扣</code>：它有三个主要用途：</p><ul><li>因果分析：确定<strong>自变量对因变量的影响的强度</strong>。比如计算剂量和效应，销售和营销支出，年龄和收入之间的关系。</li><li>预测影响：预测影响或变化的影响，即<strong>因变量随着一个或多个自变量的变化而变化多少</strong>。典型的问题是，「增加一个单位 X， Y 能增加多少？」</li><li>趋势预测：<strong>预测趋势和未来价值</strong>。比如，「从现在起6个月，黄金的价格是多少？」，「任务 X 的总体成本是多少？」</li></ul><p><code>阿特</code>：好像很强大，那它有什么缺点呢？</p><p><code>阿扣</code>：有两个主要的缺点：</p><ul><li>只适用于本身是线性关系的数据</li><li>对 outliner 敏感</li></ul><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/lin-reg-w-outliers.png" alt=""></p><p>比如上图右上角的几个点，偏离平局值比较多，我们叫 outliner。出现这种情况，我们可以试试其他的回归分析类型，或者放弃回归分析，用其他的算法了。</p><table><thead><tr><th>Name</th><th>名称</th><th>因变量个数</th><th>自变量个数</th></tr></thead><tbody><tr><td>Simple linear regression</td><td>简单线性回归</td><td>1</td><td>1</td></tr><tr><td>Multiple linear regression</td><td>多元线性回归</td><td>1</td><td>2+</td></tr><tr><td>Logistic regression</td><td>逻辑回归</td><td>1</td><td>2+</td></tr><tr><td>Ordinal regression</td><td>序数回归</td><td>1</td><td>1+</td></tr><tr><td>Multinominal regression</td><td>多项式回归</td><td>1</td><td>1+</td></tr><tr><td>Discriminant analysis</td><td>判别分析</td><td>1</td><td>1+</td></tr></tbody></table><p>如果需要预测的结果依赖于多个变量，可以用多元线性回归，比如：</p><p>$$y = m_1x_1 + m_2x_2 + b$$</p><p>我们用一个三维平面来表示这个二元线性回归：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/just-a-2d-reg.png" alt=""></p><p><code>阿特</code>：那么多回归类型，不会都要掌握吧？</p><p><code>阿扣</code>：嗯，我们接触比较多的是逻辑回归(Logistic regression)。下回给你讲讲逻辑回归要用到的激活函数吧。</p><p><code>阿特</code>：🐵 </p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.wikiwand.com/zh/%E8%BF%B4%E6%AD%B8%E5%88%86%E6%9E%90" target="_blank" rel="noopener">迴歸分析 - Wikiwand</a></li><li><a href="https://www.wikiwand.com/zh/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8" target="_blank" rel="noopener">線性回歸 - Wikiwand</a></li><li><a href="http://www.statisticssolutions.com/what-is-linear-regression/" target="_blank" rel="noopener">What is Linear Regression? - Statistics Solutions</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：Neural Networks 神经网络</title>
    <link href="http://uegeek.com/171209DLN2-NeuralNetworks.html"/>
    <id>http://uegeek.com/171209DLN2-NeuralNetworks.html</id>
    <published>2017-12-09T11:01:34.000Z</published>
    <updated>2017-12-18T11:17:20.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png" alt=""></p><a id="more"></a> <p>回顾 - <a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">DL笔记：机器学习和深度学习的区别</a></p><p><code>阿特</code>：听说深度学习的思想受到神经网络的启发，那是什么玩意儿？</p><p><code>阿扣</code>：神经网络包括生物神经网络和人工神经网络。在生物神经网络中，每个神经元与其他神经元相连。它接收其他神经元的输入，当电位超过了某个阈值（threshold）而被「激活」时，会向相连的神经元「发射」（fire）信号。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/neuralNetwork.png" alt=""></p><p><code>阿特</code>：那跟<a href="http://www.uegeek.com/171206DLNote1-ML-DL-Basic.html" target="_blank" rel="noopener">机器学习</a>有关系吗？机器没有生命啊……</p><h3 id="Perceptrons-感知机"><a href="#Perceptrons-感知机" class="headerlink" title="Perceptrons 感知机"></a>Perceptrons 感知机</h3><p><code>阿扣</code>：参考生物神经网络，在计算机科学中，我们将独立的计算单元看做神经元。感知机 (Perceptron) 是神经网络的基本单位。每一个感知机都完成类似「给我一个数字，我告诉你它是正还是负」这样的简单任务。</p><p>比如说，我们把神经元看做包含一个 0 到 1 之间数字的小球：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/perceptron-s.png" alt=""></p><p>神经元里面的数字叫激活函数 (Activation)。当数字超过某个阈值，比如说 0.5 时，我们就说这个神经元被激活了，它会输出 1 作为信号。如果神经元包含的数字小于 0.5，那它就输出 0，表示没有被激活。</p><p>这个神经元就是一个感知机。</p><p>一个感知机接收若干二进制输入 $x_1,x_2,…$，然后产生一个二进制输出：</p><p><img src="http://neuralnetworksanddeeplearning.com/images/tikz0.png" alt=""></p><p><code>阿特</code>：这小球长得倒是有那么一丢丢像神经元……</p><p><code>阿扣</code>：在这个最简单的系统里，包含：</p><ul><li>输入：这个神经元接收到的其他神经元的信号</li><li>判断器：激活函数</li><li>输出：1 表示 yes「发射」，0 表示 no「不发射」</li></ul><p><code>阿特</code>：艾玛，这也叫简单？</p><p><code>阿扣</code>：它其实是这个意思：</p><p><img src="https://viniciusarruda.github.io/images/mp_neuron.png" alt=""></p><p><code>阿特</code>：好吧我错了……让我晕一晕</p><p><code>阿扣</code>：其实主要看蓝色的字就好。神经元怎么计算输出呢？我们引入「权重」(weights)，它表示从输入到输出的重要程度。权重的和 $\sum_j w_jx_j$ 如果大于阈值 $v_k$，就输出 1。</p><p>每一层神经元因为拥有上一层神经元的「经验」（上一层的输出），所以可以做出更抽象的「决策」。当我们把许多这样的神经元按一定的层次结构连接起来，就得到了人工神经网络（Artificial Neural Network）。</p><p><code>阿特</code>：ANN，那我可以叫它 安？</p><p><code>阿扣</code>：你喜欢咯…… 其实所有的深度学习的神经网络，都可以抽象成三个部分：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/neuralNetwork1.png" alt=""></p><p>除了输入和输出层，中间的层都叫隐层。<strong>深度神经网络就是隐层数量很多的神经网络，深度学习就是从多层神经网络中，自动学习出各种 pattern。</strong></p><p><code>阿特</code>：666！能不能 input 废纸 output 比特币呀？</p><p><code>阿扣</code>：……吃药时间到了</p><h3 id="利用深度神经网络进行学习"><a href="#利用深度神经网络进行学习" class="headerlink" title="利用深度神经网络进行学习"></a>利用深度神经网络进行学习</h3><p><code>阿扣</code>：总结一下，对神经网络来说，<strong>输入层是数据集/变量，隐层是变量之间的关系（包含变量权重），形成高一级别的「模式」传递给下一个隐层，最后确定输出层的结果。</strong></p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/ANN_example.png" alt=""></p><p><code>阿特</code>：为什么我总是听说「训练」神经网络好让它「学习」呢？</p><p><code>阿扣</code>：训练神经网络的目标，其实就是<strong>计算和调整权重 weights，使得模型输出结果最接近真实的数据集。</strong></p><p><code>阿特</code>：好抽象哦……</p><p><code>阿扣</code>：举个例子，我们要预测房价的走势。假设知道房子大小可以预测房价，这个关系就可以用一个神经网络节点（node）来简单估计。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/fangjia_example.png" alt=""></p><p>如果我们知道很多房子的信息怎么办呢？这时候就需要很多的节点，这些节点构成神经网络。房子的多种信息作为输入，房价的预测值作为输出，中间层（可以有多个）是用来计算出前面一层信息的权重，得出一定的模式，传导给下一层，直到最后得出预测值 y。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/ngcourse_housingprice.png" alt=""></p><p>via: <a href="https://www.coursera.org/learn/neural-networks-deep-learning" target="_blank" rel="noopener">Neural Networks and Deep Learning | Coursera</a></p><p><code>阿特</code>：好像有点明白了，让机器自己学习中间隐藏起来看不见的「规律」！</p><p><code>阿扣</code>：再举个例子，图像识别是深度学习最广泛的应用之一，我们给系统看一张图，它能告诉我们这张图里有没有汪星人：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/HowToRecognizeDog.png" alt=""></p><p><code>阿特</code>：哇，原来机器在背后做了这么多事情，我还以为机器都很聪明呢，原来它们只是比较勤奋哈哈哈</p><p><code>阿扣</code>：你得到了它~</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="noopener">Neural networks and deep learning</a></li><li><a href="https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101" target="_blank" rel="noopener">Deep Learning Nanodegree | Udacity</a></li><li><a href="https://www.coursera.org/learn/neural-networks-deep-learning" target="_blank" rel="noopener">Neural Networks and Deep Learning | Coursera</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/Art_Code_Bro.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>DL笔记：机器学习和深度学习的区别</title>
    <link href="http://uegeek.com/171206DLNote1-ML-DL-Basic.html"/>
    <id>http://uegeek.com/171206DLNote1-ML-DL-Basic.html</id>
    <published>2017-12-06T01:24:46.000Z</published>
    <updated>2017-12-09T01:27:46.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg.png" alt=""><br>via <a href="https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/" target="_blank" rel="noopener">The Difference Between AI, Machine Learning, and Deep Learning? | NVIDIA Blog</a></p><a id="more"></a> <p>Nvidia 博客上的这张图很好表示了 AI, Machine Learning, Deep Learning 三者的关系。人工智能是一类非常广泛的问题，机器学习是其中一个重要领域和手段，<strong>深度学习则是机器学习的一个分支</strong>。在很多人工智能问题上，深度学习的方法突破了传统机器学习的瓶颈，因而影响力迅速扩大。</p><h3 id="什么是机器学习？"><a href="#什么是机器学习？" class="headerlink" title="什么是机器学习？"></a>什么是机器学习？</h3><p><img src="https://uploads.toptal.io/blog/image/443/toptal-blog-image-1407508081138.png" alt=""></p><p>00 试着翻出一些机器学习相对权威的定义，看看它们有什么共同点：</p><table><thead><tr><th>Definition</th><th>Translation</th><th>Source</th><th>Key words</th></tr></thead><tbody><tr><td>The field of machine learning is concerned with the question of how to construct computer programs that automatically improve with experience.</td><td>机器学习聚焦于一个问题：如何构建随着经验而自动改进的计算机程序。</td><td>Tom Mitchell in  <a href="http://www.amazon.com/dp/0070428077?tag=inspiredalgor-20" target="_blank" rel="noopener">Machine Learning</a></td><td>会自我改进的程序</td></tr><tr><td>Vast amounts of data are being generated in many fields, and the statisticians’s job is to make sense of it all: to extract important patterns and trends, and to understand “what the data says”. We call this learning from data.</td><td>从数据中提取重要的模式和规律/趋势</td><td><a href="http://www.amazon.com/dp/0387848576?tag=inspiredalgor-20" target="_blank" rel="noopener">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a></td><td>模式提取</td></tr><tr><td>Pattern recognition has its origins in engineering, whereas machine learning grew out of computer science. However, these activities can be viewed as two facets of the same field…</td><td>模式识别和机器学习是一体两面</td><td>Bishop in <a href="http://www.amazon.com/dp/0387310738?tag=inspiredalgor-20" target="_blank" rel="noopener">Pattern Recognition and Machine Learning</a></td><td>模式识别</td></tr><tr><td>Machine Learning is the training of a model from data that generalizes a decision against a performance measure.</td><td>机器学习是通过用于决策的数据去训练模型，并达到某些运行标准</td><td><a href="http://machinelearningmastery.com/author/jasonb/" target="_blank" rel="noopener">Jason Brownlee</a> in <a href="http://machinelearningmastery.com/what-is-machine-learning/" target="_blank" rel="noopener">What is Machine Learning: A Tour of Authoritative Definitions and a Handy One-Liner You Can Use</a></td><td>通过数据训练模型</td></tr></tbody></table><p>简单来说，就是机器通过一系列「任务」从「经验」（数据）中学习，并且评估「效果」如何：</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Col.DL.ETP.png" alt=""></p><p>为什么叫做「学习」呢？一般编程语言的做法，是定义每一步指令，逐一执行并最终达到目标。而机器学习则相反，先定义好输出，然后程序自动「学习」出达到目标的「步骤」。</p><p>机器学习可以分为：</p><ul><li>监督学习：给出定义好的标签，程序「学习」标签和数据之间的映射关系</li><li>非监督学习：没有标签的数据集</li><li>强化学习：达到目标会有正向反馈</li></ul><p><img src="https://i1.wp.com/cybrml.com/wp-content/uploads/2017/01/MachineLearningDiagram.png?resize=770%2C551" alt=""></p><h3 id="机器学习擅长做什么？"><a href="#机器学习擅长做什么？" class="headerlink" title="机器学习擅长做什么？"></a>机器学习擅长做什么？</h3><p>当然是替代重复的人工劳动，用机器自动从大量数据中识别模式——也就是「套路」啦。知道「套路」后，我们可以干嘛呢？</p><ul><li>Classification 分类，如垃圾邮件识别(detection, ranking)</li><li>Regression 回归，例如股市预测</li><li>Clustering 聚类，如 iPhoto 按人分组</li><li>Rule Extraction 规则提取，如数据挖掘</li></ul><p>比如垃圾邮件识别的问题，做法是先从每一封邮件中抽取出对识别结果可能有影响的因素（称为特征 feature），比如发件地址、邮件标题、收件人数量等等。然后使用算法去训练数据中每个特征和预测结果的相关度，最终得到可以预测结果的特征。</p><p>算法再强大，如果无法从数据中「学习到」更好的特征表达，也是徒劳。同样的数据，使用不同的表达方法，可能会极大影响问题的难度。一旦解决了数据表达和特征提取问题，很多人工智能任务也就迎刃而解。</p><h3 id="为什么需要深度学习？"><a href="#为什么需要深度学习？" class="headerlink" title="为什么需要深度学习？"></a>为什么需要深度学习？</h3><p>但是对机器学习来说，特征提取并不简单。特征工程往往需要人工投入大量时间去研究和调整，就好像原本应该机器解决的问题，却需要人一直在旁边搀扶。</p><p>深度学习便是解决特征提取问题的一个机器学习分支。它可以自动学习特征和任务之间的关联，还能从简单特征中提取复杂的特征。</p><p><img src="http://7xjpra.com1.z0.glb.clouddn.com/Col.DL.ML_vs_DL.png" alt=""></p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="http://machinelearningmastery.com/what-is-machine-learning/" target="_blank" rel="noopener">What is Machine Learning: A Tour of Authoritative Definitions and a Handy One-Liner You Can Use - Machine Learning Mastery</a></li><li><a href="https://book.douban.com/subject/26708119/" target="_blank" rel="noopener">机器学习 (豆瓣)</a></li><li><a href="https://book.douban.com/subject/26976457/" target="_blank" rel="noopener">Tensorflow：实战Google深度学习框架 (豆瓣)</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;via &lt;a href=&quot;https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The Difference Between AI, Machine Learning, and Deep Learning? | NVIDIA Blog&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="动手" scheme="http://uegeek.com/categories/%E5%8A%A8%E6%89%8B/"/>
    
    
      <category term="Python" scheme="http://uegeek.com/tags/Python/"/>
    
      <category term="深度学习" scheme="http://uegeek.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="AI" scheme="http://uegeek.com/tags/AI/"/>
    
      <category term="ArtxCode" scheme="http://uegeek.com/tags/ArtxCode/"/>
    
      <category term="DeepLearning" scheme="http://uegeek.com/tags/DeepLearning/"/>
    
      <category term="Coding" scheme="http://uegeek.com/tags/Coding/"/>
    
  </entry>
  
  <entry>
    <title>大哉问02 - 如何爱自己？拟一份爱的宣言</title>
    <link href="http://uegeek.com/171204HowToLoveYourself.html"/>
    <id>http://uegeek.com/171204HowToLoveYourself.html</id>
    <published>2017-12-04T01:16:18.000Z</published>
    <updated>2017-12-09T01:23:32.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/love_yourself.jpg" alt=""></p><a id="more"></a>  <p>这是一个困扰我已久的问题。</p><p>以前，朋友会跟我说「你不够爱自己」。除了愕然，好像多少有些认同，可是再进一步也不知道该做些什么。最近这大半年近距离接触了心理咨询，每次看到「爱己才能爱人」这个几乎是所有情感问题解药中的配方出现，也就时不时会想起这个问题。</p><p>可是，「爱自己」这简单的三个字，到底要怎么做？</p><h2 id="烦恼之源"><a href="#烦恼之源" class="headerlink" title="烦恼之源"></a>烦恼之源</h2><p>阿德勒说，所有的烦恼都来自于人际关系。我想，他说的人际关系，既包含与他人的关系，但首先是与自己的关系。在所有人际关系问题的表象之下，根源也许都是我们与自己的关系出现了紧张。</p><p>我们容易焦虑。且不说在焦虑的时候，「自己」在不在场，有没有提供应有的安慰。更棘手的是，这些焦虑的来源，往往就是我们自己。</p><p>所以我们感到痛苦，想要逃避，不断寻求一种来自外部的肯定，确认自己是有价值的、好的、受欢迎的、值得被爱的。在困顿无助的时候，因为自己给不出，所以时时想伸手向外寻求安抚。</p><p>我们甚至不知道自己要什么，不与自己耐心对话，而是下意识地、急不可耐地抓过一些能彰显某种身份的标识装扮在身上，尝试告诉自己和世界，我是一个怎样的人，你们应该怎样对待我。</p><p>阿德勒给出的解药是：人只有在觉得自己有价值的时候，才会有勇气。而价值不由「做了什么」来提供，那是有条件的价值。如果我们能以「存在」的视角来看待自己，认可存在本身就是价值，就能使自我的关系更加和谐。</p><p>跟别人的关系，再亲密也好，也有可能或主动或被动终结。但是自己跟自己相处一辈子，无法欺瞒，无法离弃。处理好跟自己的关系，真真是人生必修第一课。</p><p>如果用一种比喻形容你和自己的关系，会是什么？</p><p>对「如何爱自己」这个问题，这会是一个好的开始。</p><h2 id="从爱他人学着爱自己"><a href="#从爱他人学着爱自己" class="headerlink" title="从爱他人学着爱自己"></a>从爱他人学着爱自己</h2><p>「爱自己，就给自己买 xxx」</p><p>这大概是时下最流行的广告语。如果爱自己只是愿意花钱，只是时时放过自己，那未免也太容易了，我怎么一直没学会呢？</p><p>可能因为，<strong>爱是一种需要付出艰辛努力和持续练习才能获得的能力。</strong></p><p>如果一个问题我没法理解，就会用「类比和迁移」的办法。比如，先去想想我是怎么喜爱某个兴趣的，怎么把这种喜爱转换到自己身上。</p><p>但是行不通。因为「爱」是一个关系和相处问题，不能缺少人这个因素，无法只靠逻辑去求解。</p><p>似乎只能选择与你关系最亲密的人作为对象，把经验迁移过来：</p><blockquote><p>你如何去爱一个人？</p></blockquote><p>当你有要爱的人，就会变得勇敢和愿意付出。想想你会如何把最好的事物和感情交付给所爱的人？尤其当这个人需要你保护和付出时，比如你已经为人父母，选择小孩为对象来类比和迁移经验，就再适合不过了。</p><p>有时候问题就是这么吊诡——当我们不会爱别人，我们可能就不会爱自己；当我们不爱自己，就没法很好地爱别人。到底从哪一端开始？就从现在所处的位置开始吧，以一个新的角度看待与自己的关系。</p><h2 id="爱是一种练习"><a href="#爱是一种练习" class="headerlink" title="爱是一种练习"></a>爱是一种练习</h2><p>什么是爱？<strong>弗洛姆说：爱是一种能自觉地为被爱者的发展和幸福而付出一切努力的代称。</strong></p><p>让我们暂时把这句话作为「爱自己」的总纲领吧。</p><p>可是只有纲领还不够，我们还要细细去追问，我们可以如何爱人，我们应该如何爱自己。以下的铺陈，不是已经掌握的能力，而是「爱他人和爱自己」的详细理解，是行动纲领，是愿景，是坚持不懈的练习目标。</p><h3 id="忠于自己"><a href="#忠于自己" class="headerlink" title="忠于自己"></a>忠于自己</h3><p>世间有千万种勇气，最不能丧失的一种，叫做「直面自己」。这是对爱情也不能让步的。</p><p>每个人都需要面对自己过去生命里的困顿、失落、挫折。有时候这些负担太沉重，不希望它们如影随形，所以我们选择打造一个面具，或者任由「超我」去规划和引导一条偏离原本轨迹的人生航线。越是掩埋过去，离真实的自己好像就越遥远。失去真实，力量就会耗费在与自己的斗争中，无暇照顾其他。</p><p><strong>接受对方的一切，只要那是真实的。——这大概是爱他人和爱自己的第一原则</strong></p><p>台湾作家陈雪有一段话说得好：</p><blockquote><p>爱是即使在孤独中依然可以付出力量，爱是：我珍爱你的脆弱孤独，你的别扭，你的生硬，你的艰难，爱是正因为我知道我可以穿透那些硬壳看见最脆弱的你，那无意间暴露在我眼前的，使我想要细心爱怜。</p></blockquote><p>使人相爱的最终是安全和信任，而不应该是幻想成分居多的期望。</p><p>因为爱你，所以信任你，希望你在我身边可以做自己，像草木一样自如。因为爱你，所以想要陪你去细细区分，哪些是内心真正认同的；哪些是过去的伤害所结的伤疤，不想去触碰；哪些习性反应是即使伤口早已愈合，却还是习得性回避的东西。</p><p>因为爱自己，所以给自己安全和信任，而不是持续地声明种种期望。时时留心公平地对待本我/自我/超我，不过分关注超我，因为那样反而滋长它。接受本我，不去对抗一些出厂设置。让自我积极探索，回答「我是谁」的问题。</p><p>来自底层、最为无条件的信任，只能自己供给。<strong>接受任何面貌的自己，不推诿，不辩解，不自我攻击。</strong>在主动成长之前，不要求，不期待，然后才会放胆去探索。<strong>放弃要求并不意味着放任自流，因为你相信自己会选择合适的道路，会对自己负责，会匹配得起生命本身应有的重量。</strong></p><h3 id="尊重"><a href="#尊重" class="headerlink" title="尊重"></a>尊重</h3><p>因为爱你，所以视你为一个独立而完整的人。相信你有能力解决属于你的问题，探索出一条未知但属于你的道路。我作为一个旅伴，不去动那些想改变你的念头，即便觉得那些改变可能对你比较好——因为只有你能决定哪些是真正的好，哪些改变你愿意发生。你是自己的主导者，别人不能代替你成为自己，谁也不行。如果你愿意，如果你向我表达，我很乐意陪你一起探索。</p><p>因为爱自己，我视自己为一个独立而完整的人。别人不能代替我成为自己，谁也不行。</p><p><strong>对自己负起全部的责任。</strong></p><p>我对自己说。</p><h3 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h3><p>开始喜欢一个人时，最直观的疯狂和努力大概就是「了解」。</p><p>了解对方的喜好，看什么书和电影，喜欢吃什么，去过的地方，值得骄傲的经历，以后的打算……日常再琐碎的细节，都会被仔仔细细、反反复复地探究。我们期望通过这些探究，建立起关于对方的庞大数据库，以便加快关于这人的一切信息的处理速度，识别出各自模式，生成与对方的相处模式——了解慢慢变成了理解。而人又是变化的，所以理解这个工程并没有停歇的一天。</p><p>因为爱你，想用一辈子的时间去理解你，成为关于「你」的专家。我想，当我真正理解你，这段关系的任何走向、任何形式和任何结果，我应该都能接受。因为我会明白你怎么一步一步走到这一天。理解最终带来的是自由吧。</p><p>但是理解很难。</p><p>我们常常用「想象」、「推测」代替理解。<strong>理解需要通过真实场景下真实发生的言语行为，以及隐藏在表象之下的弦外之音、模糊的线索去深入同理、思考、判断、修正。</strong></p><p>因为爱自己，面对自己时选择慢下来，不逃避，有耐心。</p><p>人最擅长自欺欺人，所以真正的理解总是多少伴随着恐惧、失落、争执、误解、孤独。就是因为得来不易，所以这样的心意才显得可贵。比起一时的眉目传情、心意相通，尝试去理解的努力会让人更接近爱，那是一种练习，一种付出，一种耕耘。</p><p>在成为他人的专家之前，祝我们都成为自己的「专家」。</p><h3 id="初心"><a href="#初心" class="headerlink" title="初心"></a>初心</h3><p>爱上一个人，总是有初心的，不论自己能不能说得清楚（大部分情况都说不清楚）。</p><p>那份初心，大概都会来自某种与众不同。</p><p>喜欢你，是因为你敢于坚持某些东西，敢于跟普世保持距离，敢于在某些大家可能忽视的方面做个异类。喜欢你，是因为你拥有独特的生命力，呈现出独特的生命状态。</p><p>因为爱你，所以珍视这些与众不同。希望你能继续保护好那些你不曾妥协、拼命守护的东西，那些在经历起伏后，会感慨好在自己守住了的美好而脆弱的东西。</p><p>因为爱自己，我也要慢慢找出自己一直在努力守护的东西。我们有那么多东西可以妥协，也不得不妥协，偏偏就是这些如此弱小的东西，我们花费了几乎所有要来保护。感谢自己守护住了一些纯粹和好奇，面对新的处境时不后退，努力学习和适应，才有了今天写这篇文章的自己。</p><p>因为爱自己，我会继续打磨三观，让初心跳动到每一个当下，让自己可以时时为它代言。</p><h3 id="相处"><a href="#相处" class="headerlink" title="相处"></a>相处</h3><p>比爱更难的是理解，比理解更难的是相处。安心、长久的陪伴，前提是双方不会想逃离。如果一味严肃、苛责、不会表达、不愿交流，谁都会被吓跑的。</p><p>因为爱你，我愿意倾听，尽力去感受你的情绪和需要，理解发生了什么，你需要面对的是什么，给予温和但有力量的回应，然后才是一起分析和解决问题。不应该指责你做得不够好，因为已经看到了那么努力的尝试。你已经足够努力了，我也不会做得比你好，不过如果你愿意，我们可以一起再试试看。</p><p>因为爱自己，所以事事应该先安慰和鼓励自己——情绪平复以后，问题我会自己解决好的。我不是一个生性敏感而丰富的人，倾听/沟通/共情都需要大量练习。对别人对自己都是，要保持练习。</p><p>因为爱你，应该尽量在相处中让你时时都感到「放松」。首先放下自己的期盼和要求，相信你不是不重视我，只是需要空间先处理好自己的各种事物，先跟自己好好相处。</p><p>所以，跟自己的相处之道，大概也是尽量让自己「放松」。「放松」不是一种命令，甚至无法成为目标，因为它是一种悖论式的存在。<strong>真正的包容，也包容不包容；不要求放松，可能就能放松下来。一旦放松，有趣也就会发生。</strong></p><h3 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h3><p>天长地久还是曾经拥有？</p><p><strong>死亡这个事实一早就劝诫我们，生命的过程远远比结果重要。</strong></p><p>爱可能始于一个激动人心的确认和开始，有可能终结于一个无法释怀的离别。但那些都不是爱的主体。爱的主体是两人的关系，建立在经年累月的相处和理解之上的关系，即使不在身边内心也会留有对方位置的关系。<strong>爱既不是最终的结果，也不是开篇的承诺。爱其实存在于关系建立和变化的全程。</strong>所以它一定不如预想的跌宕起伏，因为生活的大多数时光总是平淡的。但爱就是在一起，或身或心。</p><p>喜欢你，是因为你身上有达成某些结果的能力，而不是因为你口袋里装着这些结果。所以，有自我疗愈和成长的能力，比成熟更重要；有对美的理解和坚持，比颜值更重要；是否能鉴别有趣的问题并愿意费心思索，比聪明重要；看待财富的观念和赚钱能力，比有多少钱重要……</p><p>既然爱是过程，何必计较结果。向死而生的人类，在生命流逝的过程中，暂时无视死亡的结果，转而积极地探索可能性，才创造出了种种奇迹。</p><p>因为爱你，所以我选择 being in the present，尽可能心无旁骛地陪伴，让有你的时光加倍值得回味。</p><p><strong>因为爱自己，所以时时跟自己在一起，明白此刻正在经历什么，全身心地投入，未来不迎，当时不杂，既过不恋。</strong></p><p>因为爱自己，所以明白并不是我不好，也不是世界充满险恶无情，而是还没有修炼到很快找到或切换到一个最适合的角度去看待当下。当熟练之后，更多的时间精力就能从警惕、自我保护、应激中节省出来，去好好欣赏路途的景致，结识同样寂寞但心怀好奇的旅伴，去感受这样的旅途带给我什么样独特的感受。</p><h2 id="当我真正开始爱自己"><a href="#当我真正开始爱自己" class="headerlink" title="当我真正开始爱自己"></a>当我真正开始爱自己</h2><p>感谢今年出现在我生命里我喜爱的人。让我知道自己还有能力去爱，让我有动力成为更好的自己。</p><p>感谢今年出现在我生命里我避之不及的人。让我懂得珍惜自己身上那些弥足珍贵的东西。让我懂得人生有限，应该把最美好的自己，留给合适的人和事。</p><p>爱真的不是放肆，也不是克制，而是深思熟虑、身体力行的努力，可能称不出重量的努力。</p><p><strong>爱不应允幸福，爱是原原本本回到自己身上。问问自己，在这个人/自己身边，能否有勇气清楚看待自己，不屈从，不顺应，不自欺，但也不畏惧改变。</strong></p><p>最后，用卓别林给自己的诗来正式开启爱自己的旅途吧：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">当我真正开始爱自己，</span><br><span class="line">我才认识到，所有的痛苦和情感的折磨，</span><br><span class="line">都只是提醒我：活着，不要违背自己的本心。</span><br><span class="line">今天我明白了，这叫做「真实」。</span><br><span class="line"></span><br><span class="line">当我真正开始爱自己，</span><br><span class="line">我才懂得，把自己的愿望强加于人，</span><br><span class="line">是多么的无礼，就算我知道，时机并不成熟，</span><br><span class="line">那人也还没有做好准备，</span><br><span class="line">就算那个人就是我自己，</span><br><span class="line">今天我明白了，这叫做「尊重」。</span><br><span class="line"></span><br><span class="line">当我开始爱自己，</span><br><span class="line">我不再渴求不同的人生，</span><br><span class="line">我知道任何发生在我身边的事情，</span><br><span class="line">都是对我成长的邀请。</span><br><span class="line">如今，我称之为「成熟」。</span><br><span class="line"></span><br><span class="line">当我开始真正爱自己，</span><br><span class="line">我才明白，我其实一直都在正确的时间，</span><br><span class="line">正确的地方，发生的一切都恰如其分。</span><br><span class="line">由此我得以平静。</span><br><span class="line">今天我明白了，这叫做「自信」。</span><br><span class="line"></span><br><span class="line">当我开始真正爱自己，</span><br><span class="line">我不再牺牲自己的自由时间，</span><br><span class="line">不再去勾画什么宏伟的明天。</span><br><span class="line">今天我只做有趣和快乐的事，</span><br><span class="line">做自己热爱，让心欢喜的事，</span><br><span class="line">用我的方式，以我的韵律。</span><br><span class="line">今天我明白了，这叫做「单纯」。</span><br><span class="line"></span><br><span class="line">当我开始真正爱自己，</span><br><span class="line">我开始远离一切不健康的东西。</span><br><span class="line">不论是饮食和人物，还是事情和环境，</span><br><span class="line">我远离一切让我远离本真的东西。</span><br><span class="line">从前我把这叫做「追求健康的自私自利」，</span><br><span class="line">但今天我明白了，这是「自爱」。</span><br><span class="line"></span><br><span class="line">当我开始真正爱自己，</span><br><span class="line">我不再总想着要永远正确，不犯错误。</span><br><span class="line">我今天明白了，这叫做「谦逊」。</span><br><span class="line"></span><br><span class="line">我当开始真正爱自己，</span><br><span class="line">我不再继续沉溺于过去，</span><br><span class="line">也不再为明天而忧虑，</span><br><span class="line">现在我只活在一切正在发生的当下，</span><br><span class="line">今天，我活在此时此地，</span><br><span class="line">如此日复一日。这就叫「完美」。</span><br><span class="line"></span><br><span class="line">当我开始真正爱自己，</span><br><span class="line">我明白，我的思虑让我变得贫乏和病态，</span><br><span class="line">但当我唤起了心灵的力量，</span><br><span class="line">理智就变成了一个重要的伙伴，</span><br><span class="line">这种组合我称之为，「心的智慧」。</span><br><span class="line"></span><br><span class="line">我们无须再害怕自己和他人的分歧，</span><br><span class="line">矛盾和问题，</span><br><span class="line">因为即使星星有时也会碰在一起，</span><br><span class="line">形成新的世界，</span><br><span class="line">今天我明白，</span><br><span class="line">这就是「生命」。</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/love_yourself.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="CriticalThinking" scheme="http://uegeek.com/tags/CriticalThinking/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="Love" scheme="http://uegeek.com/tags/Love/"/>
    
  </entry>
  
  <entry>
    <title>大哉问01 - 什么样的时间观值得拥有？</title>
    <link href="http://uegeek.com/171126TimePerspective.html"/>
    <id>http://uegeek.com/171126TimePerspective.html</id>
    <published>2017-11-26T01:12:43.000Z</published>
    <updated>2017-12-09T01:14:57.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/dbproductivity.jpg" alt=""></p><a id="more"></a>  <blockquote><p>我们自己虚构了一些问题,然后又炮制了一些答案。        </p><p>——西蒙娜·德·波伏娃</p></blockquote><p><a href="http://www.uegeek.com/171112-HowToAskGoodQuestion.html" target="_blank" rel="noopener">HackYourself 大哉问系列</a>第一篇，我们来讨论「时间」。</p><p>为什么要选择这么虚无的话题呢？我在想，人大概有三大限制：时间，空间，认知资源。从这三个角度重新思考我们这种脆弱又作死的物种，大概会挺有意思。</p><p>虽然一直身处于奔流的时间长河中，但是我们对时间的汹涌却（常常）浑然不觉。面对时间这种无人可以掌控的东西，不禁想问：</p><blockquote><p>我们应该持有什么样的时间观？</p></blockquote><p>时间观是关于时间的观念，关于时间和自己的关系，如何理解时间，如果依据时间做出种种决策，如何对待时间…… 这里讨论的不是时间管理。毕竟，如果对时间本身都还没有自己的理解，凭什么说人家已经是「朋友」，又怎么去管理它呢？</p><p>心理学家津巴多对「时间」做了三十多年的研究，他呼吁我们认真对待自己所持有的时间观念：</p><blockquote><p>一个健康的时间观，能让你以人生的长度来决定如何做最优化的决策。一个平衡的时间观，是高度的积极的过去观，中等偏高的积极的未来观，以及温和的选择性地享乐但不冲动反应的现在观。换言之，拥有一个平衡的时间观，就是为自己的过去骄傲，有自信；对未来有高期望但并不好高骛远，对于当下的自己，适当地享受生活，但既不冲动也不是随叫随到的无计划性。 ——津巴多</p></blockquote><p><img src="https://cdn.dribbble.com/users/89889/screenshots/3658659/toolittletime-dribbble.gif" alt=""></p><h2 id="给时间重新找一个比喻"><a href="#给时间重新找一个比喻" class="headerlink" title="给时间重新找一个比喻"></a>给时间重新找一个比喻</h2><p>对我而言，时间是什么？</p><p>除了从小被教育的「时间就是金钱」，除了日渐步入「Time famine」的深渊，我对时间最大的印象大概就是「无情」了，像器物一般的无情。</p><h3 id="意义-行动标尺"><a href="#意义-行动标尺" class="headerlink" title="意义/行动标尺"></a>意义/行动标尺</h3><p>与无限的时间相比，人太弱小太可怜，不得不沿着单向、不可逆的时间轴往前奔走。如果不是因为生命的时间有限，谁会在意生存、变化、权力、美、爱、有没有后代？印刻在出厂设置中的生命长度，让（有自我意识的）生命体开始珍视自己，有了尽力让生命存在、焕发的意念，也就滋长了种种欲望。<strong>所有的欲望，都是「生命有限」这个事实的形容词。</strong></p><p>因为生命短促，人才会孜孜不倦地追求目标和意义，好让这短暂的时间之旅的残存能够消散得慢一点。</p><p>看起来好像是时间定义了生命，其实，是生命所的持续时间让人有必要以人的尺度来定义时间：一万年对人来说不重要，一豪秒对人来说也不重要。</p><p>我们太习惯以人活着能够经常体验到的时间单位去观察万事万物，也太习惯以满足当下的需要为理由来消耗时间。这同时也提醒我们，只需要稍微转动一下时间标尺的角度，我们观察世界的框架可能就会大有不同：</p><blockquote><p>如果有一辈子的时间来做某件事会怎样？</p><p>如果某件事只会持续 1 秒，我对它的态度会有什么不同？</p><p>如果我与某个人共有 +∞ 的时间（一直相处）会怎样？如果共有时间为 0 （没有交集）会怎样？</p></blockquote><h3 id="可能性的培养皿"><a href="#可能性的培养皿" class="headerlink" title="可能性的培养皿"></a>可能性的培养皿</h3><p>时间可能是全能的神 最大/唯一武器。</p><p>因为无限，所以造物主根本不需要呕心沥血去「设计」生命的所有细节，而是将一切都交给时间，给定初始值，无限演化下去。不论过程中出现了什么，生命轮回也好，沧海桑田也罢，生机勃勃也好，万籁俱寂也罢，都没有所谓，都只是演化过程的一个片段。</p><p>没有秘诀。</p><p>上帝甚至不需要全知全能——只要交给无限的时间就好。只要时间足够长，可能性就不会穷尽。</p><p>我们常常说：「我没有时间了」、「时间不够」、「你有空吗？」……</p><p>有趣的是，<strong>时间本身不包含任何东西</strong>。时间只是度量单位，只是「容器」。我们问「你有时间吗？」，是不是好像在问：「你有厘米吗？」、「你有分贝吗？」。里面什么都没有。</p><p>真正的内容，是时间单位内我们投入的注意力、能量、情感、行动等等。我们不拥有时间，我们只拥有注意力、能量、情感……时间只是培养皿，想要培养出有机体，需要加培养液，不是吗？</p><h2 id="有意义的时间观"><a href="#有意义的时间观" class="headerlink" title="有意义的时间观"></a>有意义的时间观</h2><blockquote><p>什么样的时间观能带来更大收益？</p></blockquote><p>这是一个倾向性很明显的问题。我们似乎得先考虑：</p><ul><li>什么是「收益」？它一定是「结果」吗？（结果可能只是资源，不是目标本身）</li><li>要在多大时间尺度/周期内考虑？</li></ul><p>时间被如此定义，是因为生命体的有限。那生命又是个什么东西？</p><blockquote><p>生命似乎是物质的有序和有规律的行为，它不是完全基于从有序走向无序的倾向，而是部分基于得到保持的现存秩序。……生命有机体如何避免衰退为惰性「平衡」状态呢？通过新陈代谢。……新陈代谢的本质是使有机体成功消除了它活着时不得不产生的所有熵。 —— 薛定谔，「生命是什么」</p></blockquote><p>生命体的伟大之处，在于（一定时间内）抵御了混沌无序的倾向，制造出（或者说吸收了）「负熵」。</p><p>如果回归到这一层含义，对人有意义的「收益」，是不是也可以理解为「有意义的秩序」？</p><p>暂时抛开时间周期的问题，来想想那些时间感消散的时刻。比如说，专注地处于心流状态的时候，在类似做梦这种意识混沌的时候，我们感受不到时间的流逝。身处这些时刻，是不是反而能更真实、直接地触摸到生命本身？</p><p>回到上面的问题：怎样才算最理想的时间收益？对我而言大概是：</p><blockquote><p>在有意识的所有时刻里，都生机勃勃：投入、沉浸、痛并快乐、见过去所未见，体验一个生命可能抵达的深度。更重要的是——最终塑造出自己，并且留下能延续一段时间、传递某种深度的载体。</p></blockquote><p>那么，可以如何去调控时间以及对时间的感觉？如何放大时间的价值？</p><p>似乎有两种办法：<strong>融于当下，或者穿越时间</strong>。</p><p><strong>融于当下</strong>，是指让时间感消失——沉浸到时间里面，<strong>让更多的时间处于聚焦/有序而不是耗散状态</strong>。也就是说，吃饭时就心无旁骛，与伴侣共处时就交心会意，思考时就清理杂乱的欲望，悲伤时就不要阻止眼泪……努力让真正重要的事情的「过程价值」大于「结果价值」。毕竟，我们全身心经历的是每一分每一秒，应该更多地为全程的福祉考虑，而不只是获得结果的那一刹那的高峰体验。</p><p><strong>穿越时间</strong>，是指留下能够抵御时间侵袭的「晶体」，可以是文字、记录、作品、人生信条等等，它是你拼尽全力，从混沌无序中凝练出来的「恰好」和「最好」，它们是（哪怕只有一丢丢）有意义的秩序，可以穿越（哪怕只有一丢丢）时间长河而不被冲刷得面目全非。</p><h2 id="修炼生命力"><a href="#修炼生命力" class="headerlink" title="修炼生命力"></a>修炼生命力</h2><p>于是，时间似乎是焕发生命力的养料和工具套件。</p><p><strong>让我们把时间当做意义过滤器</strong>。哪些事情哪怕只有 1 秒，我们也会珍惜？哪些信息，出现在时间的源头？哪些内容，能真正穿越时间的洗礼？什么目标，值得用大时间周期去追逐？</p><p><strong>让我们把时间当做培养皿</strong>。在时间这个容器中，我们到底需要倾注些什么？希望锻造出什么？投入产出是否匹配？怎样把其他资源转化为时间资源？如果花的每一分钱，都值时间价值；如果花的每一分钟，都超出经济价值，那大概就是世界上最好的投资。</p><p><strong>让我们把时间当做生命过程本身</strong>。在时间流逝中，尽可能去抵御熵增，提炼有意义的秩序，印证我们的存在和延续——不只是基因和生命体的延续，还是探索精神、思考深度的延续，是对自然和美的敬畏的延续。</p><p>这么看来，其实重要的不是时间能送我们到达哪里，真正应该珍惜的，是时间给了我们修炼的机会——<strong>修炼一种在任何情境下都让自己避免熵增、有所获益的能力</strong>，这种神奇能力，大概就是生命力。</p><p>生命那只随机的大手会把我们降落在哪里，没有人知晓。但不论跌落在哪里，都要生生不息，甚至能留下穿越时间的智慧晶体。</p><p>这是生命的责任。</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://book.douban.com/subject/5246820/" target="_blank" rel="noopener">津巴多时间心理学</a></li><li><a href="https://book.douban.com/subject/26309060/" target="_blank" rel="noopener">生命是什么</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/dbproductivity.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="CriticalThinking" scheme="http://uegeek.com/tags/CriticalThinking/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
      <category term="时间" scheme="http://uegeek.com/tags/%E6%97%B6%E9%97%B4/"/>
    
  </entry>
  
  <entry>
    <title>用问题对话虚无 —— HackYourself 大哉问系列</title>
    <link href="http://uegeek.com/171112-HowToAskGoodQuestion.html"/>
    <id>http://uegeek.com/171112-HowToAskGoodQuestion.html</id>
    <published>2017-11-12T02:52:24.000Z</published>
    <updated>2017-11-14T02:56:15.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xjpra.com1.z0.glb.clouddn.com/question-title.jpg" alt=""></p><a id="more"></a>  <blockquote><p>我们自己虚构了一些问题,然后又炮制了一些答案。        </p><p>——西蒙娜·德·波伏娃 「人都是要死的」</p></blockquote><p>经过低产的一年，HackYourself 准备恢复（双）周更的频率。</p><p>欢迎围观 00  的新坑：大哉问系列。</p><p>什么是「大哉问」？</p><blockquote><p>林放问礼之本。子曰：“大哉问！礼，与其奢也，宁俭；丧，与其易也，宁戚。” ——论语 八佾篇第三</p></blockquote><p>大哉问（据说）出自论语，意思是「这是一个非常棒的问题」、「你的问题意义重大啊」。</p><p>这会是一个自问自答的系列。正如「学什么」比「怎么学」更重要，「问什么问题」比「如何回答」更重要。在之前的读书会尝试过「以问题驱动」的读书法，效果不错。加上之前有过「问题作为人生地图」的思考，所以有了大哉问系列的想法。</p><p>人生的种种困惑、迷茫、无力、混沌，只会随着复杂度指数上升的世界而加重。用问题作为线索，与趋于无序、混乱的环境展开对话，也许是一条通幽的小径吧。</p><h2 id="为什么要多问好问题？"><a href="#为什么要多问好问题？" class="headerlink" title="为什么要多问好问题？"></a>为什么要多问好问题？</h2><blockquote><p>为什么与问人类如何作出好决策相比，我们更不愿意问人类如何找到好目标？——马奇</p></blockquote><p>人生好像总是有无穷的问题等待解决。</p><p>问题永远解决不完，这其实不是困扰。真正会造成困扰的，是我们没有意识到：<strong>要解答哪些问题，在某种程度上可以自主选择</strong>。用主动的姿态去探索问题，更是一种选择。</p><p>管理大师马奇的发问提醒我们，好问题多么可贵 —— 跟解决方案（决策）相比，更稀缺的是问对的问题（目标）。</p><h3 id="最大化资源配置"><a href="#最大化资源配置" class="headerlink" title="最大化资源配置"></a>最大化资源配置</h3><p>先用一个功利的视角来解读。</p><p>多问好问题的隐含前提是：<strong>人的寿命太短，精力太宝贵</strong>。</p><p>每一个问题都可能是时间和精力的黑洞，如果我们自己不选择要面对、要解答的问题，马上就会被一大堆问题塞满——<strong>它们可能来自雇佣你、跟你做时间交易的 boss，来自无数生命力顽强的模因（Meme），来自无孔不入想让你做出购买决策的广告，来自不停侵犯个人边界的重要或不重要的他人，来自其实与你完全无关但是能逗乐大脑的垃圾信息</strong>……</p><p>如果把精力和注意力比作可以调动的资源，在滔天的信息洪流之中，我们脑子里工作记忆这一丁点儿资源，实在太过贫乏，必需得像个守财奴一样死死守护它。</p><p>资源配置的目的，无非是更好地转化为产出、达成目标。在这里，「目标」是一个大坑。每个人看似都在为生活奔忙，可是每当夜深人静扪心自问：我每天到底都在干嘛？</p><p>嗯，我到底在干嘛 —— 也是一个问题。</p><p>如果能经常自己给自己设定问题，作为「产出/目的」的重要记录和反馈，并且<strong>有意识地、主动</strong>尝试着寻找答案，「精力」这笔账是不是就没那么糊涂？</p><h3 id="构筑意义，抵抗无序和虚无"><a href="#构筑意义，抵抗无序和虚无" class="headerlink" title="构筑意义，抵抗无序和虚无"></a>构筑意义，抵抗无序和虚无</h3><p>再来切换一个不那么功利的视角。</p><p>人生本无意义。不停追问意义，这大概是人的生理缺陷。</p><p>意义无法按图索骥找到，也不能靠机缘偶遇，而是一点一点提炼和构筑出来的。</p><p>让好问题成为人生线索，通过经常追问各种各样的问题，我们会更清楚自己是什么样的人、看重什么、被什么打动、受什么困扰。这也是打磨三观，寻找意义和自我的过程。</p><blockquote><p>What Do I Stand For?</p></blockquote><p>我为谁（什么）代言？？<strong>这是绝对不能交给他人来回答的问题。</strong></p><p>面对这种终极问题，谁不想回避呢？学校也从来不教该如何解答这些问题。可是它们就是阴魂不散啊，似乎每一次逃避，都往虚无多走了一步。到底有没对错？应该坚持什么？每天的所作所为何以为继？</p><p>万事万物都有一个宿命般的终点：无序。要用有限的生命和稀缺的注意力对抗无序，可能真的没有太多办法，我会试着<strong>用问题编制「有序」的骨架，用沉浸和心流附着成为「有序」的血肉</strong>。</p><p>在问题的牵引之下，希望我们都能迭代出令自己满意的答案，交出人生答卷。当然，给自己设计人生问卷，更为重要。</p><h3 id="留下一些有趣的痕迹"><a href="#留下一些有趣的痕迹" class="headerlink" title="留下一些有趣的痕迹"></a>留下一些有趣的痕迹</h3><p>既然问出了问题，总是会试着去思考、试验、回答。有趣的问题，会激发行动，聚集同好。</p><p>如果一直只是做一个思想和内容消费者，似乎也不太有意思，为什么不留下一些痕迹呢？</p><p>如果能把这些问题的思考、迭代过程记录下来，大概也是对自己一个很好的交待吧？</p><h2 id="什么是好问题？"><a href="#什么是好问题？" class="headerlink" title="什么是好问题？"></a>什么是好问题？</h2><p>这本身就是个需要迭代思考的好问题。</p><p>如果只是为了装 x，很容易问出一些「终极问题」，比如「美是什么？」</p><p>在维特根斯坦看来，这些问题本身不成为问题。因为定义和解释是语言的范畴，只是一种语言的单向逻辑，它解决不了语言之外的问题。意义是终极解释，而「美」不存在语言上的终极解释。那些过于倚重范畴的问题、容易变成文字游戏的「终极」问题，我实在驾驭不来，还是少碰为好。</p><p>怎样识别好问题呢？一个思路是用归纳法，去搜集各种各样的问题，选出好的，然后总结出特征。</p><h3 id="好问题的特征"><a href="#好问题的特征" class="headerlink" title="好问题的特征"></a>好问题的特征</h3><p>00 先凭自己的经验和直觉，尝试总结好问题的特征：</p><ul><li>描述清晰</li><li>不容易回答，值得 go deep，能激发更高、更抽象层级的思考</li><li>指向有潜力的探索方向，牵引出有价值的回答，激发行动和带来改变</li><li>开放式，没有唯一答案，不同背景经历的人可能会有迥异的答案</li><li>或者是时代的大问题，或者是超越时空的普适性问题</li><li>可能不会单独出现，而是一组相关问题</li></ul><h3 id="好问题的栗子"><a href="#好问题的栗子" class="headerlink" title="好问题的栗子"></a>好问题的栗子</h3><p><a href="http://edge.org" target="_blank" rel="noopener">Edge</a> 网站每年都会提出一个 Big question，激发知识界的集体思维碰撞，今年已经是第 19 年。作为好问题的参考再合适不过：</p><table><thead><tr><th>YEAR</th><th>ANNUAL QUESTION</th></tr></thead><tbody><tr><td>2017</td><td>What Scientific Term or Concept Ought To Be More Widely Known?</td></tr><tr><td>2016</td><td>What Do You Consider The Most Interesting Recent [Scientific] News? What Makes It Important? </td></tr><tr><td>2015</td><td>What Do You Think about Machines That Think? </td></tr><tr><td>2014</td><td>What Scientific Idea Is Ready for Retirement? </td></tr><tr><td>2013</td><td>What <em>Should</em> We Be Worried about? </td></tr><tr><td>2012</td><td>What Is Your Favorite Deep, Elegant, or Beautiful Explanation? </td></tr><tr><td>2011</td><td>What Scientific Concept Would Improve Everybody’s Cognitive Toolkit? </td></tr><tr><td>2010</td><td>How Is the Internet Changing the Way You Think? </td></tr><tr><td>2009</td><td>What Will Change Everything? </td></tr><tr><td>2008</td><td>What Have You Changed Your Mind about? Why? </td></tr><tr><td>2007</td><td>What Are You Optimistic About? </td></tr><tr><td>2006</td><td>What Is Your Dangerous Idea? </td></tr><tr><td>2005</td><td>What Do You Believe Is True Even Though You Cannot Prove It? </td></tr><tr><td>2004</td><td>What’s Your Law? </td></tr><tr><td>2003</td><td>What Are the Pressing Scientific Issues for the Nation and the World, and What Is Your Advice on How I Can Begin to Deal With Them? </td></tr><tr><td>2002</td><td>What Is Your Question? … Why? </td></tr><tr><td>2001</td><td>What Questions Have Disappeared? What Now? </td></tr><tr><td>2000</td><td>What Is Today’s Most Important Unreported Story? </td></tr><tr><td>1999</td><td>What Is the Most Important Invention in the Past Two Thousand Years </td></tr><tr><td>1998</td><td>What Questions Are You Asking Yourself?</td></tr></tbody></table><p>在「为未知而教，为未来而学」一书中，作者提出了很多关于教育的好问题。他倡导多提出「有生命力的问题」。</p><p><img src="https://img3.doubanio.com/lpic/s28356404.jpg" alt=""></p><p>哲学家威廉·詹姆斯在「The Will to Believe」一文中，区分了「有生命力的假设」与「无生命力的假设」。有生命力的假设，指一个人在对自己而言具有真实性的问题中所发现的、值得尝试的各种可能性。</p><p>「有生命力的问题」与之类似，<strong>指能够为对话提供焦点和重要意义的一些探究性主题</strong>。教育者可以通过多种方式来引导：</p><ul><li>提供中心线索，包含一系列广泛的探究主题，学习者可以对此进行长时间的探究。</li><li>围绕着大概念而非答案来组织教学。比如：植物不同于动物，它们没有感觉系统，植物的各个部分怎么「知道」应该往哪里生长呢？</li><li><p>提出增殖性问题，让学习者积累一定经验后继续提出相应问题。比如：</p><ul><li>New Middle East 有可能实现吗？（地理）</li><li>人类基因组计划：是福是祸？（生物）</li><li>参与第一次世界大战那一代人为何在 20 年内又发动了第二次世界大战？（历史）</li><li>人为什么要结婚？（社会学和人类学）</li><li>什么是爱？（社会学、生物学、心理学和历史学）</li><li>奥运会是否改善了我们的价值观？（跨学科）</li></ul></li><li><p>找到问题的焦点。从提供一个问题的焦点开始：提供一个主题、题目或者对象，具有真实性和启发性。</p></li></ul><p>解决问题天生伴随着「提出问题」或「发现问题」。这一步教育的缺失，还是得靠自己来弥补。</p><p>关于什么是好问题，你有什么想跟大家分享的吗？欢迎留言。</p><h2 id="如何让好问题成为指引"><a href="#如何让好问题成为指引" class="headerlink" title="如何让好问题成为指引"></a>如何让好问题成为指引</h2><p>普利策奖得主、诺贝尔物理学奖获得者 Isidor Rabi 说，大部分目前在孩子放学回家后都会问一句：「你今天学到什么了吗？」但他的妈妈当年问的是：</p><blockquote><p>你今天有没有提出一个好问题？</p></blockquote><p>提问大概跟学习任何技能都一样，需要大量练习。如果能提出 100 个问题，总能选出最好的 10 个吧？多提问，常常反思是否提出了好的问题，提问这门「手艺」也会精湛起来。</p><p>提出问题仅仅是第一步，我们的目的是让问题真正起到穿针引线的作用。</p><h3 id="筛选问题"><a href="#筛选问题" class="headerlink" title="筛选问题"></a>筛选问题</h3><p>当我们试着列出一些问题，很快就会发现，这些问题的层次差别很大。</p><p>有的思考几分钟就能有大概的思路，有的可能穷极一生也给不出满意的答案。00 暂时以输出为目标，用问题思考周期粗暴地替代问题的复杂度/深度，将问题分成用 周/月/年 时间来思考的不同类型。</p><p>比如「编程思维有什么特点？可以如何改善生活？」可能需要至少一个月来思考和实践。</p><p>那么可以把平时收集的问题列表，标记上「周」或者「月」（如果可以作为年度主题就另外考虑了），如果以月为单位，看看能不能拆分为几个以周为单位的小问题，排出优先级，一周一个。</p><p>大哉问系列打算聚焦在这样的问题：</p><ul><li>思考和实践周期在 一周 ~ 五年 的问题</li><li>对知识体系、立场、思考本身有迭代作用</li><li>个人已有相关困惑和经验积累，待梳理总结</li><li>可以启发近期的行动</li></ul><h3 id="琢磨"><a href="#琢磨" class="headerlink" title="琢磨"></a>琢磨</h3><p>筛选好问题之后才是关键的一步。除了大块的工作时间之外，把问题作为最高优先级的事项：频繁加载问题到脑子中，让注意力尽量聚焦，围绕问题去收集信息、展开思路、建立连接、形成观点，等等。</p><p>怎样做到频繁加载问题呢？现在注意力实在太涣散了。我们可以尝试设定一些 Triggers：</p><table><thead><tr><th>IF</th><th>THEN</th></tr></thead><tbody><tr><td>周日午/晚饭后</td><td>挑选下周的问题，写在卡片上</td></tr><tr><td>出门/通勤</td><td>带上问题卡片，写下思路</td></tr><tr><td>跑步/散步</td><td>热身时加载问题，变跑边整理思路，回来写下笔记</td></tr><tr><td>周六</td><td>整理成文</td></tr></tbody></table><p>（注：跑步和散步对我特别有效，可能不适合大部分人）</p><h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><p>如果没有输出，等于没有思考过。</p><p>思考得再深入，也需要反馈。于是必需将思考做阶段性整理和输出，用来评估自己对问题的理解程度，收集大家的反馈，如果能有观点的碰撞就更好了。</p><p>用于收集反馈和评估的问题：</p><ul><li>这个问题是否激发了比较深度的思考？</li><li>思考、实践过程中我有哪些新收获？</li><li>如何转化为观念和行动上的改变？</li><li>发现了哪些待探索和深入的领域？</li><li>输出过程中遇到哪些问题？</li><li>这到底是不是一个好问题？</li><li>其他人有什么思路？</li></ul><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><blockquote><p>Judge a man by his questions rather than by his answers. ― Voltaire 伏尔泰</p></blockquote><p>HackYourself 大哉问系列启动，欢迎提出你的好问题~</p><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://www.edge.org/annual-questions" target="_blank" rel="noopener">Edge.org</a></li><li><a href="https://book.douban.com/subject/26586892/" target="_blank" rel="noopener">为未知而教,为未来而学</a></li><li><a href="http://blog.lifeway.com/explorethebible/blog/5-characteristics-of-a-good-question/" target="_blank" rel="noopener">5 Characteristics of a Good Question</a></li><li><a href="https://www.zhihu.com/question/21706038" target="_blank" rel="noopener">美是什么？是否存在客观的美？ 以及如何问出一个美的问题？ - 知乎</a></li><li><a href="https://www.zhihu.com/question/22810030" target="_blank" rel="noopener">知乎上的好问题有哪些？</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xjpra.com1.z0.glb.clouddn.com/question-title.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="叽歪" scheme="http://uegeek.com/categories/%E5%8F%BD%E6%AD%AA/"/>
    
    
      <category term="HackYourself" scheme="http://uegeek.com/tags/HackYourself/"/>
    
      <category term="CriticalThinking" scheme="http://uegeek.com/tags/CriticalThinking/"/>
    
      <category term="大哉问" scheme="http://uegeek.com/tags/%E5%A4%A7%E5%93%89%E9%97%AE/"/>
    
  </entry>
  
</feed>
